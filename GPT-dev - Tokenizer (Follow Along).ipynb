{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "q-WmewF1aP8H",
        "bTtqo-s5nkcl",
        "YwJT89vj63YL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization :(\n",
        "\n",
        "Tokenization is at the heart of much weirdness of LLMs. Do not brush it off.\n",
        "\n",
        "- Why can't LLM spell words? **Tokenization**.\n",
        "- Why can't LLM do super simple string processing tasks like reversing a string? **Tokenization**.\n",
        "- Why is LLM worse at non-English languages (e.g. Japanese)? **Tokenization**.\n",
        "- Why is LLM bad at simple arithmetic? **Tokenization**.\n",
        "- Why did GPT-2 have more than necessary trouble coding in Python? **Tokenization**.\n",
        "- Why did my LLM abruptly halt when it sees the string \"<|endoftext|>\"? **Tokenization**.\n",
        "- What is this weird warning I get about a \"trailing whitespace\"? **Tokenization**.\n",
        "- Why the LLM break if I ask it about \"SolidGoldMagikarp\"? **Tokenization**.\n",
        "- Why should I prefer to use YAML over JSON with LLMs? **Tokenization**.\n",
        "- Why is LLM not actually end-to-end language modeling? **Tokenization**.\n",
        "- What is the real root of suffering? **Tokenization**.\n",
        "\n",
        "---\n",
        "\n",
        "Good tokenization web app: [https://tiktokenizer.vercel.app](https://tiktokenizer.vercel.app)\n",
        "\n",
        "Example string:\n",
        "\n",
        "```\n",
        "Tokenization is at the heart of much weirdness of LLMs. Do not brush it off.\n",
        "\n",
        "127 + 677 = 804\n",
        "1275 + 6773 = 8041\n",
        "\n",
        "Egg.\n",
        "I have an Egg.\n",
        "egg.\n",
        "EGG.\n",
        "\n",
        "ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”. ì €ëŠ” OpenAIì—ì„œ ê°œë°œí•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì¸ ChatGPTìž…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ê²ƒì´ ìžˆìœ¼ì‹œë©´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.\n",
        "\n",
        "for i in range(1, 101):\n",
        "    if i % 3 == 0 and i % 5 == 0:\n",
        "        print(\"FizzBuzz\")\n",
        "    elif i % 3 == 0:\n",
        "        print(\"Fizz\")\n",
        "    elif i % 5 == 0:\n",
        "        print(\"Buzz\")\n",
        "    else:\n",
        "        print(i)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "Much glory awaits someone who can delete the need for tokenization. But meanwhile, let's learn about it.\n"
      ],
      "metadata": {
        "id": "cqYa9VbqYEGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"ì•ˆë…•í•˜ì„¸ìš” ðŸ‘‹ (hello in Korean!)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uxqOxZicX4gn",
        "outputId": "0a7a13c2-0b2f-4f06-8967-bf3f12be4b78"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ì•ˆë…•í•˜ì„¸ìš” ðŸ‘‹ (hello in Korean!)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[ord(x)for x in \"ì•ˆë…•í•˜ì„¸ìš” ðŸ‘‹ (hello in Korean!)\"]  # ord() --> convert a single Unicode character into its integer representation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onuq_OOgX3OG",
        "outputId": "70aec645-ff3e-4555-b892-3d19d8400060"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[50504,\n",
              " 45397,\n",
              " 54616,\n",
              " 49464,\n",
              " 50836,\n",
              " 32,\n",
              " 128075,\n",
              " 32,\n",
              " 40,\n",
              " 104,\n",
              " 101,\n",
              " 108,\n",
              " 108,\n",
              " 111,\n",
              " 32,\n",
              " 105,\n",
              " 110,\n",
              " 32,\n",
              " 75,\n",
              " 111,\n",
              " 114,\n",
              " 101,\n",
              " 97,\n",
              " 110,\n",
              " 33,\n",
              " 41]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes"
      ],
      "metadata": {
        "id": "q-WmewF1aP8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image you shared seems to show the length of a string and its encoded byte representation. This illustrates how UTF-8 uses a variable number of bytes for different characters.\n",
        "\n",
        "In the specific case of Korean characters, as mentioned earlier, each character is typically encoded using three bytes in UTF-8. The lengths shown likely relate to:\n",
        "- The number of characters in the string (`39` might be counting individual characters in a Unicode-aware manner, where each code point is counted separately).\n",
        "- The number of bytes used to encode the string (`26` might be the length of a shorter string or portion of the string).\n",
        "\n",
        "The three-byte encoding per character for Korean is due to their position in the Unicode code point table (U+AC00 to U+D7AF):\n",
        "- **First byte**: Starts with `1110`, marking it as the beginning of a three-byte sequence.\n",
        "- **Second and third bytes**: Begin with `10`, indicating continuation bytes.\n",
        "\n",
        "This method allows UTF-8 to dynamically adjust the number of bytes it uses based on the character's Unicode code point, making it both efficient for characters that have lower code points (like ASCII, which uses only one byte) and capable of representing the full range of Unicode characters, which includes much higher code points using more bytes.\n",
        "\n",
        "If you need more detailed breakdowns of specific characters or examples, feel free to specify, and I can provide further explanations or examples!"
      ],
      "metadata": {
        "id": "hVeNKMvHaP5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If a byte starts with the bit pattern `1110`, it cannot represent a valid one-byte sequence in UTF-8. This pattern specifically indicates that the byte is the beginning of a three-byte sequence. Here's how UTF-8 encodes data based on the leading bits:\n",
        "\n",
        "1. **One-byte sequence (`0xxxxxxx`)**:\n",
        "   - Used for characters from U+0000 to U+007F (standard ASCII range).\n",
        "   - The byte starts with a `0`, followed by the 7-bit ASCII code of the character.\n",
        "\n",
        "2. **Two-byte sequence (`110xxxxx 10xxxxxx`)**:\n",
        "   - Used for characters from U+0080 to U+07FF.\n",
        "   - The first byte starts with `110`, followed by the first 5 bits of the character's Unicode code point.\n",
        "   - The second byte starts with `10`, followed by the next 6 bits of the character's Unicode code point.\n",
        "\n",
        "3. **Three-byte sequence (`1110xxxx 10xxxxxx 10xxxxxx`)**:\n",
        "   - Used for characters from U+0800 to U+FFFF.\n",
        "   - The first byte starts with `1110`, indicating the start of a three-byte sequence and is followed by the first 4 bits of the Unicode code point.\n",
        "   - The second and third bytes start with `10`, each carrying 6 bits of the code point.\n",
        "\n",
        "4. **Four-byte sequence (`11110xxx 10xxxxxx 10xxxxxx 10xxxxxx`)**:\n",
        "   - Used for characters from U+10000 to U+10FFFF.\n",
        "   - The first byte starts with `11110`, followed by the first 3 bits of the Unicode code point.\n",
        "   - The second, third, and fourth bytes start with `10`, each carrying 6 bits of the code point.\n",
        "\n",
        "If you encounter a byte such as `11101111` (`EF` in hexadecimal) at the start of a sequence, it indicates that this byte is part of a three-byte sequence because of the `1110` prefix. It is not valid as a standalone one-byte sequence in UTF-8. This byte would need to be followed by two more bytes, each beginning with `10`, to complete the encoding of a character from U+0800 to U+FFFF."
      ],
      "metadata": {
        "id": "ObCK9NhQaP3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Back to Coding"
      ],
      "metadata": {
        "id": "7bzs0iVvaP1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(list(\"ì•ˆë…•í•˜ì„¸ìš” ðŸ‘‹ (hello in Korean!)\".encode(\"utf-8\")))) # notice how the encoded is much longer. Each korean char uses 3 bytes as seen below.\n",
        "print(len(list((\"ì•ˆë…•í•˜ì„¸ìš” ðŸ‘‹ (hello in Korean!)\".encode(\"utf-8\")).decode(\"utf-8\"))))\n",
        "\n",
        "print(list(\"ì•ˆë…•í•˜ì„¸ìš” ðŸ‘‹ (hello in Korean!)\".encode(\"utf-8\")))\n",
        "print(list((\"ì•ˆë…•í•˜ì„¸ìš” ðŸ‘‹ (hello in Korean!)\".encode(\"utf-8\")).decode(\"utf-8\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3G7EvF2X3Lp",
        "outputId": "c67e6751-8cc6-4484-e2ce-684dd1b7d621"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39\n",
            "26\n",
            "[236, 149, 136, 235, 133, 149, 237, 149, 152, 236, 132, 184, 236, 154, 148, 32, 240, 159, 145, 139, 32, 40, 104, 101, 108, 108, 111, 32, 105, 110, 32, 75, 111, 114, 101, 97, 110, 33, 41]\n",
            "['ì•ˆ', 'ë…•', 'í•˜', 'ì„¸', 'ìš”', ' ', 'ðŸ‘‹', ' ', '(', 'h', 'e', 'l', 'l', 'o', ' ', 'i', 'n', ' ', 'K', 'o', 'r', 'e', 'a', 'n', '!', ')']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text from https://www.reedbeta.com/blog/programmers-intro-to-unicode/\n",
        "text = \"ï¼µï½Žï½‰ï½ƒï½ï½„ï½…! ðŸ…¤ðŸ…ðŸ…˜ðŸ…’ðŸ…žðŸ…“ðŸ…”â€½ ðŸ‡ºâ€ŒðŸ‡³â€ŒðŸ‡®â€ŒðŸ‡¨â€ŒðŸ‡´â€ŒðŸ‡©â€ŒðŸ‡ª! ðŸ˜„ The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to â€œsupport Unicodeâ€ in our software (whatever that meansâ€”like using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I donâ€™t blame programmers for still finding the whole thing mysterious, even 30 years after Unicodeâ€™s inception.\"\n",
        "tokens = text.encode(\"utf-8\") # raw bytes (string of text had already been encoded to UTF-8 using .encode() // this method returns a bytes object, which is a sequence of bytes preresenting the Unicode chars\n",
        "                              # in the string according to utf-8 encoding)\n",
        "tokens = list(map(int, tokens)) # convert to a list of integers in range 0..255 for convenience\n",
        "                                        # the map() function applies a given function to each item of an iterable (like a list or sequence). And returns a map object, which is an iterator. In this case\n",
        "                                                # applying int() function to each item in the \"tokens\" sequence\n",
        "print('---')\n",
        "print(text)\n",
        "print(\"length:\", len(text))\n",
        "print('---')\n",
        "print(tokens)\n",
        "print(\"length:\", len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuOOZKFKX3I-",
        "outputId": "8a4b50f3-57ed-4a69-984f-6f62de7866de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "ï¼µï½Žï½‰ï½ƒï½ï½„ï½…! ðŸ…¤ðŸ…ðŸ…˜ðŸ…’ðŸ…žðŸ…“ðŸ…”â€½ ðŸ‡ºâ€ŒðŸ‡³â€ŒðŸ‡®â€ŒðŸ‡¨â€ŒðŸ‡´â€ŒðŸ‡©â€ŒðŸ‡ª! ðŸ˜„ The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to â€œsupport Unicodeâ€ in our software (whatever that meansâ€”like using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I donâ€™t blame programmers for still finding the whole thing mysterious, even 30 years after Unicodeâ€™s inception.\n",
            "length: 533\n",
            "---\n",
            "[239, 188, 181, 239, 189, 142, 239, 189, 137, 239, 189, 131, 239, 189, 143, 239, 189, 132, 239, 189, 133, 33, 32, 240, 159, 133, 164, 240, 159, 133, 157, 240, 159, 133, 152, 240, 159, 133, 146, 240, 159, 133, 158, 240, 159, 133, 147, 240, 159, 133, 148, 226, 128, 189, 32, 240, 159, 135, 186, 226, 128, 140, 240, 159, 135, 179, 226, 128, 140, 240, 159, 135, 174, 226, 128, 140, 240, 159, 135, 168, 226, 128, 140, 240, 159, 135, 180, 226, 128, 140, 240, 159, 135, 169, 226, 128, 140, 240, 159, 135, 170, 33, 32, 240, 159, 152, 132, 32, 84, 104, 101, 32, 118, 101, 114, 121, 32, 110, 97, 109, 101, 32, 115, 116, 114, 105, 107, 101, 115, 32, 102, 101, 97, 114, 32, 97, 110, 100, 32, 97, 119, 101, 32, 105, 110, 116, 111, 32, 116, 104, 101, 32, 104, 101, 97, 114, 116, 115, 32, 111, 102, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 119, 111, 114, 108, 100, 119, 105, 100, 101, 46, 32, 87, 101, 32, 97, 108, 108, 32, 107, 110, 111, 119, 32, 119, 101, 32, 111, 117, 103, 104, 116, 32, 116, 111, 32, 226, 128, 156, 115, 117, 112, 112, 111, 114, 116, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 157, 32, 105, 110, 32, 111, 117, 114, 32, 115, 111, 102, 116, 119, 97, 114, 101, 32, 40, 119, 104, 97, 116, 101, 118, 101, 114, 32, 116, 104, 97, 116, 32, 109, 101, 97, 110, 115, 226, 128, 148, 108, 105, 107, 101, 32, 117, 115, 105, 110, 103, 32, 119, 99, 104, 97, 114, 95, 116, 32, 102, 111, 114, 32, 97, 108, 108, 32, 116, 104, 101, 32, 115, 116, 114, 105, 110, 103, 115, 44, 32, 114, 105, 103, 104, 116, 63, 41, 46, 32, 66, 117, 116, 32, 85, 110, 105, 99, 111, 100, 101, 32, 99, 97, 110, 32, 98, 101, 32, 97, 98, 115, 116, 114, 117, 115, 101, 44, 32, 97, 110, 100, 32, 100, 105, 118, 105, 110, 103, 32, 105, 110, 116, 111, 32, 116, 104, 101, 32, 116, 104, 111, 117, 115, 97, 110, 100, 45, 112, 97, 103, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 83, 116, 97, 110, 100, 97, 114, 100, 32, 112, 108, 117, 115, 32, 105, 116, 115, 32, 100, 111, 122, 101, 110, 115, 32, 111, 102, 32, 115, 117, 112, 112, 108, 101, 109, 101, 110, 116, 97, 114, 121, 32, 97, 110, 110, 101, 120, 101, 115, 44, 32, 114, 101, 112, 111, 114, 116, 115, 44, 32, 97, 110, 100, 32, 110, 111, 116, 101, 115, 32, 99, 97, 110, 32, 98, 101, 32, 109, 111, 114, 101, 32, 116, 104, 97, 110, 32, 97, 32, 108, 105, 116, 116, 108, 101, 32, 105, 110, 116, 105, 109, 105, 100, 97, 116, 105, 110, 103, 46, 32, 73, 32, 100, 111, 110, 226, 128, 153, 116, 32, 98, 108, 97, 109, 101, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 102, 111, 114, 32, 115, 116, 105, 108, 108, 32, 102, 105, 110, 100, 105, 110, 103, 32, 116, 104, 101, 32, 119, 104, 111, 108, 101, 32, 116, 104, 105, 110, 103, 32, 109, 121, 115, 116, 101, 114, 105, 111, 117, 115, 44, 32, 101, 118, 101, 110, 32, 51, 48, 32, 121, 101, 97, 114, 115, 32, 97, 102, 116, 101, 114, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 153, 115, 32, 105, 110, 99, 101, 112, 116, 105, 111, 110, 46]\n",
            "length: 616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]): # Pythonic way to iterate consecutive elements\n",
        "                                          # ids[1:] --> creates a new list that is the original list ids starting from the second element\n",
        "                                          # zip(ids, ids[1:]) --> pairs each element in ids with its subsequent element, forming a tuple.\n",
        "                                              # this loop iterates over each of these pairs\n",
        "        counts[pair] = counts.get(pair, 0) + 1    # returns the valye for the key \"pair\" from dictionary \"counts\" // if not already a key, returns 0 instead (default value) // then increments count of \"pair\" by 1\n",
        "    return counts\n",
        "\n",
        "stats = get_stats(tokens)\n",
        "print(stats)\n",
        "print(sorted(((v,k) for k,v in stats.items()), reverse=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02o695KyX3Gj",
        "outputId": "8f466457-680a-4545-d70c-c055bbb9c928"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(239, 188): 1, (188, 181): 1, (181, 239): 1, (239, 189): 6, (189, 142): 1, (142, 239): 1, (189, 137): 1, (137, 239): 1, (189, 131): 1, (131, 239): 1, (189, 143): 1, (143, 239): 1, (189, 132): 1, (132, 239): 1, (189, 133): 1, (133, 33): 1, (33, 32): 2, (32, 240): 3, (240, 159): 15, (159, 133): 7, (133, 164): 1, (164, 240): 1, (133, 157): 1, (157, 240): 1, (133, 152): 1, (152, 240): 1, (133, 146): 1, (146, 240): 1, (133, 158): 1, (158, 240): 1, (133, 147): 1, (147, 240): 1, (133, 148): 1, (148, 226): 1, (226, 128): 12, (128, 189): 1, (189, 32): 1, (159, 135): 7, (135, 186): 1, (186, 226): 1, (128, 140): 6, (140, 240): 6, (135, 179): 1, (179, 226): 1, (135, 174): 1, (174, 226): 1, (135, 168): 1, (168, 226): 1, (135, 180): 1, (180, 226): 1, (135, 169): 1, (169, 226): 1, (135, 170): 1, (170, 33): 1, (159, 152): 1, (152, 132): 1, (132, 32): 1, (32, 84): 1, (84, 104): 1, (104, 101): 6, (101, 32): 20, (32, 118): 1, (118, 101): 3, (101, 114): 6, (114, 121): 2, (121, 32): 2, (32, 110): 2, (110, 97): 1, (97, 109): 4, (109, 101): 6, (32, 115): 5, (115, 116): 5, (116, 114): 3, (114, 105): 4, (105, 107): 2, (107, 101): 2, (101, 115): 3, (115, 32): 10, (32, 102): 4, (102, 101): 1, (101, 97): 4, (97, 114): 7, (114, 32): 6, (32, 97): 10, (97, 110): 10, (110, 100): 6, (100, 32): 4, (97, 119): 1, (119, 101): 2, (32, 105): 6, (105, 110): 12, (110, 116): 4, (116, 111): 3, (111, 32): 3, (32, 116): 9, (116, 104): 8, (32, 104): 1, (114, 116): 3, (116, 115): 3, (32, 111): 4, (111, 102): 3, (102, 32): 2, (32, 112): 3, (112, 114): 2, (114, 111): 2, (111, 103): 2, (103, 114): 2, (114, 97): 2, (109, 109): 2, (114, 115): 3, (32, 119): 4, (119, 111): 1, (111, 114): 6, (114, 108): 1, (108, 100): 1, (100, 119): 1, (119, 105): 1, (105, 100): 2, (100, 101): 5, (101, 46): 1, (46, 32): 3, (32, 87): 1, (87, 101): 1, (97, 108): 2, (108, 108): 3, (108, 32): 3, (32, 107): 1, (107, 110): 1, (110, 111): 2, (111, 119): 1, (119, 32): 1, (111, 117): 4, (117, 103): 1, (103, 104): 2, (104, 116): 2, (116, 32): 6, (32, 226): 1, (128, 156): 1, (156, 115): 1, (115, 117): 2, (117, 112): 2, (112, 112): 2, (112, 111): 2, (32, 85): 4, (85, 110): 4, (110, 105): 4, (105, 99): 4, (99, 111): 4, (111, 100): 4, (101, 226): 2, (128, 157): 1, (157, 32): 1, (110, 32): 5, (117, 114): 1, (115, 111): 1, (102, 116): 2, (116, 119): 1, (119, 97): 1, (114, 101): 3, (32, 40): 1, (40, 119): 1, (119, 104): 2, (104, 97): 4, (97, 116): 3, (116, 101): 4, (101, 118): 2, (32, 109): 3, (110, 115): 2, (115, 226): 1, (128, 148): 1, (148, 108): 1, (108, 105): 2, (32, 117): 1, (117, 115): 5, (115, 105): 1, (110, 103): 6, (103, 32): 4, (119, 99): 1, (99, 104): 1, (114, 95): 1, (95, 116): 1, (102, 111): 2, (103, 115): 1, (115, 44): 4, (44, 32): 5, (32, 114): 2, (105, 103): 1, (116, 63): 1, (63, 41): 1, (41, 46): 1, (32, 66): 1, (66, 117): 1, (117, 116): 1, (32, 99): 2, (99, 97): 2, (32, 98): 3, (98, 101): 2, (97, 98): 1, (98, 115): 1, (114, 117): 1, (115, 101): 1, (101, 44): 1, (32, 100): 3, (100, 105): 2, (105, 118): 1, (118, 105): 1, (104, 111): 2, (115, 97): 1, (100, 45): 1, (45, 112): 1, (112, 97): 1, (97, 103): 1, (103, 101): 1, (32, 83): 1, (83, 116): 1, (116, 97): 2, (100, 97): 2, (114, 100): 1, (112, 108): 2, (108, 117): 1, (105, 116): 2, (100, 111): 2, (111, 122): 1, (122, 101): 1, (101, 110): 3, (108, 101): 3, (101, 109): 1, (110, 110): 1, (110, 101): 1, (101, 120): 1, (120, 101): 1, (101, 112): 2, (111, 116): 1, (109, 111): 1, (97, 32): 1, (32, 108): 1, (116, 116): 1, (116, 108): 1, (116, 105): 4, (105, 109): 1, (109, 105): 1, (103, 46): 1, (32, 73): 1, (73, 32): 1, (111, 110): 2, (110, 226): 1, (128, 153): 2, (153, 116): 1, (98, 108): 1, (108, 97): 1, (105, 108): 1, (102, 105): 1, (111, 108): 1, (104, 105): 1, (109, 121): 1, (121, 115): 1, (105, 111): 2, (32, 101): 1, (32, 51): 1, (51, 48): 1, (48, 32): 1, (32, 121): 1, (121, 101): 1, (97, 102): 1, (153, 115): 1, (110, 99): 1, (99, 101): 1, (112, 116): 1, (110, 46): 1}\n",
            "[(20, (101, 32)), (15, (240, 159)), (12, (226, 128)), (12, (105, 110)), (10, (115, 32)), (10, (97, 110)), (10, (32, 97)), (9, (32, 116)), (8, (116, 104)), (7, (159, 135)), (7, (159, 133)), (7, (97, 114)), (6, (239, 189)), (6, (140, 240)), (6, (128, 140)), (6, (116, 32)), (6, (114, 32)), (6, (111, 114)), (6, (110, 103)), (6, (110, 100)), (6, (109, 101)), (6, (104, 101)), (6, (101, 114)), (6, (32, 105)), (5, (117, 115)), (5, (115, 116)), (5, (110, 32)), (5, (100, 101)), (5, (44, 32)), (5, (32, 115)), (4, (116, 105)), (4, (116, 101)), (4, (115, 44)), (4, (114, 105)), (4, (111, 117)), (4, (111, 100)), (4, (110, 116)), (4, (110, 105)), (4, (105, 99)), (4, (104, 97)), (4, (103, 32)), (4, (101, 97)), (4, (100, 32)), (4, (99, 111)), (4, (97, 109)), (4, (85, 110)), (4, (32, 119)), (4, (32, 111)), (4, (32, 102)), (4, (32, 85)), (3, (118, 101)), (3, (116, 115)), (3, (116, 114)), (3, (116, 111)), (3, (114, 116)), (3, (114, 115)), (3, (114, 101)), (3, (111, 102)), (3, (111, 32)), (3, (108, 108)), (3, (108, 101)), (3, (108, 32)), (3, (101, 115)), (3, (101, 110)), (3, (97, 116)), (3, (46, 32)), (3, (32, 240)), (3, (32, 112)), (3, (32, 109)), (3, (32, 100)), (3, (32, 98)), (2, (128, 153)), (2, (121, 32)), (2, (119, 104)), (2, (119, 101)), (2, (117, 112)), (2, (116, 97)), (2, (115, 117)), (2, (114, 121)), (2, (114, 111)), (2, (114, 97)), (2, (112, 114)), (2, (112, 112)), (2, (112, 111)), (2, (112, 108)), (2, (111, 110)), (2, (111, 103)), (2, (110, 115)), (2, (110, 111)), (2, (109, 109)), (2, (108, 105)), (2, (107, 101)), (2, (105, 116)), (2, (105, 111)), (2, (105, 107)), (2, (105, 100)), (2, (104, 116)), (2, (104, 111)), (2, (103, 114)), (2, (103, 104)), (2, (102, 116)), (2, (102, 111)), (2, (102, 32)), (2, (101, 226)), (2, (101, 118)), (2, (101, 112)), (2, (100, 111)), (2, (100, 105)), (2, (100, 97)), (2, (99, 97)), (2, (98, 101)), (2, (97, 108)), (2, (33, 32)), (2, (32, 114)), (2, (32, 110)), (2, (32, 99)), (1, (239, 188)), (1, (189, 143)), (1, (189, 142)), (1, (189, 137)), (1, (189, 133)), (1, (189, 132)), (1, (189, 131)), (1, (189, 32)), (1, (188, 181)), (1, (186, 226)), (1, (181, 239)), (1, (180, 226)), (1, (179, 226)), (1, (174, 226)), (1, (170, 33)), (1, (169, 226)), (1, (168, 226)), (1, (164, 240)), (1, (159, 152)), (1, (158, 240)), (1, (157, 240)), (1, (157, 32)), (1, (156, 115)), (1, (153, 116)), (1, (153, 115)), (1, (152, 240)), (1, (152, 132)), (1, (148, 226)), (1, (148, 108)), (1, (147, 240)), (1, (146, 240)), (1, (143, 239)), (1, (142, 239)), (1, (137, 239)), (1, (135, 186)), (1, (135, 180)), (1, (135, 179)), (1, (135, 174)), (1, (135, 170)), (1, (135, 169)), (1, (135, 168)), (1, (133, 164)), (1, (133, 158)), (1, (133, 157)), (1, (133, 152)), (1, (133, 148)), (1, (133, 147)), (1, (133, 146)), (1, (133, 33)), (1, (132, 239)), (1, (132, 32)), (1, (131, 239)), (1, (128, 189)), (1, (128, 157)), (1, (128, 156)), (1, (128, 148)), (1, (122, 101)), (1, (121, 115)), (1, (121, 101)), (1, (120, 101)), (1, (119, 111)), (1, (119, 105)), (1, (119, 99)), (1, (119, 97)), (1, (119, 32)), (1, (118, 105)), (1, (117, 116)), (1, (117, 114)), (1, (117, 103)), (1, (116, 119)), (1, (116, 116)), (1, (116, 108)), (1, (116, 63)), (1, (115, 226)), (1, (115, 111)), (1, (115, 105)), (1, (115, 101)), (1, (115, 97)), (1, (114, 117)), (1, (114, 108)), (1, (114, 100)), (1, (114, 95)), (1, (112, 116)), (1, (112, 97)), (1, (111, 122)), (1, (111, 119)), (1, (111, 116)), (1, (111, 108)), (1, (110, 226)), (1, (110, 110)), (1, (110, 101)), (1, (110, 99)), (1, (110, 97)), (1, (110, 46)), (1, (109, 121)), (1, (109, 111)), (1, (109, 105)), (1, (108, 117)), (1, (108, 100)), (1, (108, 97)), (1, (107, 110)), (1, (105, 118)), (1, (105, 109)), (1, (105, 108)), (1, (105, 103)), (1, (104, 105)), (1, (103, 115)), (1, (103, 101)), (1, (103, 46)), (1, (102, 105)), (1, (102, 101)), (1, (101, 120)), (1, (101, 109)), (1, (101, 46)), (1, (101, 44)), (1, (100, 119)), (1, (100, 45)), (1, (99, 104)), (1, (99, 101)), (1, (98, 115)), (1, (98, 108)), (1, (97, 119)), (1, (97, 103)), (1, (97, 102)), (1, (97, 98)), (1, (97, 32)), (1, (95, 116)), (1, (87, 101)), (1, (84, 104)), (1, (83, 116)), (1, (73, 32)), (1, (66, 117)), (1, (63, 41)), (1, (51, 48)), (1, (48, 32)), (1, (45, 112)), (1, (41, 46)), (1, (40, 119)), (1, (32, 226)), (1, (32, 121)), (1, (32, 118)), (1, (32, 117)), (1, (32, 108)), (1, (32, 107)), (1, (32, 104)), (1, (32, 101)), (1, (32, 87)), (1, (32, 84)), (1, (32, 83)), (1, (32, 73)), (1, (32, 66)), (1, (32, 51)), (1, (32, 40))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_pair = max(stats, key=stats.get)\n",
        "top_pair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdf9DHa8X3EQ",
        "outputId": "c2e8d99c-48dd-4238-b426-3dc25679a0b8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge(ids, pair, idx): # Defines a function named merge that takes three parameters:\n",
        "                                      # ids (a list of integers), pair (a tuple of two integers to search for in ids), and idx (a new integer that will replace occurrences of pair).\n",
        "  # in the list of ints (ids), replace all consecutive occurences of pair with the new token idx\n",
        "  newids = []\n",
        "  i = 0\n",
        "  while i < len(ids):\n",
        "    # if we are not at the very last position AND the pair matches, replace it\n",
        "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "      newids.append(idx)\n",
        "      i += 2\n",
        "    else:\n",
        "      newids.append(ids[i])\n",
        "      i += 1\n",
        "  return newids\n",
        "\n",
        "print(merge([5, 6, 6, 7, 9, 1], (6, 7), 99))\n",
        "\n",
        "tokens2 = merge(tokens, top_pair, 256)\n",
        "print(tokens2)\n",
        "print(\"length:\", len(tokens2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_t5At_cX3By",
        "outputId": "151b6ca5-e7b1-4392-dc7b-84ca4c71d017"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 6, 99, 9, 1]\n",
            "[239, 188, 181, 239, 189, 142, 239, 189, 137, 239, 189, 131, 239, 189, 143, 239, 189, 132, 239, 189, 133, 33, 32, 240, 159, 133, 164, 240, 159, 133, 157, 240, 159, 133, 152, 240, 159, 133, 146, 240, 159, 133, 158, 240, 159, 133, 147, 240, 159, 133, 148, 226, 128, 189, 32, 240, 159, 135, 186, 226, 128, 140, 240, 159, 135, 179, 226, 128, 140, 240, 159, 135, 174, 226, 128, 140, 240, 159, 135, 168, 226, 128, 140, 240, 159, 135, 180, 226, 128, 140, 240, 159, 135, 169, 226, 128, 140, 240, 159, 135, 170, 33, 32, 240, 159, 152, 132, 32, 84, 104, 256, 118, 101, 114, 121, 32, 110, 97, 109, 256, 115, 116, 114, 105, 107, 101, 115, 32, 102, 101, 97, 114, 32, 97, 110, 100, 32, 97, 119, 256, 105, 110, 116, 111, 32, 116, 104, 256, 104, 101, 97, 114, 116, 115, 32, 111, 102, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 119, 111, 114, 108, 100, 119, 105, 100, 101, 46, 32, 87, 256, 97, 108, 108, 32, 107, 110, 111, 119, 32, 119, 256, 111, 117, 103, 104, 116, 32, 116, 111, 32, 226, 128, 156, 115, 117, 112, 112, 111, 114, 116, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 157, 32, 105, 110, 32, 111, 117, 114, 32, 115, 111, 102, 116, 119, 97, 114, 256, 40, 119, 104, 97, 116, 101, 118, 101, 114, 32, 116, 104, 97, 116, 32, 109, 101, 97, 110, 115, 226, 128, 148, 108, 105, 107, 256, 117, 115, 105, 110, 103, 32, 119, 99, 104, 97, 114, 95, 116, 32, 102, 111, 114, 32, 97, 108, 108, 32, 116, 104, 256, 115, 116, 114, 105, 110, 103, 115, 44, 32, 114, 105, 103, 104, 116, 63, 41, 46, 32, 66, 117, 116, 32, 85, 110, 105, 99, 111, 100, 256, 99, 97, 110, 32, 98, 256, 97, 98, 115, 116, 114, 117, 115, 101, 44, 32, 97, 110, 100, 32, 100, 105, 118, 105, 110, 103, 32, 105, 110, 116, 111, 32, 116, 104, 256, 116, 104, 111, 117, 115, 97, 110, 100, 45, 112, 97, 103, 256, 85, 110, 105, 99, 111, 100, 256, 83, 116, 97, 110, 100, 97, 114, 100, 32, 112, 108, 117, 115, 32, 105, 116, 115, 32, 100, 111, 122, 101, 110, 115, 32, 111, 102, 32, 115, 117, 112, 112, 108, 101, 109, 101, 110, 116, 97, 114, 121, 32, 97, 110, 110, 101, 120, 101, 115, 44, 32, 114, 101, 112, 111, 114, 116, 115, 44, 32, 97, 110, 100, 32, 110, 111, 116, 101, 115, 32, 99, 97, 110, 32, 98, 256, 109, 111, 114, 256, 116, 104, 97, 110, 32, 97, 32, 108, 105, 116, 116, 108, 256, 105, 110, 116, 105, 109, 105, 100, 97, 116, 105, 110, 103, 46, 32, 73, 32, 100, 111, 110, 226, 128, 153, 116, 32, 98, 108, 97, 109, 256, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 102, 111, 114, 32, 115, 116, 105, 108, 108, 32, 102, 105, 110, 100, 105, 110, 103, 32, 116, 104, 256, 119, 104, 111, 108, 256, 116, 104, 105, 110, 103, 32, 109, 121, 115, 116, 101, 114, 105, 111, 117, 115, 44, 32, 101, 118, 101, 110, 32, 51, 48, 32, 121, 101, 97, 114, 115, 32, 97, 102, 116, 101, 114, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 153, 115, 32, 105, 110, 99, 101, 112, 116, 105, 111, 110, 46]\n",
            "length: 596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making the training text longer to have more representative token statistics\n",
        "# text from https://www.reedbeta.com/blog/programmers-intro-to-unicode/\n",
        "text = \"\"\"A Programmerâ€™s Introduction to Unicode March 3, 2017 Â· Coding Â· 22 Comments  ï¼µï½Žï½‰ï½ƒï½ï½„ï½…! ðŸ…¤ðŸ…ðŸ…˜ðŸ…’ðŸ…žðŸ…“ðŸ…”â€½ ðŸ‡º\\u200cðŸ‡³\\u200cðŸ‡®\\u200cðŸ‡¨\\u200cðŸ‡´\\u200cðŸ‡©\\u200cðŸ‡ª! ðŸ˜„ The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to â€œsupport Unicodeâ€ in our software (whatever that meansâ€”like using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I donâ€™t blame programmers for still finding the whole thing mysterious, even 30 years after Unicodeâ€™s inception.  A few months ago, I got interested in Unicode and decided to spend some time learning more about it in detail. In this article, Iâ€™ll give an introduction to it from a programmerâ€™s point of view.  Iâ€™m going to focus on the character set and whatâ€™s involved in working with strings and files of Unicode text. However, in this article Iâ€™m not going to talk about fonts, text layout/shaping/rendering, or localization in detailâ€”those are separate issues, beyond my scope (and knowledge) here.  Diversity and Inherent Complexity The Unicode Codespace Codespace Allocation Scripts Usage Frequency Encodings UTF-8 UTF-16 Combining Marks Canonical Equivalence Normalization Forms Grapheme Clusters And Moreâ€¦ Diversity and Inherent Complexity As soon as you start to study Unicode, it becomes clear that it represents a large jump in complexity over character sets like ASCII that you may be more familiar with. Itâ€™s not just that Unicode contains a much larger number of characters, although thatâ€™s part of it. Unicode also has a great deal of internal structure, features, and special cases, making it much more than what one might expect a mere â€œcharacter setâ€ to be. Weâ€™ll see some of that later in this article.  When confronting all this complexity, especially as an engineer, itâ€™s hard not to find oneself asking, â€œWhy do we need all this? Is this really necessary? Couldnâ€™t it be simplified?â€  However, Unicode aims to faithfully represent the entire worldâ€™s writing systems. The Unicode Consortiumâ€™s stated goal is â€œenabling people around the world to use computers in any languageâ€. And as you might imagine, the diversity of written languages is immense! To date, Unicode supports 135 different scripts, covering some 1100 languages, and thereâ€™s still a long tail of over 100 unsupported scripts, both modern and historical, which people are still working to add.  Given this enormous diversity, itâ€™s inevitable that representing it is a complicated project. Unicode embraces that diversity, and accepts the complexity inherent in its mission to include all human writing systems. It doesnâ€™t make a lot of trade-offs in the name of simplification, and it makes exceptions to its own rules where necessary to further its mission.  Moreover, Unicode is committed not just to supporting texts in any single language, but also to letting multiple languages coexist within one textâ€”which introduces even more complexity.  Most programming languages have libraries available to handle the gory low-level details of text manipulation, but as a programmer, youâ€™ll still need to know about certain Unicode features in order to know when and how to apply them. It may take some time to wrap your head around it all, but donâ€™t be discouragedâ€”think about the billions of people for whom your software will be more accessible through supporting text in their language. Embrace the complexity!  The Unicode Codespace Letâ€™s start with some general orientation. The basic elements of Unicodeâ€”its â€œcharactersâ€, although that term isnâ€™t quite rightâ€”are called code points. Code points are identified by number, customarily written in hexadecimal with the prefix â€œU+â€, such as U+0041 â€œAâ€ latin capital letter a or U+03B8 â€œÎ¸â€ greek small letter theta. Each code point also has a short name, and quite a few other properties, specified in the Unicode Character Database.  The set of all possible code points is called the codespace. The Unicode codespace consists of 1,114,112 code points. However, only 128,237 of themâ€”about 12% of the codespaceâ€”are actually assigned, to date. Thereâ€™s plenty of room for growth! Unicode also reserves an additional 137,468 code points as â€œprivate useâ€ areas, which have no standardized meaning and are available for individual applications to define for their own purposes.  Codespace Allocation To get a feel for how the codespace is laid out, itâ€™s helpful to visualize it. Below is a map of the entire codespace, with one pixel per code point. Itâ€™s arranged in tiles for visual coherence; each small square is 16Ã—16 = 256 code points, and each large square is a â€œplaneâ€ of 65,536 code points. There are 17 planes altogether.  Map of the Unicode codespace (click to zoom)  White represents unassigned space. Blue is assigned code points, green is private-use areas, and the small red area is surrogates (more about those later). As you can see, the assigned code points are distributed somewhat sparsely, but concentrated in the first three planes.  Plane 0 is also known as the â€œBasic Multilingual Planeâ€, or BMP. The BMP contains essentially all the characters needed for modern text in any script, including Latin, Cyrillic, Greek, Han (Chinese), Japanese, Korean, Arabic, Hebrew, Devanagari (Indian), and many more.  (In the past, the codespace was just the BMP and no moreâ€”Unicode was originally conceived as a straightforward 16-bit encoding, with only 65,536 code points. It was expanded to its current size in 1996. However, the vast majority of code points in modern text belong to the BMP.)  Plane 1 contains historical scripts, such as Sumerian cuneiform and Egyptian hieroglyphs, as well as emoji and various other symbols. Plane 2 contains a large block of less-common and historical Han characters. The remaining planes are empty, except for a small number of rarely-used formatting characters in Plane 14; planes 15â€“16 are reserved entirely for private use.  Scripts Letâ€™s zoom in on the first three planes, since thatâ€™s where the action is:  Map of scripts in Unicode planes 0â€“2 (click to zoom)  This map color-codes the 135 different scripts in Unicode. You can see how Han () and Korean () take up most of the range of the BMP (the left large square). By contrast, all of the European, Middle Eastern, and South Asian scripts fit into the first row of the BMP in this diagram.  Many areas of the codespace are adapted or copied from earlier encodings. For example, the first 128 code points of Unicode are just a copy of ASCII. This has clear benefits for compatibilityâ€”itâ€™s easy to losslessly convert texts from smaller encodings into Unicode (and the other direction too, as long as no characters outside the smaller encoding are used).  Usage Frequency One more interesting way to visualize the codespace is to look at the distribution of usageâ€”in other words, how often each code point is actually used in real-world texts. Below is a heat map of planes 0â€“2 based on a large sample of text from Wikipedia and Twitter (all languages). Frequency increases from black (never seen) through red and yellow to white.  Heat map of code point usage frequency in Unicode planes 0â€“2 (click to zoom)  You can see that the vast majority of this text sample lies in the BMP, with only scattered usage of code points from planes 1â€“2. The biggest exception is emoji, which show up here as the several bright squares in the bottom row of plane 1.  Encodings Weâ€™ve seen that Unicode code points are abstractly identified by their index in the codespace, ranging from U+0000 to U+10FFFF. But how do code points get represented as bytes, in memory or in a file?  The most convenient, computer-friendliest (and programmer-friendliest) thing to do would be to just store the code point index as a 32-bit integer. This works, but it consumes 4 bytes per code point, which is sort of a lot. Using 32-bit ints for Unicode will cost you a bunch of extra storage, memory, and performance in bandwidth-bound scenarios, if you work with a lot of text.  Consequently, there are several more-compact encodings for Unicode. The 32-bit integer encoding is officially called UTF-32 (UTF = â€œUnicode Transformation Formatâ€), but itâ€™s rarely used for storage. At most, it comes up sometimes as a temporary internal representation, for examining or operating on the code points in a string.  Much more commonly, youâ€™ll see Unicode text encoded as either UTF-8 or UTF-16. These are both variable-length encodings, made up of 8-bit or 16-bit units, respectively. In these schemes, code points with smaller index values take up fewer bytes, which saves a lot of memory for typical texts. The trade-off is that processing UTF-8/16 texts is more programmatically involved, and likely slower.  UTF-8 In UTF-8, each code point is stored using 1 to 4 bytes, based on its index value.  UTF-8 uses a system of binary prefixes, in which the high bits of each byte mark whether itâ€™s a single byte, the beginning of a multi-byte sequence, or a continuation byte; the remaining bits, concatenated, give the code point index. This table shows how it works:  UTF-8 (binary)\\tCode point (binary)\\tRange 0xxxxxxx\\txxxxxxx\\tU+0000â€“U+007F 110xxxxx 10yyyyyy\\txxxxxyyyyyy\\tU+0080â€“U+07FF 1110xxxx 10yyyyyy 10zzzzzz\\txxxxyyyyyyzzzzzz\\tU+0800â€“U+FFFF 11110xxx 10yyyyyy 10zzzzzz 10wwwwww\\txxxyyyyyyzzzzzzwwwwww\\tU+10000â€“U+10FFFF A handy property of UTF-8 is that code points below 128 (ASCII characters) are encoded as single bytes, and all non-ASCII code points are encoded using sequences of bytes 128â€“255. This has a couple of nice consequences. First, any strings or files out there that are already in ASCII can also be interpreted as UTF-8 without any conversion. Second, lots of widely-used string programming idiomsâ€”such as null termination, or delimiters (newlines, tabs, commas, slashes, etc.)â€”will just work on UTF-8 strings. ASCII bytes never occur inside the encoding of non-ASCII code points, so searching byte-wise for a null terminator or a delimiter will do the right thing.  Thanks to this convenience, itâ€™s relatively simple to extend legacy ASCII programs and APIs to handle UTF-8 strings. UTF-8 is very widely used in the Unix/Linux and Web worlds, and many programmers argue UTF-8 should be the default encoding everywhere.  However, UTF-8 isnâ€™t a drop-in replacement for ASCII strings in all respects. For instance, code that iterates over the â€œcharactersâ€ in a string will need to decode UTF-8 and iterate over code points (or maybe grapheme clustersâ€”more about those later), not bytes. When you measure the â€œlengthâ€ of a string, youâ€™ll need to think about whether you want the length in bytes, the length in code points, the width of the text when rendered, or something else.  UTF-16 The other encoding that youâ€™re likely to encounter is UTF-16. It uses 16-bit words, with each code point stored as either 1 or 2 words.  Like UTF-8, we can express the UTF-16 encoding rules in the form of binary prefixes:  UTF-16 (binary)\\tCode point (binary)\\tRange xxxxxxxxxxxxxxxx\\txxxxxxxxxxxxxxxx\\tU+0000â€“U+FFFF 110110xxxxxxxxxx 110111yyyyyyyyyy\\txxxxxxxxxxyyyyyyyyyy + 0x10000\\tU+10000â€“U+10FFFF A more common way that people talk about UTF-16 encoding, though, is in terms of code points called â€œsurrogatesâ€. All the code points in the range U+D800â€“U+DFFFâ€”or in other words, the code points that match the binary prefixes 110110 and 110111 in the table aboveâ€”are reserved specifically for UTF-16 encoding, and donâ€™t represent any valid characters on their own. Theyâ€™re only meant to occur in the 2-word encoding pattern above, which is called a â€œsurrogate pairâ€. Surrogate code points are illegal in any other context! Theyâ€™re not allowed in UTF-8 or UTF-32 at all.  Historically, UTF-16 is a descendant of the original, pre-1996 versions of Unicode, in which there were only 65,536 code points. The original intention was that there would be no different â€œencodingsâ€; Unicode was supposed to be a straightforward 16-bit character set. Later, the codespace was expanded to make room for a long tail of less-common (but still important) Han characters, which the Unicode designers didnâ€™t originally plan for. Surrogates were then introduced, asâ€”to put it bluntlyâ€”a kludge, allowing 16-bit encodings to access the new code points.  Today, Javascript uses UTF-16 as its standard string representation: if you ask for the length of a string, or iterate over it, etc., the result will be in UTF-16 words, with any code points outside the BMP expressed as surrogate pairs. UTF-16 is also used by the Microsoft Win32 APIs; though Win32 supports either 8-bit or 16-bit strings, the 8-bit version unaccountably still doesnâ€™t support UTF-8â€”only legacy code-page encodings, like ANSI. This leaves UTF-16 as the only way to get proper Unicode support in Windows. (Update: in Win10 version 1903, they finally added UTF-8 support to the 8-bit APIs! ðŸ˜Š)  By the way, UTF-16â€™s words can be stored either little-endian or big-endian. Unicode has no opinion on that issue, though it does encourage the convention of putting U+FEFF zero width no-break space at the top of a UTF-16 file as a byte-order mark, to disambiguate the endianness. (If the file doesnâ€™t match the systemâ€™s endianness, the BOM will be decoded as U+FFFE, which isnâ€™t a valid code point.)  Combining Marks In the story so far, weâ€™ve been focusing on code points. But in Unicode, a â€œcharacterâ€ can be more complicated than just an individual code point!  Unicode includes a system for dynamically composing characters, by combining multiple code points together. This is used in various ways to gain flexibility without causing a huge combinatorial explosion in the number of code points.  In European languages, for example, this shows up in the application of diacritics to letters. Unicode supports a wide range of diacritics, including acute and grave accents, umlauts, cedillas, and many more. All these diacritics can be applied to any letter of any alphabetâ€”and in fact, multiple diacritics can be used on a single letter.  If Unicode tried to assign a distinct code point to every possible combination of letter and diacritics, things would rapidly get out of hand. Instead, the dynamic composition system enables you to construct the character you want, by starting with a base code point (the letter) and appending additional code points, called â€œcombining marksâ€, to specify the diacritics. When a text renderer sees a sequence like this in a string, it automatically stacks the diacritics over or under the base letter to create a composed character.  For example, the accented character â€œÃâ€ can be expressed as a string of two code points: U+0041 â€œAâ€ latin capital letter a plus U+0301 â€œâ—ŒÌâ€ combining acute accent. This string automatically gets rendered as a single character: â€œÃâ€.  Now, Unicode does also include many â€œprecomposedâ€ code points, each representing a letter with some combination of diacritics already applied, such as U+00C1 â€œÃâ€ latin capital letter a with acute or U+1EC7 â€œá»‡â€ latin small letter e with circumflex and dot below. I suspect these are mostly inherited from older encodings that were assimilated into Unicode, and kept around for compatibility. In practice, there are precomposed code points for most of the common letter-with-diacritic combinations in European-script languages, so they donâ€™t use dynamic composition that much in typical text.  Still, the system of combining marks does allow for an arbitrary number of diacritics to be stacked on any base character. The reductio-ad-absurdum of this is Zalgo text, which works by Í–ÍŸÍ…rÍžaá¹‹Ì«Ì Ì–ÍˆÌ—dÍ–Ì»Ì¹Ã³mÌªÍ™Í•Ì—ÌÄ¼Í‡Ì°Í“Ì³Ì«Ã½Í“Ì¥ÌŸÍ Ì•sÌ«tÌ«Ì±Í•Ì—Ì°Ì¼Ì˜ÍœaÌ¼Ì©Í–Í‡Ì ÍˆÌ£ÍcÌ™ÍkÌ–Ì±Ì¹ÍÍ˜iÌ¢nÌ¨ÌºÌÍ‡Í‡ÌŸÍ™Ä£Ì«Ì®ÍŽÌ»ÌŸÍ… Ì•nÌ¼ÌºÍˆÍžuÌ®Í™mÌºÌ­ÌŸÌ—ÍžeÌžÍ“Ì°Ì¤Í“Ì«rÌµoÌ–á¹·sÒ‰ÌªÍÌ­Ì¬ÌÌ¤ Ì®Í‰ÌÌžÌ—ÌŸÍ dÌ´ÌŸÌœÌ±Í•ÍšiÍ‡Ì«Ì¼Ì¯Ì­ÌœÍ¡á¸Í™Ì»Ì¼cÌ²Ì²Ì¹rÌ¨Ì Ì¹Ì£Ì°Ì¦iÌ±tÌ¤Ì»Ì¤ÍÍ™Ì˜Ì•iÌµÌœÌ­Ì¤Ì±ÍŽcÌµs Í˜oÌ±Ì²ÍˆÌ™Í–Í‡Ì²Í¢nÍ˜ ÌœÍˆeÌ¬Ì²Ì Ì©acÍ•ÌºÌ Í‰hÌ·Ìª ÌºÌ£Í–Ì±á¸»Ì«Ì¬ÌÌ¹á¸™Ì™ÌºÍ™Ì­Í“Ì²tÌžÌžÍ‡Ì²Í‰ÍtÌ·Í”ÌªÍ‰Ì²Ì»Ì Í™eÌ¦Ì»ÍˆÍ‰Í‡rÍ‡Ì­Ì­Ì¬Í–,Ì–Ì ÌœÍ™Í“Ì£Ì­sÌ˜Ì˜ÍˆoÌ±Ì°Ì¤Ì²Í… Ì›Ì¬ÌœÌ™tÌ¼Ì¦Í•Ì±Ì¹Í•Ì¥hÌ³Ì²ÍˆÍÍ…aÌ¦tÌ»Ì² Ì»ÌŸÌ­Ì¦Ì–tÌ›Ì°Ì©hÌ Í•Ì³ÌÌ«Í•eÍˆÌ¤Ì˜Í–ÌžÍ˜yÒ‰ÌÍ™ Ì·Í‰Í”Ì°Ì oÌžÌ°vÍˆÍˆÌ³Ì˜ÍœerÌ¶fÌ°ÍˆÍ”á¸»Í•Ì˜Ì«ÌºÌ²oÌ²Ì­Í™Í Í…wÌ±Ì³Ìº ÍœtÌ¸hÍ‡Ì­Í•Ì³ÍeÌ–Ì¯ÌŸÌ  ÍÌžÌœÍ”Ì©ÌªÍœÄ¼ÍŽÌªÌ²ÍšiÌÌ²Ì¹Ì™Ì©Ì¹nÌ¨Ì¦Ì©Ì–á¸™Ì¼Ì²Ì¼Í¢Í… Ì¬ÍsÌ¼ÍšÌ˜ÌžÍpÍ™Ì˜Ì»aÌ™cÒ‰Í‰ÌœÌ¤ÍˆÌ¯Ì–iÌ¥Í¡nÌ¦Ì Ì±ÍŸgÌ¸Ì—Ì»Ì¦Ì­Ì®ÌŸÍ… Ì³ÌªÌ Í–Ì³Ì¯Ì•aÌ«ÍœnÍdÍ¡ Ì£Ì¦Ì™Í…cÌªÌ—rÌ´Í™Ì®Ì¦Ì¹Ì³eÍ‡ÍšÌžÍ”Ì¹Ì«ÍŸaÌ™ÌºÌ™È›Í”ÍŽÌ˜Ì¹Í…eÌ¥Ì©Í aÍ–ÌªÌœÌ®Í™Ì¹nÌ¢Í‰Ì Í‡Í‰Í“Ì¦Ì¼ÌaÌ³Í–ÌªÌ¤Ì±pÌ–Í”Í”ÌŸÍ‡ÍŽÍ pÌ±ÍÌºÄ™Ì²ÍŽÍˆÌ°Ì²Ì¤Ì«aÌ¯ÍœrÌ¨Ì®Ì«Ì£Ì˜aÌ©Ì¯Í–nÌ¹Ì¦Ì°ÍŽÌ£ÌžÌžcÌ¨Ì¦Ì±Í”ÍŽÍÍ–eÌ¬Í“Í˜ Ì¤Ì°Ì©Í™Ì¤Ì¬Í™oÌµÌ¼Ì»Ì¬Ì»Í‡Ì®ÌªfÌ´ Ì¡Ì™Ì­Í“Í–ÌªÌ¤â€œÌ¸Í™Ì Ì¼cÌ³Ì—ÍœoÍÌ¼Í™Í”Ì®rÌžÌ«ÌºÌžÌ¥Ì¬ruÌºÌ»Ì¯Í‰Ì­Ì»Ì¯pÌ°Ì¥Í“Ì£Ì«Ì™Ì¤Í¢tÌ³ÍÌ³Ì–Í…iÌ¶ÍˆÌÍ™Ì¼Ì™Ì¹oÌ¡Í”nÌ™ÌºÌ¹Ì–Ì©ÍÍ…â€Ì¨Ì—Í–ÍšÌ©.Ì¯Í“  A few other places where dynamic character composition shows up in Unicode:  Vowel-pointing notation in Arabic and Hebrew. In these languages, words are normally spelled with some of their vowels left out. They then have diacritic notation to indicate the vowels (used in dictionaries, language-teaching materials, childrenâ€™s books, and such). These diacritics are expressed with combining marks.  A Hebrew example, with niqqud:\\t×Ö¶×ª ×“Ö·×œÖ°×ªÖ´Ö¼×™ ×”Öµ×–Ö´×™×– ×”Öµ× Ö´×™×¢Ö·, ×§Ö¶×˜Ö¶×‘ ×œÖ´×©Ö°××›Ö·Ö¼×ªÖ´Ö¼×™ ×™Ö¸×©××•Ö¹×“ Normal writing (no niqqud):\\t××ª ×“×œ×ª×™ ×”×–×™×– ×”× ×™×¢, ×§×˜×‘ ×œ×©×›×ª×™ ×™×©×•×“ Devanagari, the script used to write Hindi, Sanskrit, and many other South Asian languages, expresses certain vowels as combining marks attached to consonant letters. For example, â€œà¤¹â€ + â€œ\\u200bà¤¿â€ = â€œà¤¹à¤¿â€ (â€œhâ€ + â€œiâ€ = â€œhiâ€). Korean characters stand for syllables, but they are composed of letters called jamo that stand for the vowels and consonants in the syllable. While there are code points for precomposed Korean syllables, itâ€™s also possible to dynamically compose them by concatenating their jamo. For example, â€œá„’â€ + â€œá…¡â€ + â€œá†«â€ = â€œí•œâ€ (â€œhâ€ + â€œaâ€ + â€œnâ€ = â€œhanâ€). Canonical Equivalence In Unicode, precomposed characters exist alongside the dynamic composition system. A consequence of this is that there are multiple ways to express â€œthe sameâ€ stringâ€”different sequences of code points that result in the same user-perceived characters. For example, as we saw earlier, we can express the character â€œÃâ€ either as the single code point U+00C1, or as the string of two code points U+0041 U+0301.  Another source of ambiguity is the ordering of multiple diacritics in a single character. Diacritic order matters visually when two diacritics apply to the same side of the base character, e.g. both above: â€œÇ¡â€ (dot, then macron) is different from â€œÄÌ‡â€ (macron, then dot). However, when diacritics apply to different sides of the character, e.g. one above and one below, then the order doesnâ€™t affect rendering. Moreover, a character with multiple diacritics might have one of the diacritics precomposed and others expressed as combining marks.  For example, the Vietnamese letter â€œá»‡â€ can be expressed in five different ways:  Fully precomposed: U+1EC7 â€œá»‡â€ Partially precomposed: U+1EB9 â€œáº¹â€ + U+0302 â€œâ—ŒÌ‚â€ Partially precomposed: U+00EA â€œÃªâ€ + U+0323 â€œâ—ŒÌ£â€ Fully decomposed: U+0065 â€œeâ€ + U+0323 â€œâ—ŒÌ£â€ + U+0302 â€œâ—ŒÌ‚â€ Fully decomposed: U+0065 â€œeâ€ + U+0302 â€œâ—ŒÌ‚â€ + U+0323 â€œâ—ŒÌ£â€ Unicode refers to set of strings like this as â€œcanonically equivalentâ€. Canonically equivalent strings are supposed to be treated as identical for purposes of searching, sorting, rendering, text selection, and so on. This has implications for how you implement operations on text. For example, if an app has a â€œfind in fileâ€ operation and the user searches for â€œá»‡â€, it should, by default, find occurrences of any of the five versions of â€œá»‡â€ above!  Normalization Forms To address the problem of â€œhow to handle canonically equivalent stringsâ€, Unicode defines several normalization forms: ways of converting strings into a canonical form so that they can be compared code-point-by-code-point (or byte-by-byte).  The â€œNFDâ€ normalization form fully decomposes every character down to its component base and combining marks, taking apart any precomposed code points in the string. It also sorts the combining marks in each character according to their rendered position, so e.g. diacritics that go below the character come before the ones that go above the character. (It doesnâ€™t reorder diacritics in the same rendered position, since their order matters visually, as previously mentioned.)  The â€œNFCâ€ form, conversely, puts things back together into precomposed code points as much as possible. If an unusual combination of diacritics is called for, there may not be any precomposed code point for it, in which case NFC still precomposes what it can and leaves any remaining combining marks in place (again ordered by rendered position, as in NFD).  There are also forms called NFKD and NFKC. The â€œKâ€ here refers to compatibility decompositions, which cover characters that are â€œsimilarâ€ in some sense but not visually identical. However, Iâ€™m not going to cover that here.  Grapheme Clusters As weâ€™ve seen, Unicode contains various cases where a thing that a user thinks of as a single â€œcharacterâ€ might actually be made up of multiple code points under the hood. Unicode formalizes this using the notion of a grapheme cluster: a string of one or more code points that constitute a single â€œuser-perceived characterâ€.  UAX #29 defines the rules for what, precisely, qualifies as a grapheme cluster. Itâ€™s approximately â€œa base code point followed by any number of combining marksâ€, but the actual definition is a bit more complicated; it accounts for things like Korean jamo, and emoji ZWJ sequences.  The main thing grapheme clusters are used for is text editing: theyâ€™re often the most sensible unit for cursor placement and text selection boundaries. Using grapheme clusters for these purposes ensures that you canâ€™t accidentally chop off some diacritics when you copy-and-paste text, that left/right arrow keys always move the cursor by one visible character, and so on.  Another place where grapheme clusters are useful is in enforcing a string length limitâ€”say, on a database field. While the true, underlying limit might be something like the byte length of the string in UTF-8, you wouldnâ€™t want to enforce that by just truncating bytes. At a minimum, youâ€™d want to â€œround downâ€ to the nearest code point boundary; but even better, round down to the nearest grapheme cluster boundary. Otherwise, you might be corrupting the last character by cutting off a diacritic, or interrupting a jamo sequence or ZWJ sequence.  And Moreâ€¦ Thereâ€™s much more that could be said about Unicode from a programmerâ€™s perspective! I havenâ€™t gotten into such fun topics as case mapping, collation, compatibility decompositions and confusables, Unicode-aware regexes, or bidirectional text. Nor have I said anything yet about implementation issuesâ€”how to efficiently store and look-up data about the sparsely-assigned code points, or how to optimize UTF-8 decoding, string comparison, or NFC normalization. Perhaps Iâ€™ll return to some of those things in future posts.  Unicode is a fascinating and complex system. It has a many-to-one mapping between bytes and code points, and on top of that a many-to-one (or, under some circumstances, many-to-many) mapping between code points and â€œcharactersâ€. It has oddball special cases in every corner. But no one ever claimed that representing all written languages was going to be easy, and itâ€™s clear that weâ€™re never going back to the bad old days of a patchwork of incompatible encodings.  Further reading:  The Unicode Standard UTF-8 Everywhere Manifesto Dark corners of Unicode by Eevee ICU (International Components for Unicode)â€”C/C++/Java libraries implementing many Unicode algorithms and related things Python 3 Unicode Howto Google Noto Fontsâ€”set of fonts intended to cover all assigned code points\"\"\"\n",
        "tokens = text.encode(\"utf-8\") # raw bytes\n",
        "tokens = list(map(int, tokens)) # convert to a list of integers in range 0..255 for convenience\n",
        "print('---')\n",
        "print(tokens)\n",
        "print(\"length:\", len(tokens))\n",
        "print(\"max:\"   , max(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRGjJLKZX2_v",
        "outputId": "b1df7ff4-3d36-49ef-e74e-4aa643bed323"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "[65, 32, 80, 114, 111, 103, 114, 97, 109, 109, 101, 114, 226, 128, 153, 115, 32, 73, 110, 116, 114, 111, 100, 117, 99, 116, 105, 111, 110, 32, 116, 111, 32, 85, 110, 105, 99, 111, 100, 101, 32, 77, 97, 114, 99, 104, 32, 51, 44, 32, 50, 48, 49, 55, 32, 194, 183, 32, 67, 111, 100, 105, 110, 103, 32, 194, 183, 32, 50, 50, 32, 67, 111, 109, 109, 101, 110, 116, 115, 32, 32, 239, 188, 181, 239, 189, 142, 239, 189, 137, 239, 189, 131, 239, 189, 143, 239, 189, 132, 239, 189, 133, 33, 32, 240, 159, 133, 164, 240, 159, 133, 157, 240, 159, 133, 152, 240, 159, 133, 146, 240, 159, 133, 158, 240, 159, 133, 147, 240, 159, 133, 148, 226, 128, 189, 32, 240, 159, 135, 186, 226, 128, 140, 240, 159, 135, 179, 226, 128, 140, 240, 159, 135, 174, 226, 128, 140, 240, 159, 135, 168, 226, 128, 140, 240, 159, 135, 180, 226, 128, 140, 240, 159, 135, 169, 226, 128, 140, 240, 159, 135, 170, 33, 32, 240, 159, 152, 132, 32, 84, 104, 101, 32, 118, 101, 114, 121, 32, 110, 97, 109, 101, 32, 115, 116, 114, 105, 107, 101, 115, 32, 102, 101, 97, 114, 32, 97, 110, 100, 32, 97, 119, 101, 32, 105, 110, 116, 111, 32, 116, 104, 101, 32, 104, 101, 97, 114, 116, 115, 32, 111, 102, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 119, 111, 114, 108, 100, 119, 105, 100, 101, 46, 32, 87, 101, 32, 97, 108, 108, 32, 107, 110, 111, 119, 32, 119, 101, 32, 111, 117, 103, 104, 116, 32, 116, 111, 32, 226, 128, 156, 115, 117, 112, 112, 111, 114, 116, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 157, 32, 105, 110, 32, 111, 117, 114, 32, 115, 111, 102, 116, 119, 97, 114, 101, 32, 40, 119, 104, 97, 116, 101, 118, 101, 114, 32, 116, 104, 97, 116, 32, 109, 101, 97, 110, 115, 226, 128, 148, 108, 105, 107, 101, 32, 117, 115, 105, 110, 103, 32, 119, 99, 104, 97, 114, 95, 116, 32, 102, 111, 114, 32, 97, 108, 108, 32, 116, 104, 101, 32, 115, 116, 114, 105, 110, 103, 115, 44, 32, 114, 105, 103, 104, 116, 63, 41, 46, 32, 66, 117, 116, 32, 85, 110, 105, 99, 111, 100, 101, 32, 99, 97, 110, 32, 98, 101, 32, 97, 98, 115, 116, 114, 117, 115, 101, 44, 32, 97, 110, 100, 32, 100, 105, 118, 105, 110, 103, 32, 105, 110, 116, 111, 32, 116, 104, 101, 32, 116, 104, 111, 117, 115, 97, 110, 100, 45, 112, 97, 103, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 83, 116, 97, 110, 100, 97, 114, 100, 32, 112, 108, 117, 115, 32, 105, 116, 115, 32, 100, 111, 122, 101, 110, 115, 32, 111, 102, 32, 115, 117, 112, 112, 108, 101, 109, 101, 110, 116, 97, 114, 121, 32, 97, 110, 110, 101, 120, 101, 115, 44, 32, 114, 101, 112, 111, 114, 116, 115, 44, 32, 97, 110, 100, 32, 110, 111, 116, 101, 115, 32, 99, 97, 110, 32, 98, 101, 32, 109, 111, 114, 101, 32, 116, 104, 97, 110, 32, 97, 32, 108, 105, 116, 116, 108, 101, 32, 105, 110, 116, 105, 109, 105, 100, 97, 116, 105, 110, 103, 46, 32, 73, 32, 100, 111, 110, 226, 128, 153, 116, 32, 98, 108, 97, 109, 101, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 102, 111, 114, 32, 115, 116, 105, 108, 108, 32, 102, 105, 110, 100, 105, 110, 103, 32, 116, 104, 101, 32, 119, 104, 111, 108, 101, 32, 116, 104, 105, 110, 103, 32, 109, 121, 115, 116, 101, 114, 105, 111, 117, 115, 44, 32, 101, 118, 101, 110, 32, 51, 48, 32, 121, 101, 97, 114, 115, 32, 97, 102, 116, 101, 114, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 153, 115, 32, 105, 110, 99, 101, 112, 116, 105, 111, 110, 46, 32, 32, 65, 32, 102, 101, 119, 32, 109, 111, 110, 116, 104, 115, 32, 97, 103, 111, 44, 32, 73, 32, 103, 111, 116, 32, 105, 110, 116, 101, 114, 101, 115, 116, 101, 100, 32, 105, 110, 32, 85, 110, 105, 99, 111, 100, 101, 32, 97, 110, 100, 32, 100, 101, 99, 105, 100, 101, 100, 32, 116, 111, 32, 115, 112, 101, 110, 100, 32, 115, 111, 109, 101, 32, 116, 105, 109, 101, 32, 108, 101, 97, 114, 110, 105, 110, 103, 32, 109, 111, 114, 101, 32, 97, 98, 111, 117, 116, 32, 105, 116, 32, 105, 110, 32, 100, 101, 116, 97, 105, 108, 46, 32, 73, 110, 32, 116, 104, 105, 115, 32, 97, 114, 116, 105, 99, 108, 101, 44, 32, 73, 226, 128, 153, 108, 108, 32, 103, 105, 118, 101, 32, 97, 110, 32, 105, 110, 116, 114, 111, 100, 117, 99, 116, 105, 111, 110, 32, 116, 111, 32, 105, 116, 32, 102, 114, 111, 109, 32, 97, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 226, 128, 153, 115, 32, 112, 111, 105, 110, 116, 32, 111, 102, 32, 118, 105, 101, 119, 46, 32, 32, 73, 226, 128, 153, 109, 32, 103, 111, 105, 110, 103, 32, 116, 111, 32, 102, 111, 99, 117, 115, 32, 111, 110, 32, 116, 104, 101, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 115, 101, 116, 32, 97, 110, 100, 32, 119, 104, 97, 116, 226, 128, 153, 115, 32, 105, 110, 118, 111, 108, 118, 101, 100, 32, 105, 110, 32, 119, 111, 114, 107, 105, 110, 103, 32, 119, 105, 116, 104, 32, 115, 116, 114, 105, 110, 103, 115, 32, 97, 110, 100, 32, 102, 105, 108, 101, 115, 32, 111, 102, 32, 85, 110, 105, 99, 111, 100, 101, 32, 116, 101, 120, 116, 46, 32, 72, 111, 119, 101, 118, 101, 114, 44, 32, 105, 110, 32, 116, 104, 105, 115, 32, 97, 114, 116, 105, 99, 108, 101, 32, 73, 226, 128, 153, 109, 32, 110, 111, 116, 32, 103, 111, 105, 110, 103, 32, 116, 111, 32, 116, 97, 108, 107, 32, 97, 98, 111, 117, 116, 32, 102, 111, 110, 116, 115, 44, 32, 116, 101, 120, 116, 32, 108, 97, 121, 111, 117, 116, 47, 115, 104, 97, 112, 105, 110, 103, 47, 114, 101, 110, 100, 101, 114, 105, 110, 103, 44, 32, 111, 114, 32, 108, 111, 99, 97, 108, 105, 122, 97, 116, 105, 111, 110, 32, 105, 110, 32, 100, 101, 116, 97, 105, 108, 226, 128, 148, 116, 104, 111, 115, 101, 32, 97, 114, 101, 32, 115, 101, 112, 97, 114, 97, 116, 101, 32, 105, 115, 115, 117, 101, 115, 44, 32, 98, 101, 121, 111, 110, 100, 32, 109, 121, 32, 115, 99, 111, 112, 101, 32, 40, 97, 110, 100, 32, 107, 110, 111, 119, 108, 101, 100, 103, 101, 41, 32, 104, 101, 114, 101, 46, 32, 32, 68, 105, 118, 101, 114, 115, 105, 116, 121, 32, 97, 110, 100, 32, 73, 110, 104, 101, 114, 101, 110, 116, 32, 67, 111, 109, 112, 108, 101, 120, 105, 116, 121, 32, 84, 104, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 67, 111, 100, 101, 115, 112, 97, 99, 101, 32, 67, 111, 100, 101, 115, 112, 97, 99, 101, 32, 65, 108, 108, 111, 99, 97, 116, 105, 111, 110, 32, 83, 99, 114, 105, 112, 116, 115, 32, 85, 115, 97, 103, 101, 32, 70, 114, 101, 113, 117, 101, 110, 99, 121, 32, 69, 110, 99, 111, 100, 105, 110, 103, 115, 32, 85, 84, 70, 45, 56, 32, 85, 84, 70, 45, 49, 54, 32, 67, 111, 109, 98, 105, 110, 105, 110, 103, 32, 77, 97, 114, 107, 115, 32, 67, 97, 110, 111, 110, 105, 99, 97, 108, 32, 69, 113, 117, 105, 118, 97, 108, 101, 110, 99, 101, 32, 78, 111, 114, 109, 97, 108, 105, 122, 97, 116, 105, 111, 110, 32, 70, 111, 114, 109, 115, 32, 71, 114, 97, 112, 104, 101, 109, 101, 32, 67, 108, 117, 115, 116, 101, 114, 115, 32, 65, 110, 100, 32, 77, 111, 114, 101, 226, 128, 166, 32, 68, 105, 118, 101, 114, 115, 105, 116, 121, 32, 97, 110, 100, 32, 73, 110, 104, 101, 114, 101, 110, 116, 32, 67, 111, 109, 112, 108, 101, 120, 105, 116, 121, 32, 65, 115, 32, 115, 111, 111, 110, 32, 97, 115, 32, 121, 111, 117, 32, 115, 116, 97, 114, 116, 32, 116, 111, 32, 115, 116, 117, 100, 121, 32, 85, 110, 105, 99, 111, 100, 101, 44, 32, 105, 116, 32, 98, 101, 99, 111, 109, 101, 115, 32, 99, 108, 101, 97, 114, 32, 116, 104, 97, 116, 32, 105, 116, 32, 114, 101, 112, 114, 101, 115, 101, 110, 116, 115, 32, 97, 32, 108, 97, 114, 103, 101, 32, 106, 117, 109, 112, 32, 105, 110, 32, 99, 111, 109, 112, 108, 101, 120, 105, 116, 121, 32, 111, 118, 101, 114, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 115, 101, 116, 115, 32, 108, 105, 107, 101, 32, 65, 83, 67, 73, 73, 32, 116, 104, 97, 116, 32, 121, 111, 117, 32, 109, 97, 121, 32, 98, 101, 32, 109, 111, 114, 101, 32, 102, 97, 109, 105, 108, 105, 97, 114, 32, 119, 105, 116, 104, 46, 32, 73, 116, 226, 128, 153, 115, 32, 110, 111, 116, 32, 106, 117, 115, 116, 32, 116, 104, 97, 116, 32, 85, 110, 105, 99, 111, 100, 101, 32, 99, 111, 110, 116, 97, 105, 110, 115, 32, 97, 32, 109, 117, 99, 104, 32, 108, 97, 114, 103, 101, 114, 32, 110, 117, 109, 98, 101, 114, 32, 111, 102, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 44, 32, 97, 108, 116, 104, 111, 117, 103, 104, 32, 116, 104, 97, 116, 226, 128, 153, 115, 32, 112, 97, 114, 116, 32, 111, 102, 32, 105, 116, 46, 32, 85, 110, 105, 99, 111, 100, 101, 32, 97, 108, 115, 111, 32, 104, 97, 115, 32, 97, 32, 103, 114, 101, 97, 116, 32, 100, 101, 97, 108, 32, 111, 102, 32, 105, 110, 116, 101, 114, 110, 97, 108, 32, 115, 116, 114, 117, 99, 116, 117, 114, 101, 44, 32, 102, 101, 97, 116, 117, 114, 101, 115, 44, 32, 97, 110, 100, 32, 115, 112, 101, 99, 105, 97, 108, 32, 99, 97, 115, 101, 115, 44, 32, 109, 97, 107, 105, 110, 103, 32, 105, 116, 32, 109, 117, 99, 104, 32, 109, 111, 114, 101, 32, 116, 104, 97, 110, 32, 119, 104, 97, 116, 32, 111, 110, 101, 32, 109, 105, 103, 104, 116, 32, 101, 120, 112, 101, 99, 116, 32, 97, 32, 109, 101, 114, 101, 32, 226, 128, 156, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 115, 101, 116, 226, 128, 157, 32, 116, 111, 32, 98, 101, 46, 32, 87, 101, 226, 128, 153, 108, 108, 32, 115, 101, 101, 32, 115, 111, 109, 101, 32, 111, 102, 32, 116, 104, 97, 116, 32, 108, 97, 116, 101, 114, 32, 105, 110, 32, 116, 104, 105, 115, 32, 97, 114, 116, 105, 99, 108, 101, 46, 32, 32, 87, 104, 101, 110, 32, 99, 111, 110, 102, 114, 111, 110, 116, 105, 110, 103, 32, 97, 108, 108, 32, 116, 104, 105, 115, 32, 99, 111, 109, 112, 108, 101, 120, 105, 116, 121, 44, 32, 101, 115, 112, 101, 99, 105, 97, 108, 108, 121, 32, 97, 115, 32, 97, 110, 32, 101, 110, 103, 105, 110, 101, 101, 114, 44, 32, 105, 116, 226, 128, 153, 115, 32, 104, 97, 114, 100, 32, 110, 111, 116, 32, 116, 111, 32, 102, 105, 110, 100, 32, 111, 110, 101, 115, 101, 108, 102, 32, 97, 115, 107, 105, 110, 103, 44, 32, 226, 128, 156, 87, 104, 121, 32, 100, 111, 32, 119, 101, 32, 110, 101, 101, 100, 32, 97, 108, 108, 32, 116, 104, 105, 115, 63, 32, 73, 115, 32, 116, 104, 105, 115, 32, 114, 101, 97, 108, 108, 121, 32, 110, 101, 99, 101, 115, 115, 97, 114, 121, 63, 32, 67, 111, 117, 108, 100, 110, 226, 128, 153, 116, 32, 105, 116, 32, 98, 101, 32, 115, 105, 109, 112, 108, 105, 102, 105, 101, 100, 63, 226, 128, 157, 32, 32, 72, 111, 119, 101, 118, 101, 114, 44, 32, 85, 110, 105, 99, 111, 100, 101, 32, 97, 105, 109, 115, 32, 116, 111, 32, 102, 97, 105, 116, 104, 102, 117, 108, 108, 121, 32, 114, 101, 112, 114, 101, 115, 101, 110, 116, 32, 116, 104, 101, 32, 101, 110, 116, 105, 114, 101, 32, 119, 111, 114, 108, 100, 226, 128, 153, 115, 32, 119, 114, 105, 116, 105, 110, 103, 32, 115, 121, 115, 116, 101, 109, 115, 46, 32, 84, 104, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 67, 111, 110, 115, 111, 114, 116, 105, 117, 109, 226, 128, 153, 115, 32, 115, 116, 97, 116, 101, 100, 32, 103, 111, 97, 108, 32, 105, 115, 32, 226, 128, 156, 101, 110, 97, 98, 108, 105, 110, 103, 32, 112, 101, 111, 112, 108, 101, 32, 97, 114, 111, 117, 110, 100, 32, 116, 104, 101, 32, 119, 111, 114, 108, 100, 32, 116, 111, 32, 117, 115, 101, 32, 99, 111, 109, 112, 117, 116, 101, 114, 115, 32, 105, 110, 32, 97, 110, 121, 32, 108, 97, 110, 103, 117, 97, 103, 101, 226, 128, 157, 46, 32, 65, 110, 100, 32, 97, 115, 32, 121, 111, 117, 32, 109, 105, 103, 104, 116, 32, 105, 109, 97, 103, 105, 110, 101, 44, 32, 116, 104, 101, 32, 100, 105, 118, 101, 114, 115, 105, 116, 121, 32, 111, 102, 32, 119, 114, 105, 116, 116, 101, 110, 32, 108, 97, 110, 103, 117, 97, 103, 101, 115, 32, 105, 115, 32, 105, 109, 109, 101, 110, 115, 101, 33, 32, 84, 111, 32, 100, 97, 116, 101, 44, 32, 85, 110, 105, 99, 111, 100, 101, 32, 115, 117, 112, 112, 111, 114, 116, 115, 32, 49, 51, 53, 32, 100, 105, 102, 102, 101, 114, 101, 110, 116, 32, 115, 99, 114, 105, 112, 116, 115, 44, 32, 99, 111, 118, 101, 114, 105, 110, 103, 32, 115, 111, 109, 101, 32, 49, 49, 48, 48, 32, 108, 97, 110, 103, 117, 97, 103, 101, 115, 44, 32, 97, 110, 100, 32, 116, 104, 101, 114, 101, 226, 128, 153, 115, 32, 115, 116, 105, 108, 108, 32, 97, 32, 108, 111, 110, 103, 32, 116, 97, 105, 108, 32, 111, 102, 32, 111, 118, 101, 114, 32, 49, 48, 48, 32, 117, 110, 115, 117, 112, 112, 111, 114, 116, 101, 100, 32, 115, 99, 114, 105, 112, 116, 115, 44, 32, 98, 111, 116, 104, 32, 109, 111, 100, 101, 114, 110, 32, 97, 110, 100, 32, 104, 105, 115, 116, 111, 114, 105, 99, 97, 108, 44, 32, 119, 104, 105, 99, 104, 32, 112, 101, 111, 112, 108, 101, 32, 97, 114, 101, 32, 115, 116, 105, 108, 108, 32, 119, 111, 114, 107, 105, 110, 103, 32, 116, 111, 32, 97, 100, 100, 46, 32, 32, 71, 105, 118, 101, 110, 32, 116, 104, 105, 115, 32, 101, 110, 111, 114, 109, 111, 117, 115, 32, 100, 105, 118, 101, 114, 115, 105, 116, 121, 44, 32, 105, 116, 226, 128, 153, 115, 32, 105, 110, 101, 118, 105, 116, 97, 98, 108, 101, 32, 116, 104, 97, 116, 32, 114, 101, 112, 114, 101, 115, 101, 110, 116, 105, 110, 103, 32, 105, 116, 32, 105, 115, 32, 97, 32, 99, 111, 109, 112, 108, 105, 99, 97, 116, 101, 100, 32, 112, 114, 111, 106, 101, 99, 116, 46, 32, 85, 110, 105, 99, 111, 100, 101, 32, 101, 109, 98, 114, 97, 99, 101, 115, 32, 116, 104, 97, 116, 32, 100, 105, 118, 101, 114, 115, 105, 116, 121, 44, 32, 97, 110, 100, 32, 97, 99, 99, 101, 112, 116, 115, 32, 116, 104, 101, 32, 99, 111, 109, 112, 108, 101, 120, 105, 116, 121, 32, 105, 110, 104, 101, 114, 101, 110, 116, 32, 105, 110, 32, 105, 116, 115, 32, 109, 105, 115, 115, 105, 111, 110, 32, 116, 111, 32, 105, 110, 99, 108, 117, 100, 101, 32, 97, 108, 108, 32, 104, 117, 109, 97, 110, 32, 119, 114, 105, 116, 105, 110, 103, 32, 115, 121, 115, 116, 101, 109, 115, 46, 32, 73, 116, 32, 100, 111, 101, 115, 110, 226, 128, 153, 116, 32, 109, 97, 107, 101, 32, 97, 32, 108, 111, 116, 32, 111, 102, 32, 116, 114, 97, 100, 101, 45, 111, 102, 102, 115, 32, 105, 110, 32, 116, 104, 101, 32, 110, 97, 109, 101, 32, 111, 102, 32, 115, 105, 109, 112, 108, 105, 102, 105, 99, 97, 116, 105, 111, 110, 44, 32, 97, 110, 100, 32, 105, 116, 32, 109, 97, 107, 101, 115, 32, 101, 120, 99, 101, 112, 116, 105, 111, 110, 115, 32, 116, 111, 32, 105, 116, 115, 32, 111, 119, 110, 32, 114, 117, 108, 101, 115, 32, 119, 104, 101, 114, 101, 32, 110, 101, 99, 101, 115, 115, 97, 114, 121, 32, 116, 111, 32, 102, 117, 114, 116, 104, 101, 114, 32, 105, 116, 115, 32, 109, 105, 115, 115, 105, 111, 110, 46, 32, 32, 77, 111, 114, 101, 111, 118, 101, 114, 44, 32, 85, 110, 105, 99, 111, 100, 101, 32, 105, 115, 32, 99, 111, 109, 109, 105, 116, 116, 101, 100, 32, 110, 111, 116, 32, 106, 117, 115, 116, 32, 116, 111, 32, 115, 117, 112, 112, 111, 114, 116, 105, 110, 103, 32, 116, 101, 120, 116, 115, 32, 105, 110, 32, 97, 110, 121, 32, 115, 105, 110, 103, 108, 101, 32, 108, 97, 110, 103, 117, 97, 103, 101, 44, 32, 98, 117, 116, 32, 97, 108, 115, 111, 32, 116, 111, 32, 108, 101, 116, 116, 105, 110, 103, 32, 109, 117, 108, 116, 105, 112, 108, 101, 32, 108, 97, 110, 103, 117, 97, 103, 101, 115, 32, 99, 111, 101, 120, 105, 115, 116, 32, 119, 105, 116, 104, 105, 110, 32, 111, 110, 101, 32, 116, 101, 120, 116, 226, 128, 148, 119, 104, 105, 99, 104, 32, 105, 110, 116, 114, 111, 100, 117, 99, 101, 115, 32, 101, 118, 101, 110, 32, 109, 111, 114, 101, 32, 99, 111, 109, 112, 108, 101, 120, 105, 116, 121, 46, 32, 32, 77, 111, 115, 116, 32, 112, 114, 111, 103, 114, 97, 109, 109, 105, 110, 103, 32, 108, 97, 110, 103, 117, 97, 103, 101, 115, 32, 104, 97, 118, 101, 32, 108, 105, 98, 114, 97, 114, 105, 101, 115, 32, 97, 118, 97, 105, 108, 97, 98, 108, 101, 32, 116, 111, 32, 104, 97, 110, 100, 108, 101, 32, 116, 104, 101, 32, 103, 111, 114, 121, 32, 108, 111, 119, 45, 108, 101, 118, 101, 108, 32, 100, 101, 116, 97, 105, 108, 115, 32, 111, 102, 32, 116, 101, 120, 116, 32, 109, 97, 110, 105, 112, 117, 108, 97, 116, 105, 111, 110, 44, 32, 98, 117, 116, 32, 97, 115, 32, 97, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 44, 32, 121, 111, 117, 226, 128, 153, 108, 108, 32, 115, 116, 105, 108, 108, 32, 110, 101, 101, 100, 32, 116, 111, 32, 107, 110, 111, 119, 32, 97, 98, 111, 117, 116, 32, 99, 101, 114, 116, 97, 105, 110, 32, 85, 110, 105, 99, 111, 100, 101, 32, 102, 101, 97, 116, 117, 114, 101, 115, 32, 105, 110, 32, 111, 114, 100, 101, 114, 32, 116, 111, 32, 107, 110, 111, 119, 32, 119, 104, 101, 110, 32, 97, 110, 100, 32, 104, 111, 119, 32, 116, 111, 32, 97, 112, 112, 108, 121, 32, 116, 104, 101, 109, 46, 32, 73, 116, 32, 109, 97, 121, 32, 116, 97, 107, 101, 32, 115, 111, 109, 101, 32, 116, 105, 109, 101, 32, 116, 111, 32, 119, 114, 97, 112, 32, 121, 111, 117, 114, 32, 104, 101, 97, 100, 32, 97, 114, 111, 117, 110, 100, 32, 105, 116, 32, 97, 108, 108, 44, 32, 98, 117, 116, 32, 100, 111, 110, 226, 128, 153, 116, 32, 98, 101, 32, 100, 105, 115, 99, 111, 117, 114, 97, 103, 101, 100, 226, 128, 148, 116, 104, 105, 110, 107, 32, 97, 98, 111, 117, 116, 32, 116, 104, 101, 32, 98, 105, 108, 108, 105, 111, 110, 115, 32, 111, 102, 32, 112, 101, 111, 112, 108, 101, 32, 102, 111, 114, 32, 119, 104, 111, 109, 32, 121, 111, 117, 114, 32, 115, 111, 102, 116, 119, 97, 114, 101, 32, 119, 105, 108, 108, 32, 98, 101, 32, 109, 111, 114, 101, 32, 97, 99, 99, 101, 115, 115, 105, 98, 108, 101, 32, 116, 104, 114, 111, 117, 103, 104, 32, 115, 117, 112, 112, 111, 114, 116, 105, 110, 103, 32, 116, 101, 120, 116, 32, 105, 110, 32, 116, 104, 101, 105, 114, 32, 108, 97, 110, 103, 117, 97, 103, 101, 46, 32, 69, 109, 98, 114, 97, 99, 101, 32, 116, 104, 101, 32, 99, 111, 109, 112, 108, 101, 120, 105, 116, 121, 33, 32, 32, 84, 104, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 67, 111, 100, 101, 115, 112, 97, 99, 101, 32, 76, 101, 116, 226, 128, 153, 115, 32, 115, 116, 97, 114, 116, 32, 119, 105, 116, 104, 32, 115, 111, 109, 101, 32, 103, 101, 110, 101, 114, 97, 108, 32, 111, 114, 105, 101, 110, 116, 97, 116, 105, 111, 110, 46, 32, 84, 104, 101, 32, 98, 97, 115, 105, 99, 32, 101, 108, 101, 109, 101, 110, 116, 115, 32, 111, 102, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 148, 105, 116, 115, 32, 226, 128, 156, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 226, 128, 157, 44, 32, 97, 108, 116, 104, 111, 117, 103, 104, 32, 116, 104, 97, 116, 32, 116, 101, 114, 109, 32, 105, 115, 110, 226, 128, 153, 116, 32, 113, 117, 105, 116, 101, 32, 114, 105, 103, 104, 116, 226, 128, 148, 97, 114, 101, 32, 99, 97, 108, 108, 101, 100, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 46, 32, 67, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 97, 114, 101, 32, 105, 100, 101, 110, 116, 105, 102, 105, 101, 100, 32, 98, 121, 32, 110, 117, 109, 98, 101, 114, 44, 32, 99, 117, 115, 116, 111, 109, 97, 114, 105, 108, 121, 32, 119, 114, 105, 116, 116, 101, 110, 32, 105, 110, 32, 104, 101, 120, 97, 100, 101, 99, 105, 109, 97, 108, 32, 119, 105, 116, 104, 32, 116, 104, 101, 32, 112, 114, 101, 102, 105, 120, 32, 226, 128, 156, 85, 43, 226, 128, 157, 44, 32, 115, 117, 99, 104, 32, 97, 115, 32, 85, 43, 48, 48, 52, 49, 32, 226, 128, 156, 65, 226, 128, 157, 32, 108, 97, 116, 105, 110, 32, 99, 97, 112, 105, 116, 97, 108, 32, 108, 101, 116, 116, 101, 114, 32, 97, 32, 111, 114, 32, 85, 43, 48, 51, 66, 56, 32, 226, 128, 156, 206, 184, 226, 128, 157, 32, 103, 114, 101, 101, 107, 32, 115, 109, 97, 108, 108, 32, 108, 101, 116, 116, 101, 114, 32, 116, 104, 101, 116, 97, 46, 32, 69, 97, 99, 104, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 97, 108, 115, 111, 32, 104, 97, 115, 32, 97, 32, 115, 104, 111, 114, 116, 32, 110, 97, 109, 101, 44, 32, 97, 110, 100, 32, 113, 117, 105, 116, 101, 32, 97, 32, 102, 101, 119, 32, 111, 116, 104, 101, 114, 32, 112, 114, 111, 112, 101, 114, 116, 105, 101, 115, 44, 32, 115, 112, 101, 99, 105, 102, 105, 101, 100, 32, 105, 110, 32, 116, 104, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 67, 104, 97, 114, 97, 99, 116, 101, 114, 32, 68, 97, 116, 97, 98, 97, 115, 101, 46, 32, 32, 84, 104, 101, 32, 115, 101, 116, 32, 111, 102, 32, 97, 108, 108, 32, 112, 111, 115, 115, 105, 98, 108, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 105, 115, 32, 99, 97, 108, 108, 101, 100, 32, 116, 104, 101, 32, 99, 111, 100, 101, 115, 112, 97, 99, 101, 46, 32, 84, 104, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 99, 111, 100, 101, 115, 112, 97, 99, 101, 32, 99, 111, 110, 115, 105, 115, 116, 115, 32, 111, 102, 32, 49, 44, 49, 49, 52, 44, 49, 49, 50, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 46, 32, 72, 111, 119, 101, 118, 101, 114, 44, 32, 111, 110, 108, 121, 32, 49, 50, 56, 44, 50, 51, 55, 32, 111, 102, 32, 116, 104, 101, 109, 226, 128, 148, 97, 98, 111, 117, 116, 32, 49, 50, 37, 32, 111, 102, 32, 116, 104, 101, 32, 99, 111, 100, 101, 115, 112, 97, 99, 101, 226, 128, 148, 97, 114, 101, 32, 97, 99, 116, 117, 97, 108, 108, 121, 32, 97, 115, 115, 105, 103, 110, 101, 100, 44, 32, 116, 111, 32, 100, 97, 116, 101, 46, 32, 84, 104, 101, 114, 101, 226, 128, 153, 115, 32, 112, 108, 101, 110, 116, 121, 32, 111, 102, 32, 114, 111, 111, 109, 32, 102, 111, 114, 32, 103, 114, 111, 119, 116, 104, 33, 32, 85, 110, 105, 99, 111, 100, 101, 32, 97, 108, 115, 111, 32, 114, 101, 115, 101, 114, 118, 101, 115, 32, 97, 110, 32, 97, 100, 100, 105, 116, 105, 111, 110, 97, 108, 32, 49, 51, 55, 44, 52, 54, 56, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 97, 115, 32, 226, 128, 156, 112, 114, 105, 118, 97, 116, 101, 32, 117, 115, 101, 226, 128, 157, 32, 97, 114, 101, 97, 115, 44, 32, 119, 104, 105, 99, 104, 32, 104, 97, 118, 101, 32, 110, 111, 32, 115, 116, 97, 110, 100, 97, 114, 100, 105, 122, 101, 100, 32, 109, 101, 97, 110, 105, 110, 103, 32, 97, 110, 100, 32, 97, 114, 101, 32, 97, 118, 97, 105, 108, 97, 98, 108, 101, 32, 102, 111, 114, 32, 105, 110, 100, 105, 118, 105, 100, 117, 97, 108, 32, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 115, 32, 116, 111, 32, 100, 101, 102, 105, 110, 101, 32, 102, 111, 114, 32, 116, 104, 101, 105, 114, 32, 111, 119, 110, 32, 112, 117, 114, 112, 111, 115, 101, 115, 46, 32, 32, 67, 111, 100, 101, 115, 112, 97, 99, 101, 32, 65, 108, 108, 111, 99, 97, 116, 105, 111, 110, 32, 84, 111, 32, 103, 101, 116, 32, 97, 32, 102, 101, 101, 108, 32, 102, 111, 114, 32, 104, 111, 119, 32, 116, 104, 101, 32, 99, 111, 100, 101, 115, 112, 97, 99, 101, 32, 105, 115, 32, 108, 97, 105, 100, 32, 111, 117, 116, 44, 32, 105, 116, 226, 128, 153, 115, 32, 104, 101, 108, 112, 102, 117, 108, 32, 116, 111, 32, 118, 105, 115, 117, 97, 108, 105, 122, 101, 32, 105, 116, 46, 32, 66, 101, 108, 111, 119, 32, 105, 115, 32, 97, 32, 109, 97, 112, 32, 111, 102, 32, 116, 104, 101, 32, 101, 110, 116, 105, 114, 101, 32, 99, 111, 100, 101, 115, 112, 97, 99, 101, 44, 32, 119, 105, 116, 104, 32, 111, 110, 101, 32, 112, 105, 120, 101, 108, 32, 112, 101, 114, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 46, 32, 73, 116, 226, 128, 153, 115, 32, 97, 114, 114, 97, 110, 103, 101, 100, 32, 105, 110, 32, 116, 105, 108, 101, 115, 32, 102, 111, 114, 32, 118, 105, 115, 117, 97, 108, 32, 99, 111, 104, 101, 114, 101, 110, 99, 101, 59, 32, 101, 97, 99, 104, 32, 115, 109, 97, 108, 108, 32, 115, 113, 117, 97, 114, 101, 32, 105, 115, 32, 49, 54, 195, 151, 49, 54, 32, 61, 32, 50, 53, 54, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 44, 32, 97, 110, 100, 32, 101, 97, 99, 104, 32, 108, 97, 114, 103, 101, 32, 115, 113, 117, 97, 114, 101, 32, 105, 115, 32, 97, 32, 226, 128, 156, 112, 108, 97, 110, 101, 226, 128, 157, 32, 111, 102, 32, 54, 53, 44, 53, 51, 54, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 46, 32, 84, 104, 101, 114, 101, 32, 97, 114, 101, 32, 49, 55, 32, 112, 108, 97, 110, 101, 115, 32, 97, 108, 116, 111, 103, 101, 116, 104, 101, 114, 46, 32, 32, 77, 97, 112, 32, 111, 102, 32, 116, 104, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 99, 111, 100, 101, 115, 112, 97, 99, 101, 32, 40, 99, 108, 105, 99, 107, 32, 116, 111, 32, 122, 111, 111, 109, 41, 32, 32, 87, 104, 105, 116, 101, 32, 114, 101, 112, 114, 101, 115, 101, 110, 116, 115, 32, 117, 110, 97, 115, 115, 105, 103, 110, 101, 100, 32, 115, 112, 97, 99, 101, 46, 32, 66, 108, 117, 101, 32, 105, 115, 32, 97, 115, 115, 105, 103, 110, 101, 100, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 44, 32, 103, 114, 101, 101, 110, 32, 105, 115, 32, 112, 114, 105, 118, 97, 116, 101, 45, 117, 115, 101, 32, 97, 114, 101, 97, 115, 44, 32, 97, 110, 100, 32, 116, 104, 101, 32, 115, 109, 97, 108, 108, 32, 114, 101, 100, 32, 97, 114, 101, 97, 32, 105, 115, 32, 115, 117, 114, 114, 111, 103, 97, 116, 101, 115, 32, 40, 109, 111, 114, 101, 32, 97, 98, 111, 117, 116, 32, 116, 104, 111, 115, 101, 32, 108, 97, 116, 101, 114, 41, 46, 32, 65, 115, 32, 121, 111, 117, 32, 99, 97, 110, 32, 115, 101, 101, 44, 32, 116, 104, 101, 32, 97, 115, 115, 105, 103, 110, 101, 100, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 97, 114, 101, 32, 100, 105, 115, 116, 114, 105, 98, 117, 116, 101, 100, 32, 115, 111, 109, 101, 119, 104, 97, 116, 32, 115, 112, 97, 114, 115, 101, 108, 121, 44, 32, 98, 117, 116, 32, 99, 111, 110, 99, 101, 110, 116, 114, 97, 116, 101, 100, 32, 105, 110, 32, 116, 104, 101, 32, 102, 105, 114, 115, 116, 32, 116, 104, 114, 101, 101, 32, 112, 108, 97, 110, 101, 115, 46, 32, 32, 80, 108, 97, 110, 101, 32, 48, 32, 105, 115, 32, 97, 108, 115, 111, 32, 107, 110, 111, 119, 110, 32, 97, 115, 32, 116, 104, 101, 32, 226, 128, 156, 66, 97, 115, 105, 99, 32, 77, 117, 108, 116, 105, 108, 105, 110, 103, 117, 97, 108, 32, 80, 108, 97, 110, 101, 226, 128, 157, 44, 32, 111, 114, 32, 66, 77, 80, 46, 32, 84, 104, 101, 32, 66, 77, 80, 32, 99, 111, 110, 116, 97, 105, 110, 115, 32, 101, 115, 115, 101, 110, 116, 105, 97, 108, 108, 121, 32, 97, 108, 108, 32, 116, 104, 101, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 32, 110, 101, 101, 100, 101, 100, 32, 102, 111, 114, 32, 109, 111, 100, 101, 114, 110, 32, 116, 101, 120, 116, 32, 105, 110, 32, 97, 110, 121, 32, 115, 99, 114, 105, 112, 116, 44, 32, 105, 110, 99, 108, 117, 100, 105, 110, 103, 32, 76, 97, 116, 105, 110, 44, 32, 67, 121, 114, 105, 108, 108, 105, 99, 44, 32, 71, 114, 101, 101, 107, 44, 32, 72, 97, 110, 32, 40, 67, 104, 105, 110, 101, 115, 101, 41, 44, 32, 74, 97, 112, 97, 110, 101, 115, 101, 44, 32, 75, 111, 114, 101, 97, 110, 44, 32, 65, 114, 97, 98, 105, 99, 44, 32, 72, 101, 98, 114, 101, 119, 44, 32, 68, 101, 118, 97, 110, 97, 103, 97, 114, 105, 32, 40, 73, 110, 100, 105, 97, 110, 41, 44, 32, 97, 110, 100, 32, 109, 97, 110, 121, 32, 109, 111, 114, 101, 46, 32, 32, 40, 73, 110, 32, 116, 104, 101, 32, 112, 97, 115, 116, 44, 32, 116, 104, 101, 32, 99, 111, 100, 101, 115, 112, 97, 99, 101, 32, 119, 97, 115, 32, 106, 117, 115, 116, 32, 116, 104, 101, 32, 66, 77, 80, 32, 97, 110, 100, 32, 110, 111, 32, 109, 111, 114, 101, 226, 128, 148, 85, 110, 105, 99, 111, 100, 101, 32, 119, 97, 115, 32, 111, 114, 105, 103, 105, 110, 97, 108, 108, 121, 32, 99, 111, 110, 99, 101, 105, 118, 101, 100, 32, 97, 115, 32, 97, 32, 115, 116, 114, 97, 105, 103, 104, 116, 102, 111, 114, 119, 97, 114, 100, 32, 49, 54, 45, 98, 105, 116, 32, 101, 110, 99, 111, 100, 105, 110, 103, 44, 32, 119, 105, 116, 104, 32, 111, 110, 108, 121, 32, 54, 53, 44, 53, 51, 54, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 46, 32, 73, 116, 32, 119, 97, 115, 32, 101, 120, 112, 97, 110, 100, 101, 100, 32, 116, 111, 32, 105, 116, 115, 32, 99, 117, 114, 114, 101, 110, 116, 32, 115, 105, 122, 101, 32, 105, 110, 32, 49, 57, 57, 54, 46, 32, 72, 111, 119, 101, 118, 101, 114, 44, 32, 116, 104, 101, 32, 118, 97, 115, 116, 32, 109, 97, 106, 111, 114, 105, 116, 121, 32, 111, 102, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 105, 110, 32, 109, 111, 100, 101, 114, 110, 32, 116, 101, 120, 116, 32, 98, 101, 108, 111, 110, 103, 32, 116, 111, 32, 116, 104, 101, 32, 66, 77, 80, 46, 41, 32, 32, 80, 108, 97, 110, 101, 32, 49, 32, 99, 111, 110, 116, 97, 105, 110, 115, 32, 104, 105, 115, 116, 111, 114, 105, 99, 97, 108, 32, 115, 99, 114, 105, 112, 116, 115, 44, 32, 115, 117, 99, 104, 32, 97, 115, 32, 83, 117, 109, 101, 114, 105, 97, 110, 32, 99, 117, 110, 101, 105, 102, 111, 114, 109, 32, 97, 110, 100, 32, 69, 103, 121, 112, 116, 105, 97, 110, 32, 104, 105, 101, 114, 111, 103, 108, 121, 112, 104, 115, 44, 32, 97, 115, 32, 119, 101, 108, 108, 32, 97, 115, 32, 101, 109, 111, 106, 105, 32, 97, 110, 100, 32, 118, 97, 114, 105, 111, 117, 115, 32, 111, 116, 104, 101, 114, 32, 115, 121, 109, 98, 111, 108, 115, 46, 32, 80, 108, 97, 110, 101, 32, 50, 32, 99, 111, 110, 116, 97, 105, 110, 115, 32, 97, 32, 108, 97, 114, 103, 101, 32, 98, 108, 111, 99, 107, 32, 111, 102, 32, 108, 101, 115, 115, 45, 99, 111, 109, 109, 111, 110, 32, 97, 110, 100, 32, 104, 105, 115, 116, 111, 114, 105, 99, 97, 108, 32, 72, 97, 110, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 46, 32, 84, 104, 101, 32, 114, 101, 109, 97, 105, 110, 105, 110, 103, 32, 112, 108, 97, 110, 101, 115, 32, 97, 114, 101, 32, 101, 109, 112, 116, 121, 44, 32, 101, 120, 99, 101, 112, 116, 32, 102, 111, 114, 32, 97, 32, 115, 109, 97, 108, 108, 32, 110, 117, 109, 98, 101, 114, 32, 111, 102, 32, 114, 97, 114, 101, 108, 121, 45, 117, 115, 101, 100, 32, 102, 111, 114, 109, 97, 116, 116, 105, 110, 103, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 32, 105, 110, 32, 80, 108, 97, 110, 101, 32, 49, 52, 59, 32, 112, 108, 97, 110, 101, 115, 32, 49, 53, 226, 128, 147, 49, 54, 32, 97, 114, 101, 32, 114, 101, 115, 101, 114, 118, 101, 100, 32, 101, 110, 116, 105, 114, 101, 108, 121, 32, 102, 111, 114, 32, 112, 114, 105, 118, 97, 116, 101, 32, 117, 115, 101, 46, 32, 32, 83, 99, 114, 105, 112, 116, 115, 32, 76, 101, 116, 226, 128, 153, 115, 32, 122, 111, 111, 109, 32, 105, 110, 32, 111, 110, 32, 116, 104, 101, 32, 102, 105, 114, 115, 116, 32, 116, 104, 114, 101, 101, 32, 112, 108, 97, 110, 101, 115, 44, 32, 115, 105, 110, 99, 101, 32, 116, 104, 97, 116, 226, 128, 153, 115, 32, 119, 104, 101, 114, 101, 32, 116, 104, 101, 32, 97, 99, 116, 105, 111, 110, 32, 105, 115, 58, 32, 32, 77, 97, 112, 32, 111, 102, 32, 115, 99, 114, 105, 112, 116, 115, 32, 105, 110, 32, 85, 110, 105, 99, 111, 100, 101, 32, 112, 108, 97, 110, 101, 115, 32, 48, 226, 128, 147, 50, 32, 40, 99, 108, 105, 99, 107, 32, 116, 111, 32, 122, 111, 111, 109, 41, 32, 32, 84, 104, 105, 115, 32, 109, 97, 112, 32, 99, 111, 108, 111, 114, 45, 99, 111, 100, 101, 115, 32, 116, 104, 101, 32, 49, 51, 53, 32, 100, 105, 102, 102, 101, 114, 101, 110, 116, 32, 115, 99, 114, 105, 112, 116, 115, 32, 105, 110, 32, 85, 110, 105, 99, 111, 100, 101, 46, 32, 89, 111, 117, 32, 99, 97, 110, 32, 115, 101, 101, 32, 104, 111, 119, 32, 72, 97, 110, 32, 40, 41, 32, 97, 110, 100, 32, 75, 111, 114, 101, 97, 110, 32, 40, 41, 32, 116, 97, 107, 101, 32, 117, 112, 32, 109, 111, 115, 116, 32, 111, 102, 32, 116, 104, 101, 32, 114, 97, 110, 103, 101, 32, 111, 102, 32, 116, 104, 101, 32, 66, 77, 80, 32, 40, 116, 104, 101, 32, 108, 101, 102, 116, 32, 108, 97, 114, 103, 101, 32, 115, 113, 117, 97, 114, 101, 41, 46, 32, 66, 121, 32, 99, 111, 110, 116, 114, 97, 115, 116, 44, 32, 97, 108, 108, 32, 111, 102, 32, 116, 104, 101, 32, 69, 117, 114, 111, 112, 101, 97, 110, 44, 32, 77, 105, 100, 100, 108, 101, 32, 69, 97, 115, 116, 101, 114, 110, 44, 32, 97, 110, 100, 32, 83, 111, 117, 116, 104, 32, 65, 115, 105, 97, 110, 32, 115, 99, 114, 105, 112, 116, 115, 32, 102, 105, 116, 32, 105, 110, 116, 111, 32, 116, 104, 101, 32, 102, 105, 114, 115, 116, 32, 114, 111, 119, 32, 111, 102, 32, 116, 104, 101, 32, 66, 77, 80, 32, 105, 110, 32, 116, 104, 105, 115, 32, 100, 105, 97, 103, 114, 97, 109, 46, 32, 32, 77, 97, 110, 121, 32, 97, 114, 101, 97, 115, 32, 111, 102, 32, 116, 104, 101, 32, 99, 111, 100, 101, 115, 112, 97, 99, 101, 32, 97, 114, 101, 32, 97, 100, 97, 112, 116, 101, 100, 32, 111, 114, 32, 99, 111, 112, 105, 101, 100, 32, 102, 114, 111, 109, 32, 101, 97, 114, 108, 105, 101, 114, 32, 101, 110, 99, 111, 100, 105, 110, 103, 115, 46, 32, 70, 111, 114, 32, 101, 120, 97, 109, 112, 108, 101, 44, 32, 116, 104, 101, 32, 102, 105, 114, 115, 116, 32, 49, 50, 56, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 111, 102, 32, 85, 110, 105, 99, 111, 100, 101, 32, 97, 114, 101, 32, 106, 117, 115, 116, 32, 97, 32, 99, 111, 112, 121, 32, 111, 102, 32, 65, 83, 67, 73, 73, 46, 32, 84, 104, 105, 115, 32, 104, 97, 115, 32, 99, 108, 101, 97, 114, 32, 98, 101, 110, 101, 102, 105, 116, 115, 32, 102, 111, 114, 32, 99, 111, 109, 112, 97, 116, 105, 98, 105, 108, 105, 116, 121, 226, 128, 148, 105, 116, 226, 128, 153, 115, 32, 101, 97, 115, 121, 32, 116, 111, 32, 108, 111, 115, 115, 108, 101, 115, 115, 108, 121, 32, 99, 111, 110, 118, 101, 114, 116, 32, 116, 101, 120, 116, 115, 32, 102, 114, 111, 109, 32, 115, 109, 97, 108, 108, 101, 114, 32, 101, 110, 99, 111, 100, 105, 110, 103, 115, 32, 105, 110, 116, 111, 32, 85, 110, 105, 99, 111, 100, 101, 32, 40, 97, 110, 100, 32, 116, 104, 101, 32, 111, 116, 104, 101, 114, 32, 100, 105, 114, 101, 99, 116, 105, 111, 110, 32, 116, 111, 111, 44, 32, 97, 115, 32, 108, 111, 110, 103, 32, 97, 115, 32, 110, 111, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 32, 111, 117, 116, 115, 105, 100, 101, 32, 116, 104, 101, 32, 115, 109, 97, 108, 108, 101, 114, 32, 101, 110, 99, 111, 100, 105, 110, 103, 32, 97, 114, 101, 32, 117, 115, 101, 100, 41, 46, 32, 32, 85, 115, 97, 103, 101, 32, 70, 114, 101, 113, 117, 101, 110, 99, 121, 32, 79, 110, 101, 32, 109, 111, 114, 101, 32, 105, 110, 116, 101, 114, 101, 115, 116, 105, 110, 103, 32, 119, 97, 121, 32, 116, 111, 32, 118, 105, 115, 117, 97, 108, 105, 122, 101, 32, 116, 104, 101, 32, 99, 111, 100, 101, 115, 112, 97, 99, 101, 32, 105, 115, 32, 116, 111, 32, 108, 111, 111, 107, 32, 97, 116, 32, 116, 104, 101, 32, 100, 105, 115, 116, 114, 105, 98, 117, 116, 105, 111, 110, 32, 111, 102, 32, 117, 115, 97, 103, 101, 226, 128, 148, 105, 110, 32, 111, 116, 104, 101, 114, 32, 119, 111, 114, 100, 115, 44, 32, 104, 111, 119, 32, 111, 102, 116, 101, 110, 32, 101, 97, 99, 104, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 105, 115, 32, 97, 99, 116, 117, 97, 108, 108, 121, 32, 117, 115, 101, 100, 32, 105, 110, 32, 114, 101, 97, 108, 45, 119, 111, 114, 108, 100, 32, 116, 101, 120, 116, 115, 46, 32, 66, 101, 108, 111, 119, 32, 105, 115, 32, 97, 32, 104, 101, 97, 116, 32, 109, 97, 112, 32, 111, 102, 32, 112, 108, 97, 110, 101, 115, 32, 48, 226, 128, 147, 50, 32, 98, 97, 115, 101, 100, 32, 111, 110, 32, 97, 32, 108, 97, 114, 103, 101, 32, 115, 97, 109, 112, 108, 101, 32, 111, 102, 32, 116, 101, 120, 116, 32, 102, 114, 111, 109, 32, 87, 105, 107, 105, 112, 101, 100, 105, 97, 32, 97, 110, 100, 32, 84, 119, 105, 116, 116, 101, 114, 32, 40, 97, 108, 108, 32, 108, 97, 110, 103, 117, 97, 103, 101, 115, 41, 46, 32, 70, 114, 101, 113, 117, 101, 110, 99, 121, 32, 105, 110, 99, 114, 101, 97, 115, 101, 115, 32, 102, 114, 111, 109, 32, 98, 108, 97, 99, 107, 32, 40, 110, 101, 118, 101, 114, 32, 115, 101, 101, 110, 41, 32, 116, 104, 114, 111, 117, 103, 104, 32, 114, 101, 100, 32, 97, 110, 100, 32, 121, 101, 108, 108, 111, 119, 32, 116, 111, 32, 119, 104, 105, 116, 101, 46, 32, 32, 72, 101, 97, 116, 32, 109, 97, 112, 32, 111, 102, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 117, 115, 97, 103, 101, 32, 102, 114, 101, 113, 117, 101, 110, 99, 121, 32, 105, 110, 32, 85, 110, 105, 99, 111, 100, 101, 32, 112, 108, 97, 110, 101, 115, 32, 48, 226, 128, 147, 50, 32, 40, 99, 108, 105, 99, 107, 32, 116, 111, 32, 122, 111, 111, 109, 41, 32, 32, 89, 111, 117, 32, 99, 97, 110, 32, 115, 101, 101, 32, 116, 104, 97, 116, 32, 116, 104, 101, 32, 118, 97, 115, 116, 32, 109, 97, 106, 111, 114, 105, 116, 121, 32, 111, 102, 32, 116, 104, 105, 115, 32, 116, 101, 120, 116, 32, 115, 97, 109, 112, 108, 101, 32, 108, 105, 101, 115, 32, 105, 110, 32, 116, 104, 101, 32, 66, 77, 80, 44, 32, 119, 105, 116, 104, 32, 111, 110, 108, 121, 32, 115, 99, 97, 116, 116, 101, 114, 101, 100, 32, 117, 115, 97, 103, 101, 32, 111, 102, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 102, 114, 111, 109, 32, 112, 108, 97, 110, 101, 115, 32, 49, 226, 128, 147, 50, 46, 32, 84, 104, 101, 32, 98, 105, 103, 103, 101, 115, 116, 32, 101, 120, 99, 101, 112, 116, 105, 111, 110, 32, 105, 115, 32, 101, 109, 111, 106, 105, 44, 32, 119, 104, 105, 99, 104, 32, 115, 104, 111, 119, 32, 117, 112, 32, 104, 101, 114, 101, 32, 97, 115, 32, 116, 104, 101, 32, 115, 101, 118, 101, 114, 97, 108, 32, 98, 114, 105, 103, 104, 116, 32, 115, 113, 117, 97, 114, 101, 115, 32, 105, 110, 32, 116, 104, 101, 32, 98, 111, 116, 116, 111, 109, 32, 114, 111, 119, 32, 111, 102, 32, 112, 108, 97, 110, 101, 32, 49, 46, 32, 32, 69, 110, 99, 111, 100, 105, 110, 103, 115, 32, 87, 101, 226, 128, 153, 118, 101, 32, 115, 101, 101, 110, 32, 116, 104, 97, 116, 32, 85, 110, 105, 99, 111, 100, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 97, 114, 101, 32, 97, 98, 115, 116, 114, 97, 99, 116, 108, 121, 32, 105, 100, 101, 110, 116, 105, 102, 105, 101, 100, 32, 98, 121, 32, 116, 104, 101, 105, 114, 32, 105, 110, 100, 101, 120, 32, 105, 110, 32, 116, 104, 101, 32, 99, 111, 100, 101, 115, 112, 97, 99, 101, 44, 32, 114, 97, 110, 103, 105, 110, 103, 32, 102, 114, 111, 109, 32, 85, 43, 48, 48, 48, 48, 32, 116, 111, 32, 85, 43, 49, 48, 70, 70, 70, 70, 46, 32, 66, 117, 116, 32, 104, 111, 119, 32, 100, 111, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 103, 101, 116, 32, 114, 101, 112, 114, 101, 115, 101, 110, 116, 101, 100, 32, 97, 115, 32, 98, 121, 116, 101, 115, 44, 32, 105, 110, 32, 109, 101, 109, 111, 114, 121, 32, 111, 114, 32, 105, 110, 32, 97, 32, 102, 105, 108, 101, 63, 32, 32, 84, 104, 101, 32, 109, 111, 115, 116, 32, 99, 111, 110, 118, 101, 110, 105, 101, 110, 116, 44, 32, 99, 111, 109, 112, 117, 116, 101, 114, 45, 102, 114, 105, 101, 110, 100, 108, 105, 101, 115, 116, 32, 40, 97, 110, 100, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 45, 102, 114, 105, 101, 110, 100, 108, 105, 101, 115, 116, 41, 32, 116, 104, 105, 110, 103, 32, 116, 111, 32, 100, 111, 32, 119, 111, 117, 108, 100, 32, 98, 101, 32, 116, 111, 32, 106, 117, 115, 116, 32, 115, 116, 111, 114, 101, 32, 116, 104, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 105, 110, 100, 101, 120, 32, 97, 115, 32, 97, 32, 51, 50, 45, 98, 105, 116, 32, 105, 110, 116, 101, 103, 101, 114, 46, 32, 84, 104, 105, 115, 32, 119, 111, 114, 107, 115, 44, 32, 98, 117, 116, 32, 105, 116, 32, 99, 111, 110, 115, 117, 109, 101, 115, 32, 52, 32, 98, 121, 116, 101, 115, 32, 112, 101, 114, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 44, 32, 119, 104, 105, 99, 104, 32, 105, 115, 32, 115, 111, 114, 116, 32, 111, 102, 32, 97, 32, 108, 111, 116, 46, 32, 85, 115, 105, 110, 103, 32, 51, 50, 45, 98, 105, 116, 32, 105, 110, 116, 115, 32, 102, 111, 114, 32, 85, 110, 105, 99, 111, 100, 101, 32, 119, 105, 108, 108, 32, 99, 111, 115, 116, 32, 121, 111, 117, 32, 97, 32, 98, 117, 110, 99, 104, 32, 111, 102, 32, 101, 120, 116, 114, 97, 32, 115, 116, 111, 114, 97, 103, 101, 44, 32, 109, 101, 109, 111, 114, 121, 44, 32, 97, 110, 100, 32, 112, 101, 114, 102, 111, 114, 109, 97, 110, 99, 101, 32, 105, 110, 32, 98, 97, 110, 100, 119, 105, 100, 116, 104, 45, 98, 111, 117, 110, 100, 32, 115, 99, 101, 110, 97, 114, 105, 111, 115, 44, 32, 105, 102, 32, 121, 111, 117, 32, 119, 111, 114, 107, 32, 119, 105, 116, 104, 32, 97, 32, 108, 111, 116, 32, 111, 102, 32, 116, 101, 120, 116, 46, 32, 32, 67, 111, 110, 115, 101, 113, 117, 101, 110, 116, 108, 121, 44, 32, 116, 104, 101, 114, 101, 32, 97, 114, 101, 32, 115, 101, 118, 101, 114, 97, 108, 32, 109, 111, 114, 101, 45, 99, 111, 109, 112, 97, 99, 116, 32, 101, 110, 99, 111, 100, 105, 110, 103, 115, 32, 102, 111, 114, 32, 85, 110, 105, 99, 111, 100, 101, 46, 32, 84, 104, 101, 32, 51, 50, 45, 98, 105, 116, 32, 105, 110, 116, 101, 103, 101, 114, 32, 101, 110, 99, 111, 100, 105, 110, 103, 32, 105, 115, 32, 111, 102, 102, 105, 99, 105, 97, 108, 108, 121, 32, 99, 97, 108, 108, 101, 100, 32, 85, 84, 70, 45, 51, 50, 32, 40, 85, 84, 70, 32, 61, 32, 226, 128, 156, 85, 110, 105, 99, 111, 100, 101, 32, 84, 114, 97, 110, 115, 102, 111, 114, 109, 97, 116, 105, 111, 110, 32, 70, 111, 114, 109, 97, 116, 226, 128, 157, 41, 44, 32, 98, 117, 116, 32, 105, 116, 226, 128, 153, 115, 32, 114, 97, 114, 101, 108, 121, 32, 117, 115, 101, 100, 32, 102, 111, 114, 32, 115, 116, 111, 114, 97, 103, 101, 46, 32, 65, 116, 32, 109, 111, 115, 116, 44, 32, 105, 116, 32, 99, 111, 109, 101, 115, 32, 117, 112, 32, 115, 111, 109, 101, 116, 105, 109, 101, 115, 32, 97, 115, 32, 97, 32, 116, 101, 109, 112, 111, 114, 97, 114, 121, 32, 105, 110, 116, 101, 114, 110, 97, 108, 32, 114, 101, 112, 114, 101, 115, 101, 110, 116, 97, 116, 105, 111, 110, 44, 32, 102, 111, 114, 32, 101, 120, 97, 109, 105, 110, 105, 110, 103, 32, 111, 114, 32, 111, 112, 101, 114, 97, 116, 105, 110, 103, 32, 111, 110, 32, 116, 104, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 105, 110, 32, 97, 32, 115, 116, 114, 105, 110, 103, 46, 32, 32, 77, 117, 99, 104, 32, 109, 111, 114, 101, 32, 99, 111, 109, 109, 111, 110, 108, 121, 44, 32, 121, 111, 117, 226, 128, 153, 108, 108, 32, 115, 101, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 116, 101, 120, 116, 32, 101, 110, 99, 111, 100, 101, 100, 32, 97, 115, 32, 101, 105, 116, 104, 101, 114, 32, 85, 84, 70, 45, 56, 32, 111, 114, 32, 85, 84, 70, 45, 49, 54, 46, 32, 84, 104, 101, 115, 101, 32, 97, 114, 101, 32, 98, 111, 116, 104, 32, 118, 97, 114, 105, 97, 98, 108, 101, 45, 108, 101, 110, 103, 116, 104, 32, 101, 110, 99, 111, 100, 105, 110, 103, 115, 44, 32, 109, 97, 100, 101, 32, 117, 112, 32, 111, 102, 32, 56, 45, 98, 105, 116, 32, 111, 114, 32, 49, 54, 45, 98, 105, 116, 32, 117, 110, 105, 116, 115, 44, 32, 114, 101, 115, 112, 101, 99, 116, 105, 118, 101, 108, 121, 46, 32, 73, 110, 32, 116, 104, 101, 115, 101, 32, 115, 99, 104, 101, 109, 101, 115, 44, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 119, 105, 116, 104, 32, 115, 109, 97, 108, 108, 101, 114, 32, 105, 110, 100, 101, 120, 32, 118, 97, 108, 117, 101, 115, 32, 116, 97, 107, 101, 32, 117, 112, 32, 102, 101, 119, 101, 114, 32, 98, 121, 116, 101, 115, 44, 32, 119, 104, 105, 99, 104, 32, 115, 97, 118, 101, 115, 32, 97, 32, 108, 111, 116, 32, 111, 102, 32, 109, 101, 109, 111, 114, 121, 32, 102, 111, 114, 32, 116, 121, 112, 105, 99, 97, 108, 32, 116, 101, 120, 116, 115, 46, 32, 84, 104, 101, 32, 116, 114, 97, 100, 101, 45, 111, 102, 102, 32, 105, 115, 32, 116, 104, 97, 116, 32, 112, 114, 111, 99, 101, 115, 115, 105, 110, 103, 32, 85, 84, 70, 45, 56, 47, 49, 54, 32, 116, 101, 120, 116, 115, 32, 105, 115, 32, 109, 111, 114, 101, 32, 112, 114, 111, 103, 114, 97, 109, 109, 97, 116, 105, 99, 97, 108, 108, 121, 32, 105, 110, 118, 111, 108, 118, 101, 100, 44, 32, 97, 110, 100, 32, 108, 105, 107, 101, 108, 121, 32, 115, 108, 111, 119, 101, 114, 46, 32, 32, 85, 84, 70, 45, 56, 32, 73, 110, 32, 85, 84, 70, 45, 56, 44, 32, 101, 97, 99, 104, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 105, 115, 32, 115, 116, 111, 114, 101, 100, 32, 117, 115, 105, 110, 103, 32, 49, 32, 116, 111, 32, 52, 32, 98, 121, 116, 101, 115, 44, 32, 98, 97, 115, 101, 100, 32, 111, 110, 32, 105, 116, 115, 32, 105, 110, 100, 101, 120, 32, 118, 97, 108, 117, 101, 46, 32, 32, 85, 84, 70, 45, 56, 32, 117, 115, 101, 115, 32, 97, 32, 115, 121, 115, 116, 101, 109, 32, 111, 102, 32, 98, 105, 110, 97, 114, 121, 32, 112, 114, 101, 102, 105, 120, 101, 115, 44, 32, 105, 110, 32, 119, 104, 105, 99, 104, 32, 116, 104, 101, 32, 104, 105, 103, 104, 32, 98, 105, 116, 115, 32, 111, 102, 32, 101, 97, 99, 104, 32, 98, 121, 116, 101, 32, 109, 97, 114, 107, 32, 119, 104, 101, 116, 104, 101, 114, 32, 105, 116, 226, 128, 153, 115, 32, 97, 32, 115, 105, 110, 103, 108, 101, 32, 98, 121, 116, 101, 44, 32, 116, 104, 101, 32, 98, 101, 103, 105, 110, 110, 105, 110, 103, 32, 111, 102, 32, 97, 32, 109, 117, 108, 116, 105, 45, 98, 121, 116, 101, 32, 115, 101, 113, 117, 101, 110, 99, 101, 44, 32, 111, 114, 32, 97, 32, 99, 111, 110, 116, 105, 110, 117, 97, 116, 105, 111, 110, 32, 98, 121, 116, 101, 59, 32, 116, 104, 101, 32, 114, 101, 109, 97, 105, 110, 105, 110, 103, 32, 98, 105, 116, 115, 44, 32, 99, 111, 110, 99, 97, 116, 101, 110, 97, 116, 101, 100, 44, 32, 103, 105, 118, 101, 32, 116, 104, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 105, 110, 100, 101, 120, 46, 32, 84, 104, 105, 115, 32, 116, 97, 98, 108, 101, 32, 115, 104, 111, 119, 115, 32, 104, 111, 119, 32, 105, 116, 32, 119, 111, 114, 107, 115, 58, 32, 32, 85, 84, 70, 45, 56, 32, 40, 98, 105, 110, 97, 114, 121, 41, 9, 67, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 40, 98, 105, 110, 97, 114, 121, 41, 9, 82, 97, 110, 103, 101, 32, 48, 120, 120, 120, 120, 120, 120, 120, 9, 120, 120, 120, 120, 120, 120, 120, 9, 85, 43, 48, 48, 48, 48, 226, 128, 147, 85, 43, 48, 48, 55, 70, 32, 49, 49, 48, 120, 120, 120, 120, 120, 32, 49, 48, 121, 121, 121, 121, 121, 121, 9, 120, 120, 120, 120, 120, 121, 121, 121, 121, 121, 121, 9, 85, 43, 48, 48, 56, 48, 226, 128, 147, 85, 43, 48, 55, 70, 70, 32, 49, 49, 49, 48, 120, 120, 120, 120, 32, 49, 48, 121, 121, 121, 121, 121, 121, 32, 49, 48, 122, 122, 122, 122, 122, 122, 9, 120, 120, 120, 120, 121, 121, 121, 121, 121, 121, 122, 122, 122, 122, 122, 122, 9, 85, 43, 48, 56, 48, 48, 226, 128, 147, 85, 43, 70, 70, 70, 70, 32, 49, 49, 49, 49, 48, 120, 120, 120, 32, 49, 48, 121, 121, 121, 121, 121, 121, 32, 49, 48, 122, 122, 122, 122, 122, 122, 32, 49, 48, 119, 119, 119, 119, 119, 119, 9, 120, 120, 120, 121, 121, 121, 121, 121, 121, 122, 122, 122, 122, 122, 122, 119, 119, 119, 119, 119, 119, 9, 85, 43, 49, 48, 48, 48, 48, 226, 128, 147, 85, 43, 49, 48, 70, 70, 70, 70, 32, 65, 32, 104, 97, 110, 100, 121, 32, 112, 114, 111, 112, 101, 114, 116, 121, 32, 111, 102, 32, 85, 84, 70, 45, 56, 32, 105, 115, 32, 116, 104, 97, 116, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 98, 101, 108, 111, 119, 32, 49, 50, 56, 32, 40, 65, 83, 67, 73, 73, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 41, 32, 97, 114, 101, 32, 101, 110, 99, 111, 100, 101, 100, 32, 97, 115, 32, 115, 105, 110, 103, 108, 101, 32, 98, 121, 116, 101, 115, 44, 32, 97, 110, 100, 32, 97, 108, 108, 32, 110, 111, 110, 45, 65, 83, 67, 73, 73, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 97, 114, 101, 32, 101, 110, 99, 111, 100, 101, 100, 32, 117, 115, 105, 110, 103, 32, 115, 101, 113, 117, 101, 110, 99, 101, 115, 32, 111, 102, 32, 98, 121, 116, 101, 115, 32, 49, 50, 56, 226, 128, 147, 50, 53, 53, 46, 32, 84, 104, 105, 115, 32, 104, 97, 115, 32, 97, 32, 99, 111, 117, 112, 108, 101, 32, 111, 102, 32, 110, 105, 99, 101, 32, 99, 111, 110, 115, 101, 113, 117, 101, 110, 99, 101, 115, 46, 32, 70, 105, 114, 115, 116, 44, 32, 97, 110, 121, 32, 115, 116, 114, 105, 110, 103, 115, 32, 111, 114, 32, 102, 105, 108, 101, 115, 32, 111, 117, 116, 32, 116, 104, 101, 114, 101, 32, 116, 104, 97, 116, 32, 97, 114, 101, 32, 97, 108, 114, 101, 97, 100, 121, 32, 105, 110, 32, 65, 83, 67, 73, 73, 32, 99, 97, 110, 32, 97, 108, 115, 111, 32, 98, 101, 32, 105, 110, 116, 101, 114, 112, 114, 101, 116, 101, 100, 32, 97, 115, 32, 85, 84, 70, 45, 56, 32, 119, 105, 116, 104, 111, 117, 116, 32, 97, 110, 121, 32, 99, 111, 110, 118, 101, 114, 115, 105, 111, 110, 46, 32, 83, 101, 99, 111, 110, 100, 44, 32, 108, 111, 116, 115, 32, 111, 102, 32, 119, 105, 100, 101, 108, 121, 45, 117, 115, 101, 100, 32, 115, 116, 114, 105, 110, 103, 32, 112, 114, 111, 103, 114, 97, 109, 109, 105, 110, 103, 32, 105, 100, 105, 111, 109, 115, 226, 128, 148, 115, 117, 99, 104, 32, 97, 115, 32, 110, 117, 108, 108, 32, 116, 101, 114, 109, 105, 110, 97, 116, 105, 111, 110, 44, 32, 111, 114, 32, 100, 101, 108, 105, 109, 105, 116, 101, 114, 115, 32, 40, 110, 101, 119, 108, 105, 110, 101, 115, 44, 32, 116, 97, 98, 115, 44, 32, 99, 111, 109, 109, 97, 115, 44, 32, 115, 108, 97, 115, 104, 101, 115, 44, 32, 101, 116, 99, 46, 41, 226, 128, 148, 119, 105, 108, 108, 32, 106, 117, 115, 116, 32, 119, 111, 114, 107, 32, 111, 110, 32, 85, 84, 70, 45, 56, 32, 115, 116, 114, 105, 110, 103, 115, 46, 32, 65, 83, 67, 73, 73, 32, 98, 121, 116, 101, 115, 32, 110, 101, 118, 101, 114, 32, 111, 99, 99, 117, 114, 32, 105, 110, 115, 105, 100, 101, 32, 116, 104, 101, 32, 101, 110, 99, 111, 100, 105, 110, 103, 32, 111, 102, 32, 110, 111, 110, 45, 65, 83, 67, 73, 73, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 44, 32, 115, 111, 32, 115, 101, 97, 114, 99, 104, 105, 110, 103, 32, 98, 121, 116, 101, 45, 119, 105, 115, 101, 32, 102, 111, 114, 32, 97, 32, 110, 117, 108, 108, 32, 116, 101, 114, 109, 105, 110, 97, 116, 111, 114, 32, 111, 114, 32, 97, 32, 100, 101, 108, 105, 109, 105, 116, 101, 114, 32, 119, 105, 108, 108, 32, 100, 111, 32, 116, 104, 101, 32, 114, 105, 103, 104, 116, 32, 116, 104, 105, 110, 103, 46, 32, 32, 84, 104, 97, 110, 107, 115, 32, 116, 111, 32, 116, 104, 105, 115, 32, 99, 111, 110, 118, 101, 110, 105, 101, 110, 99, 101, 44, 32, 105, 116, 226, 128, 153, 115, 32, 114, 101, 108, 97, 116, 105, 118, 101, 108, 121, 32, 115, 105, 109, 112, 108, 101, 32, 116, 111, 32, 101, 120, 116, 101, 110, 100, 32, 108, 101, 103, 97, 99, 121, 32, 65, 83, 67, 73, 73, 32, 112, 114, 111, 103, 114, 97, 109, 115, 32, 97, 110, 100, 32, 65, 80, 73, 115, 32, 116, 111, 32, 104, 97, 110, 100, 108, 101, 32, 85, 84, 70, 45, 56, 32, 115, 116, 114, 105, 110, 103, 115, 46, 32, 85, 84, 70, 45, 56, 32, 105, 115, 32, 118, 101, 114, 121, 32, 119, 105, 100, 101, 108, 121, 32, 117, 115, 101, 100, 32, 105, 110, 32, 116, 104, 101, 32, 85, 110, 105, 120, 47, 76, 105, 110, 117, 120, 32, 97, 110, 100, 32, 87, 101, 98, 32, 119, 111, 114, 108, 100, 115, 44, 32, 97, 110, 100, 32, 109, 97, 110, 121, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 97, 114, 103, 117, 101, 32, 85, 84, 70, 45, 56, 32, 115, 104, 111, 117, 108, 100, 32, 98, 101, 32, 116, 104, 101, 32, 100, 101, 102, 97, 117, 108, 116, 32, 101, 110, 99, 111, 100, 105, 110, 103, 32, 101, 118, 101, 114, 121, 119, 104, 101, 114, 101, 46, 32, 32, 72, 111, 119, 101, 118, 101, 114, 44, 32, 85, 84, 70, 45, 56, 32, 105, 115, 110, 226, 128, 153, 116, 32, 97, 32, 100, 114, 111, 112, 45, 105, 110, 32, 114, 101, 112, 108, 97, 99, 101, 109, 101, 110, 116, 32, 102, 111, 114, 32, 65, 83, 67, 73, 73, 32, 115, 116, 114, 105, 110, 103, 115, 32, 105, 110, 32, 97, 108, 108, 32, 114, 101, 115, 112, 101, 99, 116, 115, 46, 32, 70, 111, 114, 32, 105, 110, 115, 116, 97, 110, 99, 101, 44, 32, 99, 111, 100, 101, 32, 116, 104, 97, 116, 32, 105, 116, 101, 114, 97, 116, 101, 115, 32, 111, 118, 101, 114, 32, 116, 104, 101, 32, 226, 128, 156, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 226, 128, 157, 32, 105, 110, 32, 97, 32, 115, 116, 114, 105, 110, 103, 32, 119, 105, 108, 108, 32, 110, 101, 101, 100, 32, 116, 111, 32, 100, 101, 99, 111, 100, 101, 32, 85, 84, 70, 45, 56, 32, 97, 110, 100, 32, 105, 116, 101, 114, 97, 116, 101, 32, 111, 118, 101, 114, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 40, 111, 114, 32, 109, 97, 121, 98, 101, 32, 103, 114, 97, 112, 104, 101, 109, 101, 32, 99, 108, 117, 115, 116, 101, 114, 115, 226, 128, 148, 109, 111, 114, 101, 32, 97, 98, 111, 117, 116, 32, 116, 104, 111, 115, 101, 32, 108, 97, 116, 101, 114, 41, 44, 32, 110, 111, 116, 32, 98, 121, 116, 101, 115, 46, 32, 87, 104, 101, 110, 32, 121, 111, 117, 32, 109, 101, 97, 115, 117, 114, 101, 32, 116, 104, 101, 32, 226, 128, 156, 108, 101, 110, 103, 116, 104, 226, 128, 157, 32, 111, 102, 32, 97, 32, 115, 116, 114, 105, 110, 103, 44, 32, 121, 111, 117, 226, 128, 153, 108, 108, 32, 110, 101, 101, 100, 32, 116, 111, 32, 116, 104, 105, 110, 107, 32, 97, 98, 111, 117, 116, 32, 119, 104, 101, 116, 104, 101, 114, 32, 121, 111, 117, 32, 119, 97, 110, 116, 32, 116, 104, 101, 32, 108, 101, 110, 103, 116, 104, 32, 105, 110, 32, 98, 121, 116, 101, 115, 44, 32, 116, 104, 101, 32, 108, 101, 110, 103, 116, 104, 32, 105, 110, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 44, 32, 116, 104, 101, 32, 119, 105, 100, 116, 104, 32, 111, 102, 32, 116, 104, 101, 32, 116, 101, 120, 116, 32, 119, 104, 101, 110, 32, 114, 101, 110, 100, 101, 114, 101, 100, 44, 32, 111, 114, 32, 115, 111, 109, 101, 116, 104, 105, 110, 103, 32, 101, 108, 115, 101, 46, 32, 32, 85, 84, 70, 45, 49, 54, 32, 84, 104, 101, 32, 111, 116, 104, 101, 114, 32, 101, 110, 99, 111, 100, 105, 110, 103, 32, 116, 104, 97, 116, 32, 121, 111, 117, 226, 128, 153, 114, 101, 32, 108, 105, 107, 101, 108, 121, 32, 116, 111, 32, 101, 110, 99, 111, 117, 110, 116, 101, 114, 32, 105, 115, 32, 85, 84, 70, 45, 49, 54, 46, 32, 73, 116, 32, 117, 115, 101, 115, 32, 49, 54, 45, 98, 105, 116, 32, 119, 111, 114, 100, 115, 44, 32, 119, 105, 116, 104, 32, 101, 97, 99, 104, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 115, 116, 111, 114, 101, 100, 32, 97, 115, 32, 101, 105, 116, 104, 101, 114, 32, 49, 32, 111, 114, 32, 50, 32, 119, 111, 114, 100, 115, 46, 32, 32, 76, 105, 107, 101, 32, 85, 84, 70, 45, 56, 44, 32, 119, 101, 32, 99, 97, 110, 32, 101, 120, 112, 114, 101, 115, 115, 32, 116, 104, 101, 32, 85, 84, 70, 45, 49, 54, 32, 101, 110, 99, 111, 100, 105, 110, 103, 32, 114, 117, 108, 101, 115, 32, 105, 110, 32, 116, 104, 101, 32, 102, 111, 114, 109, 32, 111, 102, 32, 98, 105, 110, 97, 114, 121, 32, 112, 114, 101, 102, 105, 120, 101, 115, 58, 32, 32, 85, 84, 70, 45, 49, 54, 32, 40, 98, 105, 110, 97, 114, 121, 41, 9, 67, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 40, 98, 105, 110, 97, 114, 121, 41, 9, 82, 97, 110, 103, 101, 32, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 9, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 9, 85, 43, 48, 48, 48, 48, 226, 128, 147, 85, 43, 70, 70, 70, 70, 32, 49, 49, 48, 49, 49, 48, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 32, 49, 49, 48, 49, 49, 49, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 9, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 32, 43, 32, 48, 120, 49, 48, 48, 48, 48, 9, 85, 43, 49, 48, 48, 48, 48, 226, 128, 147, 85, 43, 49, 48, 70, 70, 70, 70, 32, 65, 32, 109, 111, 114, 101, 32, 99, 111, 109, 109, 111, 110, 32, 119, 97, 121, 32, 116, 104, 97, 116, 32, 112, 101, 111, 112, 108, 101, 32, 116, 97, 108, 107, 32, 97, 98, 111, 117, 116, 32, 85, 84, 70, 45, 49, 54, 32, 101, 110, 99, 111, 100, 105, 110, 103, 44, 32, 116, 104, 111, 117, 103, 104, 44, 32, 105, 115, 32, 105, 110, 32, 116, 101, 114, 109, 115, 32, 111, 102, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 99, 97, 108, 108, 101, 100, 32, 226, 128, 156, 115, 117, 114, 114, 111, 103, 97, 116, 101, 115, 226, 128, 157, 46, 32, 65, 108, 108, 32, 116, 104, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 105, 110, 32, 116, 104, 101, 32, 114, 97, 110, 103, 101, 32, 85, 43, 68, 56, 48, 48, 226, 128, 147, 85, 43, 68, 70, 70, 70, 226, 128, 148, 111, 114, 32, 105, 110, 32, 111, 116, 104, 101, 114, 32, 119, 111, 114, 100, 115, 44, 32, 116, 104, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 116, 104, 97, 116, 32, 109, 97, 116, 99, 104, 32, 116, 104, 101, 32, 98, 105, 110, 97, 114, 121, 32, 112, 114, 101, 102, 105, 120, 101, 115, 32, 49, 49, 48, 49, 49, 48, 32, 97, 110, 100, 32, 49, 49, 48, 49, 49, 49, 32, 105, 110, 32, 116, 104, 101, 32, 116, 97, 98, 108, 101, 32, 97, 98, 111, 118, 101, 226, 128, 148, 97, 114, 101, 32, 114, 101, 115, 101, 114, 118, 101, 100, 32, 115, 112, 101, 99, 105, 102, 105, 99, 97, 108, 108, 121, 32, 102, 111, 114, 32, 85, 84, 70, 45, 49, 54, 32, 101, 110, 99, 111, 100, 105, 110, 103, 44, 32, 97, 110, 100, 32, 100, 111, 110, 226, 128, 153, 116, 32, 114, 101, 112, 114, 101, 115, 101, 110, 116, 32, 97, 110, 121, 32, 118, 97, 108, 105, 100, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 32, 111, 110, 32, 116, 104, 101, 105, 114, 32, 111, 119, 110, 46, 32, 84, 104, 101, 121, 226, 128, 153, 114, 101, 32, 111, 110, 108, 121, 32, 109, 101, 97, 110, 116, 32, 116, 111, 32, 111, 99, 99, 117, 114, 32, 105, 110, 32, 116, 104, 101, 32, 50, 45, 119, 111, 114, 100, 32, 101, 110, 99, 111, 100, 105, 110, 103, 32, 112, 97, 116, 116, 101, 114, 110, 32, 97, 98, 111, 118, 101, 44, 32, 119, 104, 105, 99, 104, 32, 105, 115, 32, 99, 97, 108, 108, 101, 100, 32, 97, 32, 226, 128, 156, 115, 117, 114, 114, 111, 103, 97, 116, 101, 32, 112, 97, 105, 114, 226, 128, 157, 46, 32, 83, 117, 114, 114, 111, 103, 97, 116, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 97, 114, 101, 32, 105, 108, 108, 101, 103, 97, 108, 32, 105, 110, 32, 97, 110, 121, 32, 111, 116, 104, 101, 114, 32, 99, 111, 110, 116, 101, 120, 116, 33, 32, 84, 104, 101, 121, 226, 128, 153, 114, 101, 32, 110, 111, 116, 32, 97, 108, 108, 111, 119, 101, 100, 32, 105, 110, 32, 85, 84, 70, 45, 56, 32, 111, 114, 32, 85, 84, 70, 45, 51, 50, 32, 97, 116, 32, 97, 108, 108, 46, 32, 32, 72, 105, 115, 116, 111, 114, 105, 99, 97, 108, 108, 121, 44, 32, 85, 84, 70, 45, 49, 54, 32, 105, 115, 32, 97, 32, 100, 101, 115, 99, 101, 110, 100, 97, 110, 116, 32, 111, 102, 32, 116, 104, 101, 32, 111, 114, 105, 103, 105, 110, 97, 108, 44, 32, 112, 114, 101, 45, 49, 57, 57, 54, 32, 118, 101, 114, 115, 105, 111, 110, 115, 32, 111, 102, 32, 85, 110, 105, 99, 111, 100, 101, 44, 32, 105, 110, 32, 119, 104, 105, 99, 104, 32, 116, 104, 101, 114, 101, 32, 119, 101, 114, 101, 32, 111, 110, 108, 121, 32, 54, 53, 44, 53, 51, 54, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 46, 32, 84, 104, 101, 32, 111, 114, 105, 103, 105, 110, 97, 108, 32, 105, 110, 116, 101, 110, 116, 105, 111, 110, 32, 119, 97, 115, 32, 116, 104, 97, 116, 32, 116, 104, 101, 114, 101, 32, 119, 111, 117, 108, 100, 32, 98, 101, 32, 110, 111, 32, 100, 105, 102, 102, 101, 114, 101, 110, 116, 32, 226, 128, 156, 101, 110, 99, 111, 100, 105, 110, 103, 115, 226, 128, 157, 59, 32, 85, 110, 105, 99, 111, 100, 101, 32, 119, 97, 115, 32, 115, 117, 112, 112, 111, 115, 101, 100, 32, 116, 111, 32, 98, 101, 32, 97, 32, 115, 116, 114, 97, 105, 103, 104, 116, 102, 111, 114, 119, 97, 114, 100, 32, 49, 54, 45, 98, 105, 116, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 115, 101, 116, 46, 32, 76, 97, 116, 101, 114, 44, 32, 116, 104, 101, 32, 99, 111, 100, 101, 115, 112, 97, 99, 101, 32, 119, 97, 115, 32, 101, 120, 112, 97, 110, 100, 101, 100, 32, 116, 111, 32, 109, 97, 107, 101, 32, 114, 111, 111, 109, 32, 102, 111, 114, 32, 97, 32, 108, 111, 110, 103, 32, 116, 97, 105, 108, 32, 111, 102, 32, 108, 101, 115, 115, 45, 99, 111, 109, 109, 111, 110, 32, 40, 98, 117, 116, 32, 115, 116, 105, 108, 108, 32, 105, 109, 112, 111, 114, 116, 97, 110, 116, 41, 32, 72, 97, 110, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 44, 32, 119, 104, 105, 99, 104, 32, 116, 104, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 100, 101, 115, 105, 103, 110, 101, 114, 115, 32, 100, 105, 100, 110, 226, 128, 153, 116, 32, 111, 114, 105, 103, 105, 110, 97, 108, 108, 121, 32, 112, 108, 97, 110, 32, 102, 111, 114, 46, 32, 83, 117, 114, 114, 111, 103, 97, 116, 101, 115, 32, 119, 101, 114, 101, 32, 116, 104, 101, 110, 32, 105, 110, 116, 114, 111, 100, 117, 99, 101, 100, 44, 32, 97, 115, 226, 128, 148, 116, 111, 32, 112, 117, 116, 32, 105, 116, 32, 98, 108, 117, 110, 116, 108, 121, 226, 128, 148, 97, 32, 107, 108, 117, 100, 103, 101, 44, 32, 97, 108, 108, 111, 119, 105, 110, 103, 32, 49, 54, 45, 98, 105, 116, 32, 101, 110, 99, 111, 100, 105, 110, 103, 115, 32, 116, 111, 32, 97, 99, 99, 101, 115, 115, 32, 116, 104, 101, 32, 110, 101, 119, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 46, 32, 32, 84, 111, 100, 97, 121, 44, 32, 74, 97, 118, 97, 115, 99, 114, 105, 112, 116, 32, 117, 115, 101, 115, 32, 85, 84, 70, 45, 49, 54, 32, 97, 115, 32, 105, 116, 115, 32, 115, 116, 97, 110, 100, 97, 114, 100, 32, 115, 116, 114, 105, 110, 103, 32, 114, 101, 112, 114, 101, 115, 101, 110, 116, 97, 116, 105, 111, 110, 58, 32, 105, 102, 32, 121, 111, 117, 32, 97, 115, 107, 32, 102, 111, 114, 32, 116, 104, 101, 32, 108, 101, 110, 103, 116, 104, 32, 111, 102, 32, 97, 32, 115, 116, 114, 105, 110, 103, 44, 32, 111, 114, 32, 105, 116, 101, 114, 97, 116, 101, 32, 111, 118, 101, 114, 32, 105, 116, 44, 32, 101, 116, 99, 46, 44, 32, 116, 104, 101, 32, 114, 101, 115, 117, 108, 116, 32, 119, 105, 108, 108, 32, 98, 101, 32, 105, 110, 32, 85, 84, 70, 45, 49, 54, 32, 119, 111, 114, 100, 115, 44, 32, 119, 105, 116, 104, 32, 97, 110, 121, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 111, 117, 116, 115, 105, 100, 101, 32, 116, 104, 101, 32, 66, 77, 80, 32, 101, 120, 112, 114, 101, 115, 115, 101, 100, 32, 97, 115, 32, 115, 117, 114, 114, 111, 103, 97, 116, 101, 32, 112, 97, 105, 114, 115, 46, 32, 85, 84, 70, 45, 49, 54, 32, 105, 115, 32, 97, 108, 115, 111, 32, 117, 115, 101, 100, 32, 98, 121, 32, 116, 104, 101, 32, 77, 105, 99, 114, 111, 115, 111, 102, 116, 32, 87, 105, 110, 51, 50, 32, 65, 80, 73, 115, 59, 32, 116, 104, 111, 117, 103, 104, 32, 87, 105, 110, 51, 50, 32, 115, 117, 112, 112, 111, 114, 116, 115, 32, 101, 105, 116, 104, 101, 114, 32, 56, 45, 98, 105, 116, 32, 111, 114, 32, 49, 54, 45, 98, 105, 116, 32, 115, 116, 114, 105, 110, 103, 115, 44, 32, 116, 104, 101, 32, 56, 45, 98, 105, 116, 32, 118, 101, 114, 115, 105, 111, 110, 32, 117, 110, 97, 99, 99, 111, 117, 110, 116, 97, 98, 108, 121, 32, 115, 116, 105, 108, 108, 32, 100, 111, 101, 115, 110, 226, 128, 153, 116, 32, 115, 117, 112, 112, 111, 114, 116, 32, 85, 84, 70, 45, 56, 226, 128, 148, 111, 110, 108, 121, 32, 108, 101, 103, 97, 99, 121, 32, 99, 111, 100, 101, 45, 112, 97, 103, 101, 32, 101, 110, 99, 111, 100, 105, 110, 103, 115, 44, 32, 108, 105, 107, 101, 32, 65, 78, 83, 73, 46, 32, 84, 104, 105, 115, 32, 108, 101, 97, 118, 101, 115, 32, 85, 84, 70, 45, 49, 54, 32, 97, 115, 32, 116, 104, 101, 32, 111, 110, 108, 121, 32, 119, 97, 121, 32, 116, 111, 32, 103, 101, 116, 32, 112, 114, 111, 112, 101, 114, 32, 85, 110, 105, 99, 111, 100, 101, 32, 115, 117, 112, 112, 111, 114, 116, 32, 105, 110, 32, 87, 105, 110, 100, 111, 119, 115, 46, 32, 40, 85, 112, 100, 97, 116, 101, 58, 32, 105, 110, 32, 87, 105, 110, 49, 48, 32, 118, 101, 114, 115, 105, 111, 110, 32, 49, 57, 48, 51, 44, 32, 116, 104, 101, 121, 32, 102, 105, 110, 97, 108, 108, 121, 32, 97, 100, 100, 101, 100, 32, 85, 84, 70, 45, 56, 32, 115, 117, 112, 112, 111, 114, 116, 32, 116, 111, 32, 116, 104, 101, 32, 56, 45, 98, 105, 116, 32, 65, 80, 73, 115, 33, 32, 240, 159, 152, 138, 41, 32, 32, 66, 121, 32, 116, 104, 101, 32, 119, 97, 121, 44, 32, 85, 84, 70, 45, 49, 54, 226, 128, 153, 115, 32, 119, 111, 114, 100, 115, 32, 99, 97, 110, 32, 98, 101, 32, 115, 116, 111, 114, 101, 100, 32, 101, 105, 116, 104, 101, 114, 32, 108, 105, 116, 116, 108, 101, 45, 101, 110, 100, 105, 97, 110, 32, 111, 114, 32, 98, 105, 103, 45, 101, 110, 100, 105, 97, 110, 46, 32, 85, 110, 105, 99, 111, 100, 101, 32, 104, 97, 115, 32, 110, 111, 32, 111, 112, 105, 110, 105, 111, 110, 32, 111, 110, 32, 116, 104, 97, 116, 32, 105, 115, 115, 117, 101, 44, 32, 116, 104, 111, 117, 103, 104, 32, 105, 116, 32, 100, 111, 101, 115, 32, 101, 110, 99, 111, 117, 114, 97, 103, 101, 32, 116, 104, 101, 32, 99, 111, 110, 118, 101, 110, 116, 105, 111, 110, 32, 111, 102, 32, 112, 117, 116, 116, 105, 110, 103, 32, 85, 43, 70, 69, 70, 70, 32, 122, 101, 114, 111, 32, 119, 105, 100, 116, 104, 32, 110, 111, 45, 98, 114, 101, 97, 107, 32, 115, 112, 97, 99, 101, 32, 97, 116, 32, 116, 104, 101, 32, 116, 111, 112, 32, 111, 102, 32, 97, 32, 85, 84, 70, 45, 49, 54, 32, 102, 105, 108, 101, 32, 97, 115, 32, 97, 32, 98, 121, 116, 101, 45, 111, 114, 100, 101, 114, 32, 109, 97, 114, 107, 44, 32, 116, 111, 32, 100, 105, 115, 97, 109, 98, 105, 103, 117, 97, 116, 101, 32, 116, 104, 101, 32, 101, 110, 100, 105, 97, 110, 110, 101, 115, 115, 46, 32, 40, 73, 102, 32, 116, 104, 101, 32, 102, 105, 108, 101, 32, 100, 111, 101, 115, 110, 226, 128, 153, 116, 32, 109, 97, 116, 99, 104, 32, 116, 104, 101, 32, 115, 121, 115, 116, 101, 109, 226, 128, 153, 115, 32, 101, 110, 100, 105, 97, 110, 110, 101, 115, 115, 44, 32, 116, 104, 101, 32, 66, 79, 77, 32, 119, 105, 108, 108, 32, 98, 101, 32, 100, 101, 99, 111, 100, 101, 100, 32, 97, 115, 32, 85, 43, 70, 70, 70, 69, 44, 32, 119, 104, 105, 99, 104, 32, 105, 115, 110, 226, 128, 153, 116, 32, 97, 32, 118, 97, 108, 105, 100, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 46, 41, 32, 32, 67, 111, 109, 98, 105, 110, 105, 110, 103, 32, 77, 97, 114, 107, 115, 32, 73, 110, 32, 116, 104, 101, 32, 115, 116, 111, 114, 121, 32, 115, 111, 32, 102, 97, 114, 44, 32, 119, 101, 226, 128, 153, 118, 101, 32, 98, 101, 101, 110, 32, 102, 111, 99, 117, 115, 105, 110, 103, 32, 111, 110, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 46, 32, 66, 117, 116, 32, 105, 110, 32, 85, 110, 105, 99, 111, 100, 101, 44, 32, 97, 32, 226, 128, 156, 99, 104, 97, 114, 97, 99, 116, 101, 114, 226, 128, 157, 32, 99, 97, 110, 32, 98, 101, 32, 109, 111, 114, 101, 32, 99, 111, 109, 112, 108, 105, 99, 97, 116, 101, 100, 32, 116, 104, 97, 110, 32, 106, 117, 115, 116, 32, 97, 110, 32, 105, 110, 100, 105, 118, 105, 100, 117, 97, 108, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 33, 32, 32, 85, 110, 105, 99, 111, 100, 101, 32, 105, 110, 99, 108, 117, 100, 101, 115, 32, 97, 32, 115, 121, 115, 116, 101, 109, 32, 102, 111, 114, 32, 100, 121, 110, 97, 109, 105, 99, 97, 108, 108, 121, 32, 99, 111, 109, 112, 111, 115, 105, 110, 103, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 44, 32, 98, 121, 32, 99, 111, 109, 98, 105, 110, 105, 110, 103, 32, 109, 117, 108, 116, 105, 112, 108, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 116, 111, 103, 101, 116, 104, 101, 114, 46, 32, 84, 104, 105, 115, 32, 105, 115, 32, 117, 115, 101, 100, 32, 105, 110, 32, 118, 97, 114, 105, 111, 117, 115, 32, 119, 97, 121, 115, 32, 116, 111, 32, 103, 97, 105, 110, 32, 102, 108, 101, 120, 105, 98, 105, 108, 105, 116, 121, 32, 119, 105, 116, 104, 111, 117, 116, 32, 99, 97, 117, 115, 105, 110, 103, 32, 97, 32, 104, 117, 103, 101, 32, 99, 111, 109, 98, 105, 110, 97, 116, 111, 114, 105, 97, 108, 32, 101, 120, 112, 108, 111, 115, 105, 111, 110, 32, 105, 110, 32, 116, 104, 101, 32, 110, 117, 109, 98, 101, 114, 32, 111, 102, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 46, 32, 32, 73, 110, 32, 69, 117, 114, 111, 112, 101, 97, 110, 32, 108, 97, 110, 103, 117, 97, 103, 101, 115, 44, 32, 102, 111, 114, 32, 101, 120, 97, 109, 112, 108, 101, 44, 32, 116, 104, 105, 115, 32, 115, 104, 111, 119, 115, 32, 117, 112, 32, 105, 110, 32, 116, 104, 101, 32, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 32, 111, 102, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 116, 111, 32, 108, 101, 116, 116, 101, 114, 115, 46, 32, 85, 110, 105, 99, 111, 100, 101, 32, 115, 117, 112, 112, 111, 114, 116, 115, 32, 97, 32, 119, 105, 100, 101, 32, 114, 97, 110, 103, 101, 32, 111, 102, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 44, 32, 105, 110, 99, 108, 117, 100, 105, 110, 103, 32, 97, 99, 117, 116, 101, 32, 97, 110, 100, 32, 103, 114, 97, 118, 101, 32, 97, 99, 99, 101, 110, 116, 115, 44, 32, 117, 109, 108, 97, 117, 116, 115, 44, 32, 99, 101, 100, 105, 108, 108, 97, 115, 44, 32, 97, 110, 100, 32, 109, 97, 110, 121, 32, 109, 111, 114, 101, 46, 32, 65, 108, 108, 32, 116, 104, 101, 115, 101, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 99, 97, 110, 32, 98, 101, 32, 97, 112, 112, 108, 105, 101, 100, 32, 116, 111, 32, 97, 110, 121, 32, 108, 101, 116, 116, 101, 114, 32, 111, 102, 32, 97, 110, 121, 32, 97, 108, 112, 104, 97, 98, 101, 116, 226, 128, 148, 97, 110, 100, 32, 105, 110, 32, 102, 97, 99, 116, 44, 32, 109, 117, 108, 116, 105, 112, 108, 101, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 99, 97, 110, 32, 98, 101, 32, 117, 115, 101, 100, 32, 111, 110, 32, 97, 32, 115, 105, 110, 103, 108, 101, 32, 108, 101, 116, 116, 101, 114, 46, 32, 32, 73, 102, 32, 85, 110, 105, 99, 111, 100, 101, 32, 116, 114, 105, 101, 100, 32, 116, 111, 32, 97, 115, 115, 105, 103, 110, 32, 97, 32, 100, 105, 115, 116, 105, 110, 99, 116, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 116, 111, 32, 101, 118, 101, 114, 121, 32, 112, 111, 115, 115, 105, 98, 108, 101, 32, 99, 111, 109, 98, 105, 110, 97, 116, 105, 111, 110, 32, 111, 102, 32, 108, 101, 116, 116, 101, 114, 32, 97, 110, 100, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 44, 32, 116, 104, 105, 110, 103, 115, 32, 119, 111, 117, 108, 100, 32, 114, 97, 112, 105, 100, 108, 121, 32, 103, 101, 116, 32, 111, 117, 116, 32, 111, 102, 32, 104, 97, 110, 100, 46, 32, 73, 110, 115, 116, 101, 97, 100, 44, 32, 116, 104, 101, 32, 100, 121, 110, 97, 109, 105, 99, 32, 99, 111, 109, 112, 111, 115, 105, 116, 105, 111, 110, 32, 115, 121, 115, 116, 101, 109, 32, 101, 110, 97, 98, 108, 101, 115, 32, 121, 111, 117, 32, 116, 111, 32, 99, 111, 110, 115, 116, 114, 117, 99, 116, 32, 116, 104, 101, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 121, 111, 117, 32, 119, 97, 110, 116, 44, 32, 98, 121, 32, 115, 116, 97, 114, 116, 105, 110, 103, 32, 119, 105, 116, 104, 32, 97, 32, 98, 97, 115, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 40, 116, 104, 101, 32, 108, 101, 116, 116, 101, 114, 41, 32, 97, 110, 100, 32, 97, 112, 112, 101, 110, 100, 105, 110, 103, 32, 97, 100, 100, 105, 116, 105, 111, 110, 97, 108, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 44, 32, 99, 97, 108, 108, 101, 100, 32, 226, 128, 156, 99, 111, 109, 98, 105, 110, 105, 110, 103, 32, 109, 97, 114, 107, 115, 226, 128, 157, 44, 32, 116, 111, 32, 115, 112, 101, 99, 105, 102, 121, 32, 116, 104, 101, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 46, 32, 87, 104, 101, 110, 32, 97, 32, 116, 101, 120, 116, 32, 114, 101, 110, 100, 101, 114, 101, 114, 32, 115, 101, 101, 115, 32, 97, 32, 115, 101, 113, 117, 101, 110, 99, 101, 32, 108, 105, 107, 101, 32, 116, 104, 105, 115, 32, 105, 110, 32, 97, 32, 115, 116, 114, 105, 110, 103, 44, 32, 105, 116, 32, 97, 117, 116, 111, 109, 97, 116, 105, 99, 97, 108, 108, 121, 32, 115, 116, 97, 99, 107, 115, 32, 116, 104, 101, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 111, 118, 101, 114, 32, 111, 114, 32, 117, 110, 100, 101, 114, 32, 116, 104, 101, 32, 98, 97, 115, 101, 32, 108, 101, 116, 116, 101, 114, 32, 116, 111, 32, 99, 114, 101, 97, 116, 101, 32, 97, 32, 99, 111, 109, 112, 111, 115, 101, 100, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 46, 32, 32, 70, 111, 114, 32, 101, 120, 97, 109, 112, 108, 101, 44, 32, 116, 104, 101, 32, 97, 99, 99, 101, 110, 116, 101, 100, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 226, 128, 156, 195, 129, 226, 128, 157, 32, 99, 97, 110, 32, 98, 101, 32, 101, 120, 112, 114, 101, 115, 115, 101, 100, 32, 97, 115, 32, 97, 32, 115, 116, 114, 105, 110, 103, 32, 111, 102, 32, 116, 119, 111, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 58, 32, 85, 43, 48, 48, 52, 49, 32, 226, 128, 156, 65, 226, 128, 157, 32, 108, 97, 116, 105, 110, 32, 99, 97, 112, 105, 116, 97, 108, 32, 108, 101, 116, 116, 101, 114, 32, 97, 32, 112, 108, 117, 115, 32, 85, 43, 48, 51, 48, 49, 32, 226, 128, 156, 226, 151, 140, 204, 129, 226, 128, 157, 32, 99, 111, 109, 98, 105, 110, 105, 110, 103, 32, 97, 99, 117, 116, 101, 32, 97, 99, 99, 101, 110, 116, 46, 32, 84, 104, 105, 115, 32, 115, 116, 114, 105, 110, 103, 32, 97, 117, 116, 111, 109, 97, 116, 105, 99, 97, 108, 108, 121, 32, 103, 101, 116, 115, 32, 114, 101, 110, 100, 101, 114, 101, 100, 32, 97, 115, 32, 97, 32, 115, 105, 110, 103, 108, 101, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 58, 32, 226, 128, 156, 195, 129, 226, 128, 157, 46, 32, 32, 78, 111, 119, 44, 32, 85, 110, 105, 99, 111, 100, 101, 32, 100, 111, 101, 115, 32, 97, 108, 115, 111, 32, 105, 110, 99, 108, 117, 100, 101, 32, 109, 97, 110, 121, 32, 226, 128, 156, 112, 114, 101, 99, 111, 109, 112, 111, 115, 101, 100, 226, 128, 157, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 44, 32, 101, 97, 99, 104, 32, 114, 101, 112, 114, 101, 115, 101, 110, 116, 105, 110, 103, 32, 97, 32, 108, 101, 116, 116, 101, 114, 32, 119, 105, 116, 104, 32, 115, 111, 109, 101, 32, 99, 111, 109, 98, 105, 110, 97, 116, 105, 111, 110, 32, 111, 102, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 97, 108, 114, 101, 97, 100, 121, 32, 97, 112, 112, 108, 105, 101, 100, 44, 32, 115, 117, 99, 104, 32, 97, 115, 32, 85, 43, 48, 48, 67, 49, 32, 226, 128, 156, 195, 129, 226, 128, 157, 32, 108, 97, 116, 105, 110, 32, 99, 97, 112, 105, 116, 97, 108, 32, 108, 101, 116, 116, 101, 114, 32, 97, 32, 119, 105, 116, 104, 32, 97, 99, 117, 116, 101, 32, 111, 114, 32, 85, 43, 49, 69, 67, 55, 32, 226, 128, 156, 225, 187, 135, 226, 128, 157, 32, 108, 97, 116, 105, 110, 32, 115, 109, 97, 108, 108, 32, 108, 101, 116, 116, 101, 114, 32, 101, 32, 119, 105, 116, 104, 32, 99, 105, 114, 99, 117, 109, 102, 108, 101, 120, 32, 97, 110, 100, 32, 100, 111, 116, 32, 98, 101, 108, 111, 119, 46, 32, 73, 32, 115, 117, 115, 112, 101, 99, 116, 32, 116, 104, 101, 115, 101, 32, 97, 114, 101, 32, 109, 111, 115, 116, 108, 121, 32, 105, 110, 104, 101, 114, 105, 116, 101, 100, 32, 102, 114, 111, 109, 32, 111, 108, 100, 101, 114, 32, 101, 110, 99, 111, 100, 105, 110, 103, 115, 32, 116, 104, 97, 116, 32, 119, 101, 114, 101, 32, 97, 115, 115, 105, 109, 105, 108, 97, 116, 101, 100, 32, 105, 110, 116, 111, 32, 85, 110, 105, 99, 111, 100, 101, 44, 32, 97, 110, 100, 32, 107, 101, 112, 116, 32, 97, 114, 111, 117, 110, 100, 32, 102, 111, 114, 32, 99, 111, 109, 112, 97, 116, 105, 98, 105, 108, 105, 116, 121, 46, 32, 73, 110, 32, 112, 114, 97, 99, 116, 105, 99, 101, 44, 32, 116, 104, 101, 114, 101, 32, 97, 114, 101, 32, 112, 114, 101, 99, 111, 109, 112, 111, 115, 101, 100, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 102, 111, 114, 32, 109, 111, 115, 116, 32, 111, 102, 32, 116, 104, 101, 32, 99, 111, 109, 109, 111, 110, 32, 108, 101, 116, 116, 101, 114, 45, 119, 105, 116, 104, 45, 100, 105, 97, 99, 114, 105, 116, 105, 99, 32, 99, 111, 109, 98, 105, 110, 97, 116, 105, 111, 110, 115, 32, 105, 110, 32, 69, 117, 114, 111, 112, 101, 97, 110, 45, 115, 99, 114, 105, 112, 116, 32, 108, 97, 110, 103, 117, 97, 103, 101, 115, 44, 32, 115, 111, 32, 116, 104, 101, 121, 32, 100, 111, 110, 226, 128, 153, 116, 32, 117, 115, 101, 32, 100, 121, 110, 97, 109, 105, 99, 32, 99, 111, 109, 112, 111, 115, 105, 116, 105, 111, 110, 32, 116, 104, 97, 116, 32, 109, 117, 99, 104, 32, 105, 110, 32, 116, 121, 112, 105, 99, 97, 108, 32, 116, 101, 120, 116, 46, 32, 32, 83, 116, 105, 108, 108, 44, 32, 116, 104, 101, 32, 115, 121, 115, 116, 101, 109, 32, 111, 102, 32, 99, 111, 109, 98, 105, 110, 105, 110, 103, 32, 109, 97, 114, 107, 115, 32, 100, 111, 101, 115, 32, 97, 108, 108, 111, 119, 32, 102, 111, 114, 32, 97, 110, 32, 97, 114, 98, 105, 116, 114, 97, 114, 121, 32, 110, 117, 109, 98, 101, 114, 32, 111, 102, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 116, 111, 32, 98, 101, 32, 115, 116, 97, 99, 107, 101, 100, 32, 111, 110, 32, 97, 110, 121, 32, 98, 97, 115, 101, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 46, 32, 84, 104, 101, 32, 114, 101, 100, 117, 99, 116, 105, 111, 45, 97, 100, 45, 97, 98, 115, 117, 114, 100, 117, 109, 32, 111, 102, 32, 116, 104, 105, 115, 32, 105, 115, 32, 90, 97, 108, 103, 111, 32, 116, 101, 120, 116, 44, 32, 119, 104, 105, 99, 104, 32, 119, 111, 114, 107, 115, 32, 98, 121, 32, 205, 150, 205, 159, 205, 133, 114, 205, 158, 97, 225, 185, 139, 204, 171, 204, 160, 204, 150, 205, 136, 204, 151, 100, 205, 150, 204, 187, 204, 185, 195, 179, 109, 204, 170, 205, 153, 205, 149, 204, 151, 204, 157, 196, 188, 205, 135, 204, 176, 205, 147, 204, 179, 204, 171, 195, 189, 205, 147, 204, 165, 204, 159, 205, 141, 32, 204, 149, 115, 204, 171, 116, 204, 171, 204, 177, 205, 149, 204, 151, 204, 176, 204, 188, 204, 152, 205, 156, 97, 204, 188, 204, 169, 205, 150, 205, 135, 204, 160, 205, 136, 204, 163, 205, 157, 99, 204, 153, 205, 141, 107, 204, 150, 204, 177, 204, 185, 205, 141, 205, 152, 105, 204, 162, 110, 204, 168, 204, 186, 204, 157, 205, 135, 205, 135, 204, 159, 205, 153, 196, 163, 204, 171, 204, 174, 205, 142, 204, 187, 204, 159, 205, 133, 32, 204, 149, 110, 204, 188, 204, 186, 205, 136, 205, 158, 117, 204, 174, 205, 153, 109, 204, 186, 204, 173, 204, 159, 204, 151, 205, 158, 101, 204, 158, 205, 147, 204, 176, 204, 164, 205, 147, 204, 171, 114, 204, 181, 111, 204, 150, 225, 185, 183, 115, 210, 137, 204, 170, 205, 141, 204, 173, 204, 172, 204, 157, 204, 164, 32, 204, 174, 205, 137, 204, 157, 204, 158, 204, 151, 204, 159, 205, 160, 100, 204, 180, 204, 159, 204, 156, 204, 177, 205, 149, 205, 154, 105, 205, 135, 204, 171, 204, 188, 204, 175, 204, 173, 204, 156, 205, 161, 225, 184, 129, 205, 153, 204, 187, 204, 188, 99, 204, 178, 204, 178, 204, 185, 114, 204, 168, 204, 160, 204, 185, 204, 163, 204, 176, 204, 166, 105, 204, 177, 116, 204, 164, 204, 187, 204, 164, 205, 141, 205, 153, 204, 152, 204, 149, 105, 204, 181, 204, 156, 204, 173, 204, 164, 204, 177, 205, 142, 99, 204, 181, 115, 32, 205, 152, 111, 204, 177, 204, 178, 205, 136, 204, 153, 205, 150, 205, 135, 204, 178, 205, 162, 110, 205, 152, 32, 204, 156, 205, 136, 101, 204, 172, 204, 178, 204, 160, 204, 169, 97, 99, 205, 149, 204, 186, 204, 160, 205, 137, 104, 204, 183, 204, 170, 32, 204, 186, 204, 163, 205, 150, 204, 177, 225, 184, 187, 204, 171, 204, 172, 204, 157, 204, 185, 225, 184, 153, 204, 153, 204, 186, 205, 153, 204, 173, 205, 147, 204, 178, 116, 204, 158, 204, 158, 205, 135, 204, 178, 205, 137, 205, 141, 116, 204, 183, 205, 148, 204, 170, 205, 137, 204, 178, 204, 187, 204, 160, 205, 153, 101, 204, 166, 204, 187, 205, 136, 205, 137, 205, 135, 114, 205, 135, 204, 173, 204, 173, 204, 172, 205, 150, 44, 204, 150, 204, 129, 32, 204, 156, 205, 153, 205, 147, 204, 163, 204, 173, 115, 204, 152, 204, 152, 205, 136, 111, 204, 177, 204, 176, 204, 164, 204, 178, 205, 133, 32, 204, 155, 204, 172, 204, 156, 204, 153, 116, 204, 188, 204, 166, 205, 149, 204, 177, 204, 185, 205, 149, 204, 165, 104, 204, 179, 204, 178, 205, 136, 205, 157, 205, 133, 97, 204, 166, 116, 204, 187, 204, 178, 32, 204, 187, 204, 159, 204, 173, 204, 166, 204, 150, 116, 204, 155, 204, 176, 204, 169, 104, 204, 160, 205, 149, 204, 179, 204, 157, 204, 171, 205, 149, 101, 205, 136, 204, 164, 204, 152, 205, 150, 204, 158, 205, 152, 121, 210, 137, 204, 157, 205, 153, 32, 204, 183, 205, 137, 205, 148, 204, 176, 204, 160, 111, 204, 158, 204, 176, 118, 205, 136, 205, 136, 204, 179, 204, 152, 205, 156, 101, 114, 204, 182, 102, 204, 176, 205, 136, 205, 148, 225, 184, 187, 205, 149, 204, 152, 204, 171, 204, 186, 204, 178, 111, 204, 178, 204, 173, 205, 153, 205, 160, 205, 133, 119, 204, 177, 204, 179, 204, 186, 32, 205, 156, 116, 204, 184, 104, 205, 135, 204, 173, 205, 149, 204, 179, 205, 141, 101, 204, 150, 204, 175, 204, 159, 204, 160, 32, 205, 141, 204, 158, 204, 156, 205, 148, 204, 169, 204, 170, 205, 156, 196, 188, 205, 142, 204, 170, 204, 178, 205, 154, 105, 204, 157, 204, 178, 204, 185, 204, 153, 204, 169, 204, 185, 110, 204, 168, 204, 166, 204, 169, 204, 150, 225, 184, 153, 204, 188, 204, 178, 204, 188, 205, 162, 205, 133, 32, 204, 172, 205, 157, 115, 204, 188, 205, 154, 204, 152, 204, 158, 205, 157, 112, 205, 153, 204, 152, 204, 187, 97, 204, 153, 99, 210, 137, 205, 137, 204, 156, 204, 164, 205, 136, 204, 175, 204, 150, 105, 204, 165, 205, 161, 110, 204, 166, 204, 160, 204, 177, 205, 159, 103, 204, 184, 204, 151, 204, 187, 204, 166, 204, 173, 204, 174, 204, 159, 205, 133, 32, 204, 179, 204, 170, 204, 160, 205, 150, 204, 179, 204, 175, 204, 149, 97, 204, 171, 205, 156, 110, 205, 157, 100, 205, 161, 32, 204, 163, 204, 166, 204, 153, 205, 133, 99, 204, 170, 204, 151, 114, 204, 180, 205, 153, 204, 174, 204, 166, 204, 185, 204, 179, 101, 205, 135, 205, 154, 204, 158, 205, 148, 204, 185, 204, 171, 205, 159, 97, 204, 153, 204, 186, 204, 153, 200, 155, 205, 148, 205, 142, 204, 152, 204, 185, 205, 133, 101, 204, 165, 204, 169, 205, 141, 32, 97, 205, 150, 204, 170, 204, 156, 204, 174, 205, 153, 204, 185, 110, 204, 162, 205, 137, 204, 157, 32, 205, 135, 205, 137, 205, 147, 204, 166, 204, 188, 204, 129, 97, 204, 179, 205, 150, 204, 170, 204, 164, 204, 177, 112, 204, 150, 205, 148, 205, 148, 204, 159, 205, 135, 205, 142, 205, 160, 112, 204, 177, 205, 141, 204, 186, 196, 153, 204, 178, 205, 142, 205, 136, 204, 176, 204, 178, 204, 164, 204, 171, 97, 204, 175, 205, 156, 114, 204, 168, 204, 174, 204, 171, 204, 163, 204, 152, 97, 204, 169, 204, 175, 205, 150, 110, 204, 185, 204, 166, 204, 176, 205, 142, 204, 163, 204, 158, 204, 158, 99, 204, 168, 204, 166, 204, 177, 205, 148, 205, 142, 205, 141, 205, 150, 101, 204, 172, 205, 147, 205, 152, 32, 204, 164, 204, 176, 204, 169, 205, 153, 204, 164, 204, 172, 205, 153, 111, 204, 181, 204, 188, 204, 187, 204, 172, 204, 187, 205, 135, 204, 174, 204, 170, 102, 204, 180, 32, 204, 161, 204, 153, 204, 173, 205, 147, 205, 150, 204, 170, 204, 164, 226, 128, 156, 204, 184, 205, 153, 204, 160, 204, 188, 99, 204, 179, 204, 151, 205, 156, 111, 205, 143, 204, 188, 205, 153, 205, 148, 204, 174, 114, 204, 158, 204, 171, 204, 186, 204, 158, 204, 165, 204, 172, 114, 117, 204, 186, 204, 187, 204, 175, 205, 137, 204, 173, 204, 187, 204, 175, 112, 204, 176, 204, 165, 205, 147, 204, 163, 204, 171, 204, 153, 204, 164, 205, 162, 116, 204, 179, 205, 141, 204, 179, 204, 150, 205, 133, 105, 204, 182, 205, 136, 204, 157, 205, 153, 204, 188, 204, 153, 204, 185, 111, 204, 161, 205, 148, 110, 204, 153, 204, 186, 204, 185, 204, 150, 204, 169, 205, 157, 205, 133, 226, 128, 157, 204, 168, 204, 151, 205, 150, 205, 154, 204, 169, 46, 204, 175, 205, 147, 32, 32, 65, 32, 102, 101, 119, 32, 111, 116, 104, 101, 114, 32, 112, 108, 97, 99, 101, 115, 32, 119, 104, 101, 114, 101, 32, 100, 121, 110, 97, 109, 105, 99, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 99, 111, 109, 112, 111, 115, 105, 116, 105, 111, 110, 32, 115, 104, 111, 119, 115, 32, 117, 112, 32, 105, 110, 32, 85, 110, 105, 99, 111, 100, 101, 58, 32, 32, 86, 111, 119, 101, 108, 45, 112, 111, 105, 110, 116, 105, 110, 103, 32, 110, 111, 116, 97, 116, 105, 111, 110, 32, 105, 110, 32, 65, 114, 97, 98, 105, 99, 32, 97, 110, 100, 32, 72, 101, 98, 114, 101, 119, 46, 32, 73, 110, 32, 116, 104, 101, 115, 101, 32, 108, 97, 110, 103, 117, 97, 103, 101, 115, 44, 32, 119, 111, 114, 100, 115, 32, 97, 114, 101, 32, 110, 111, 114, 109, 97, 108, 108, 121, 32, 115, 112, 101, 108, 108, 101, 100, 32, 119, 105, 116, 104, 32, 115, 111, 109, 101, 32, 111, 102, 32, 116, 104, 101, 105, 114, 32, 118, 111, 119, 101, 108, 115, 32, 108, 101, 102, 116, 32, 111, 117, 116, 46, 32, 84, 104, 101, 121, 32, 116, 104, 101, 110, 32, 104, 97, 118, 101, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 32, 110, 111, 116, 97, 116, 105, 111, 110, 32, 116, 111, 32, 105, 110, 100, 105, 99, 97, 116, 101, 32, 116, 104, 101, 32, 118, 111, 119, 101, 108, 115, 32, 40, 117, 115, 101, 100, 32, 105, 110, 32, 100, 105, 99, 116, 105, 111, 110, 97, 114, 105, 101, 115, 44, 32, 108, 97, 110, 103, 117, 97, 103, 101, 45, 116, 101, 97, 99, 104, 105, 110, 103, 32, 109, 97, 116, 101, 114, 105, 97, 108, 115, 44, 32, 99, 104, 105, 108, 100, 114, 101, 110, 226, 128, 153, 115, 32, 98, 111, 111, 107, 115, 44, 32, 97, 110, 100, 32, 115, 117, 99, 104, 41, 46, 32, 84, 104, 101, 115, 101, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 97, 114, 101, 32, 101, 120, 112, 114, 101, 115, 115, 101, 100, 32, 119, 105, 116, 104, 32, 99, 111, 109, 98, 105, 110, 105, 110, 103, 32, 109, 97, 114, 107, 115, 46, 32, 32, 65, 32, 72, 101, 98, 114, 101, 119, 32, 101, 120, 97, 109, 112, 108, 101, 44, 32, 119, 105, 116, 104, 32, 110, 105, 113, 113, 117, 100, 58, 9, 215, 144, 214, 182, 215, 170, 32, 215, 147, 214, 183, 215, 156, 214, 176, 215, 170, 214, 180, 214, 188, 215, 153, 32, 215, 148, 214, 181, 215, 150, 214, 180, 215, 153, 215, 150, 32, 215, 148, 214, 181, 215, 160, 214, 180, 215, 153, 215, 162, 214, 183, 44, 32, 215, 167, 214, 182, 215, 152, 214, 182, 215, 145, 32, 215, 156, 214, 180, 215, 169, 214, 176, 215, 129, 215, 155, 214, 183, 214, 188, 215, 170, 214, 180, 214, 188, 215, 153, 32, 215, 153, 214, 184, 215, 169, 215, 129, 215, 149, 214, 185, 215, 147, 32, 78, 111, 114, 109, 97, 108, 32, 119, 114, 105, 116, 105, 110, 103, 32, 40, 110, 111, 32, 110, 105, 113, 113, 117, 100, 41, 58, 9, 215, 144, 215, 170, 32, 215, 147, 215, 156, 215, 170, 215, 153, 32, 215, 148, 215, 150, 215, 153, 215, 150, 32, 215, 148, 215, 160, 215, 153, 215, 162, 44, 32, 215, 167, 215, 152, 215, 145, 32, 215, 156, 215, 169, 215, 155, 215, 170, 215, 153, 32, 215, 153, 215, 169, 215, 149, 215, 147, 32, 68, 101, 118, 97, 110, 97, 103, 97, 114, 105, 44, 32, 116, 104, 101, 32, 115, 99, 114, 105, 112, 116, 32, 117, 115, 101, 100, 32, 116, 111, 32, 119, 114, 105, 116, 101, 32, 72, 105, 110, 100, 105, 44, 32, 83, 97, 110, 115, 107, 114, 105, 116, 44, 32, 97, 110, 100, 32, 109, 97, 110, 121, 32, 111, 116, 104, 101, 114, 32, 83, 111, 117, 116, 104, 32, 65, 115, 105, 97, 110, 32, 108, 97, 110, 103, 117, 97, 103, 101, 115, 44, 32, 101, 120, 112, 114, 101, 115, 115, 101, 115, 32, 99, 101, 114, 116, 97, 105, 110, 32, 118, 111, 119, 101, 108, 115, 32, 97, 115, 32, 99, 111, 109, 98, 105, 110, 105, 110, 103, 32, 109, 97, 114, 107, 115, 32, 97, 116, 116, 97, 99, 104, 101, 100, 32, 116, 111, 32, 99, 111, 110, 115, 111, 110, 97, 110, 116, 32, 108, 101, 116, 116, 101, 114, 115, 46, 32, 70, 111, 114, 32, 101, 120, 97, 109, 112, 108, 101, 44, 32, 226, 128, 156, 224, 164, 185, 226, 128, 157, 32, 43, 32, 226, 128, 156, 226, 128, 139, 224, 164, 191, 226, 128, 157, 32, 61, 32, 226, 128, 156, 224, 164, 185, 224, 164, 191, 226, 128, 157, 32, 40, 226, 128, 156, 104, 226, 128, 157, 32, 43, 32, 226, 128, 156, 105, 226, 128, 157, 32, 61, 32, 226, 128, 156, 104, 105, 226, 128, 157, 41, 46, 32, 75, 111, 114, 101, 97, 110, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 32, 115, 116, 97, 110, 100, 32, 102, 111, 114, 32, 115, 121, 108, 108, 97, 98, 108, 101, 115, 44, 32, 98, 117, 116, 32, 116, 104, 101, 121, 32, 97, 114, 101, 32, 99, 111, 109, 112, 111, 115, 101, 100, 32, 111, 102, 32, 108, 101, 116, 116, 101, 114, 115, 32, 99, 97, 108, 108, 101, 100, 32, 106, 97, 109, 111, 32, 116, 104, 97, 116, 32, 115, 116, 97, 110, 100, 32, 102, 111, 114, 32, 116, 104, 101, 32, 118, 111, 119, 101, 108, 115, 32, 97, 110, 100, 32, 99, 111, 110, 115, 111, 110, 97, 110, 116, 115, 32, 105, 110, 32, 116, 104, 101, 32, 115, 121, 108, 108, 97, 98, 108, 101, 46, 32, 87, 104, 105, 108, 101, 32, 116, 104, 101, 114, 101, 32, 97, 114, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 102, 111, 114, 32, 112, 114, 101, 99, 111, 109, 112, 111, 115, 101, 100, 32, 75, 111, 114, 101, 97, 110, 32, 115, 121, 108, 108, 97, 98, 108, 101, 115, 44, 32, 105, 116, 226, 128, 153, 115, 32, 97, 108, 115, 111, 32, 112, 111, 115, 115, 105, 98, 108, 101, 32, 116, 111, 32, 100, 121, 110, 97, 109, 105, 99, 97, 108, 108, 121, 32, 99, 111, 109, 112, 111, 115, 101, 32, 116, 104, 101, 109, 32, 98, 121, 32, 99, 111, 110, 99, 97, 116, 101, 110, 97, 116, 105, 110, 103, 32, 116, 104, 101, 105, 114, 32, 106, 97, 109, 111, 46, 32, 70, 111, 114, 32, 101, 120, 97, 109, 112, 108, 101, 44, 32, 226, 128, 156, 225, 132, 146, 226, 128, 157, 32, 43, 32, 226, 128, 156, 225, 133, 161, 226, 128, 157, 32, 43, 32, 226, 128, 156, 225, 134, 171, 226, 128, 157, 32, 61, 32, 226, 128, 156, 237, 149, 156, 226, 128, 157, 32, 40, 226, 128, 156, 104, 226, 128, 157, 32, 43, 32, 226, 128, 156, 97, 226, 128, 157, 32, 43, 32, 226, 128, 156, 110, 226, 128, 157, 32, 61, 32, 226, 128, 156, 104, 97, 110, 226, 128, 157, 41, 46, 32, 67, 97, 110, 111, 110, 105, 99, 97, 108, 32, 69, 113, 117, 105, 118, 97, 108, 101, 110, 99, 101, 32, 73, 110, 32, 85, 110, 105, 99, 111, 100, 101, 44, 32, 112, 114, 101, 99, 111, 109, 112, 111, 115, 101, 100, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 32, 101, 120, 105, 115, 116, 32, 97, 108, 111, 110, 103, 115, 105, 100, 101, 32, 116, 104, 101, 32, 100, 121, 110, 97, 109, 105, 99, 32, 99, 111, 109, 112, 111, 115, 105, 116, 105, 111, 110, 32, 115, 121, 115, 116, 101, 109, 46, 32, 65, 32, 99, 111, 110, 115, 101, 113, 117, 101, 110, 99, 101, 32, 111, 102, 32, 116, 104, 105, 115, 32, 105, 115, 32, 116, 104, 97, 116, 32, 116, 104, 101, 114, 101, 32, 97, 114, 101, 32, 109, 117, 108, 116, 105, 112, 108, 101, 32, 119, 97, 121, 115, 32, 116, 111, 32, 101, 120, 112, 114, 101, 115, 115, 32, 226, 128, 156, 116, 104, 101, 32, 115, 97, 109, 101, 226, 128, 157, 32, 115, 116, 114, 105, 110, 103, 226, 128, 148, 100, 105, 102, 102, 101, 114, 101, 110, 116, 32, 115, 101, 113, 117, 101, 110, 99, 101, 115, 32, 111, 102, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 116, 104, 97, 116, 32, 114, 101, 115, 117, 108, 116, 32, 105, 110, 32, 116, 104, 101, 32, 115, 97, 109, 101, 32, 117, 115, 101, 114, 45, 112, 101, 114, 99, 101, 105, 118, 101, 100, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 46, 32, 70, 111, 114, 32, 101, 120, 97, 109, 112, 108, 101, 44, 32, 97, 115, 32, 119, 101, 32, 115, 97, 119, 32, 101, 97, 114, 108, 105, 101, 114, 44, 32, 119, 101, 32, 99, 97, 110, 32, 101, 120, 112, 114, 101, 115, 115, 32, 116, 104, 101, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 226, 128, 156, 195, 129, 226, 128, 157, 32, 101, 105, 116, 104, 101, 114, 32, 97, 115, 32, 116, 104, 101, 32, 115, 105, 110, 103, 108, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 85, 43, 48, 48, 67, 49, 44, 32, 111, 114, 32, 97, 115, 32, 116, 104, 101, 32, 115, 116, 114, 105, 110, 103, 32, 111, 102, 32, 116, 119, 111, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 85, 43, 48, 48, 52, 49, 32, 85, 43, 48, 51, 48, 49, 46, 32, 32, 65, 110, 111, 116, 104, 101, 114, 32, 115, 111, 117, 114, 99, 101, 32, 111, 102, 32, 97, 109, 98, 105, 103, 117, 105, 116, 121, 32, 105, 115, 32, 116, 104, 101, 32, 111, 114, 100, 101, 114, 105, 110, 103, 32, 111, 102, 32, 109, 117, 108, 116, 105, 112, 108, 101, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 105, 110, 32, 97, 32, 115, 105, 110, 103, 108, 101, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 46, 32, 68, 105, 97, 99, 114, 105, 116, 105, 99, 32, 111, 114, 100, 101, 114, 32, 109, 97, 116, 116, 101, 114, 115, 32, 118, 105, 115, 117, 97, 108, 108, 121, 32, 119, 104, 101, 110, 32, 116, 119, 111, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 97, 112, 112, 108, 121, 32, 116, 111, 32, 116, 104, 101, 32, 115, 97, 109, 101, 32, 115, 105, 100, 101, 32, 111, 102, 32, 116, 104, 101, 32, 98, 97, 115, 101, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 44, 32, 101, 46, 103, 46, 32, 98, 111, 116, 104, 32, 97, 98, 111, 118, 101, 58, 32, 226, 128, 156, 199, 161, 226, 128, 157, 32, 40, 100, 111, 116, 44, 32, 116, 104, 101, 110, 32, 109, 97, 99, 114, 111, 110, 41, 32, 105, 115, 32, 100, 105, 102, 102, 101, 114, 101, 110, 116, 32, 102, 114, 111, 109, 32, 226, 128, 156, 196, 129, 204, 135, 226, 128, 157, 32, 40, 109, 97, 99, 114, 111, 110, 44, 32, 116, 104, 101, 110, 32, 100, 111, 116, 41, 46, 32, 72, 111, 119, 101, 118, 101, 114, 44, 32, 119, 104, 101, 110, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 97, 112, 112, 108, 121, 32, 116, 111, 32, 100, 105, 102, 102, 101, 114, 101, 110, 116, 32, 115, 105, 100, 101, 115, 32, 111, 102, 32, 116, 104, 101, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 44, 32, 101, 46, 103, 46, 32, 111, 110, 101, 32, 97, 98, 111, 118, 101, 32, 97, 110, 100, 32, 111, 110, 101, 32, 98, 101, 108, 111, 119, 44, 32, 116, 104, 101, 110, 32, 116, 104, 101, 32, 111, 114, 100, 101, 114, 32, 100, 111, 101, 115, 110, 226, 128, 153, 116, 32, 97, 102, 102, 101, 99, 116, 32, 114, 101, 110, 100, 101, 114, 105, 110, 103, 46, 32, 77, 111, 114, 101, 111, 118, 101, 114, 44, 32, 97, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 119, 105, 116, 104, 32, 109, 117, 108, 116, 105, 112, 108, 101, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 109, 105, 103, 104, 116, 32, 104, 97, 118, 101, 32, 111, 110, 101, 32, 111, 102, 32, 116, 104, 101, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 112, 114, 101, 99, 111, 109, 112, 111, 115, 101, 100, 32, 97, 110, 100, 32, 111, 116, 104, 101, 114, 115, 32, 101, 120, 112, 114, 101, 115, 115, 101, 100, 32, 97, 115, 32, 99, 111, 109, 98, 105, 110, 105, 110, 103, 32, 109, 97, 114, 107, 115, 46, 32, 32, 70, 111, 114, 32, 101, 120, 97, 109, 112, 108, 101, 44, 32, 116, 104, 101, 32, 86, 105, 101, 116, 110, 97, 109, 101, 115, 101, 32, 108, 101, 116, 116, 101, 114, 32, 226, 128, 156, 225, 187, 135, 226, 128, 157, 32, 99, 97, 110, 32, 98, 101, 32, 101, 120, 112, 114, 101, 115, 115, 101, 100, 32, 105, 110, 32, 102, 105, 118, 101, 32, 100, 105, 102, 102, 101, 114, 101, 110, 116, 32, 119, 97, 121, 115, 58, 32, 32, 70, 117, 108, 108, 121, 32, 112, 114, 101, 99, 111, 109, 112, 111, 115, 101, 100, 58, 32, 85, 43, 49, 69, 67, 55, 32, 226, 128, 156, 225, 187, 135, 226, 128, 157, 32, 80, 97, 114, 116, 105, 97, 108, 108, 121, 32, 112, 114, 101, 99, 111, 109, 112, 111, 115, 101, 100, 58, 32, 85, 43, 49, 69, 66, 57, 32, 226, 128, 156, 225, 186, 185, 226, 128, 157, 32, 43, 32, 85, 43, 48, 51, 48, 50, 32, 226, 128, 156, 226, 151, 140, 204, 130, 226, 128, 157, 32, 80, 97, 114, 116, 105, 97, 108, 108, 121, 32, 112, 114, 101, 99, 111, 109, 112, 111, 115, 101, 100, 58, 32, 85, 43, 48, 48, 69, 65, 32, 226, 128, 156, 195, 170, 226, 128, 157, 32, 43, 32, 85, 43, 48, 51, 50, 51, 32, 226, 128, 156, 226, 151, 140, 204, 163, 226, 128, 157, 32, 70, 117, 108, 108, 121, 32, 100, 101, 99, 111, 109, 112, 111, 115, 101, 100, 58, 32, 85, 43, 48, 48, 54, 53, 32, 226, 128, 156, 101, 226, 128, 157, 32, 43, 32, 85, 43, 48, 51, 50, 51, 32, 226, 128, 156, 226, 151, 140, 204, 163, 226, 128, 157, 32, 43, 32, 85, 43, 48, 51, 48, 50, 32, 226, 128, 156, 226, 151, 140, 204, 130, 226, 128, 157, 32, 70, 117, 108, 108, 121, 32, 100, 101, 99, 111, 109, 112, 111, 115, 101, 100, 58, 32, 85, 43, 48, 48, 54, 53, 32, 226, 128, 156, 101, 226, 128, 157, 32, 43, 32, 85, 43, 48, 51, 48, 50, 32, 226, 128, 156, 226, 151, 140, 204, 130, 226, 128, 157, 32, 43, 32, 85, 43, 48, 51, 50, 51, 32, 226, 128, 156, 226, 151, 140, 204, 163, 226, 128, 157, 32, 85, 110, 105, 99, 111, 100, 101, 32, 114, 101, 102, 101, 114, 115, 32, 116, 111, 32, 115, 101, 116, 32, 111, 102, 32, 115, 116, 114, 105, 110, 103, 115, 32, 108, 105, 107, 101, 32, 116, 104, 105, 115, 32, 97, 115, 32, 226, 128, 156, 99, 97, 110, 111, 110, 105, 99, 97, 108, 108, 121, 32, 101, 113, 117, 105, 118, 97, 108, 101, 110, 116, 226, 128, 157, 46, 32, 67, 97, 110, 111, 110, 105, 99, 97, 108, 108, 121, 32, 101, 113, 117, 105, 118, 97, 108, 101, 110, 116, 32, 115, 116, 114, 105, 110, 103, 115, 32, 97, 114, 101, 32, 115, 117, 112, 112, 111, 115, 101, 100, 32, 116, 111, 32, 98, 101, 32, 116, 114, 101, 97, 116, 101, 100, 32, 97, 115, 32, 105, 100, 101, 110, 116, 105, 99, 97, 108, 32, 102, 111, 114, 32, 112, 117, 114, 112, 111, 115, 101, 115, 32, 111, 102, 32, 115, 101, 97, 114, 99, 104, 105, 110, 103, 44, 32, 115, 111, 114, 116, 105, 110, 103, 44, 32, 114, 101, 110, 100, 101, 114, 105, 110, 103, 44, 32, 116, 101, 120, 116, 32, 115, 101, 108, 101, 99, 116, 105, 111, 110, 44, 32, 97, 110, 100, 32, 115, 111, 32, 111, 110, 46, 32, 84, 104, 105, 115, 32, 104, 97, 115, 32, 105, 109, 112, 108, 105, 99, 97, 116, 105, 111, 110, 115, 32, 102, 111, 114, 32, 104, 111, 119, 32, 121, 111, 117, 32, 105, 109, 112, 108, 101, 109, 101, 110, 116, 32, 111, 112, 101, 114, 97, 116, 105, 111, 110, 115, 32, 111, 110, 32, 116, 101, 120, 116, 46, 32, 70, 111, 114, 32, 101, 120, 97, 109, 112, 108, 101, 44, 32, 105, 102, 32, 97, 110, 32, 97, 112, 112, 32, 104, 97, 115, 32, 97, 32, 226, 128, 156, 102, 105, 110, 100, 32, 105, 110, 32, 102, 105, 108, 101, 226, 128, 157, 32, 111, 112, 101, 114, 97, 116, 105, 111, 110, 32, 97, 110, 100, 32, 116, 104, 101, 32, 117, 115, 101, 114, 32, 115, 101, 97, 114, 99, 104, 101, 115, 32, 102, 111, 114, 32, 226, 128, 156, 225, 187, 135, 226, 128, 157, 44, 32, 105, 116, 32, 115, 104, 111, 117, 108, 100, 44, 32, 98, 121, 32, 100, 101, 102, 97, 117, 108, 116, 44, 32, 102, 105, 110, 100, 32, 111, 99, 99, 117, 114, 114, 101, 110, 99, 101, 115, 32, 111, 102, 32, 97, 110, 121, 32, 111, 102, 32, 116, 104, 101, 32, 102, 105, 118, 101, 32, 118, 101, 114, 115, 105, 111, 110, 115, 32, 111, 102, 32, 226, 128, 156, 225, 187, 135, 226, 128, 157, 32, 97, 98, 111, 118, 101, 33, 32, 32, 78, 111, 114, 109, 97, 108, 105, 122, 97, 116, 105, 111, 110, 32, 70, 111, 114, 109, 115, 32, 84, 111, 32, 97, 100, 100, 114, 101, 115, 115, 32, 116, 104, 101, 32, 112, 114, 111, 98, 108, 101, 109, 32, 111, 102, 32, 226, 128, 156, 104, 111, 119, 32, 116, 111, 32, 104, 97, 110, 100, 108, 101, 32, 99, 97, 110, 111, 110, 105, 99, 97, 108, 108, 121, 32, 101, 113, 117, 105, 118, 97, 108, 101, 110, 116, 32, 115, 116, 114, 105, 110, 103, 115, 226, 128, 157, 44, 32, 85, 110, 105, 99, 111, 100, 101, 32, 100, 101, 102, 105, 110, 101, 115, 32, 115, 101, 118, 101, 114, 97, 108, 32, 110, 111, 114, 109, 97, 108, 105, 122, 97, 116, 105, 111, 110, 32, 102, 111, 114, 109, 115, 58, 32, 119, 97, 121, 115, 32, 111, 102, 32, 99, 111, 110, 118, 101, 114, 116, 105, 110, 103, 32, 115, 116, 114, 105, 110, 103, 115, 32, 105, 110, 116, 111, 32, 97, 32, 99, 97, 110, 111, 110, 105, 99, 97, 108, 32, 102, 111, 114, 109, 32, 115, 111, 32, 116, 104, 97, 116, 32, 116, 104, 101, 121, 32, 99, 97, 110, 32, 98, 101, 32, 99, 111, 109, 112, 97, 114, 101, 100, 32, 99, 111, 100, 101, 45, 112, 111, 105, 110, 116, 45, 98, 121, 45, 99, 111, 100, 101, 45, 112, 111, 105, 110, 116, 32, 40, 111, 114, 32, 98, 121, 116, 101, 45, 98, 121, 45, 98, 121, 116, 101, 41, 46, 32, 32, 84, 104, 101, 32, 226, 128, 156, 78, 70, 68, 226, 128, 157, 32, 110, 111, 114, 109, 97, 108, 105, 122, 97, 116, 105, 111, 110, 32, 102, 111, 114, 109, 32, 102, 117, 108, 108, 121, 32, 100, 101, 99, 111, 109, 112, 111, 115, 101, 115, 32, 101, 118, 101, 114, 121, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 100, 111, 119, 110, 32, 116, 111, 32, 105, 116, 115, 32, 99, 111, 109, 112, 111, 110, 101, 110, 116, 32, 98, 97, 115, 101, 32, 97, 110, 100, 32, 99, 111, 109, 98, 105, 110, 105, 110, 103, 32, 109, 97, 114, 107, 115, 44, 32, 116, 97, 107, 105, 110, 103, 32, 97, 112, 97, 114, 116, 32, 97, 110, 121, 32, 112, 114, 101, 99, 111, 109, 112, 111, 115, 101, 100, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 105, 110, 32, 116, 104, 101, 32, 115, 116, 114, 105, 110, 103, 46, 32, 73, 116, 32, 97, 108, 115, 111, 32, 115, 111, 114, 116, 115, 32, 116, 104, 101, 32, 99, 111, 109, 98, 105, 110, 105, 110, 103, 32, 109, 97, 114, 107, 115, 32, 105, 110, 32, 101, 97, 99, 104, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 97, 99, 99, 111, 114, 100, 105, 110, 103, 32, 116, 111, 32, 116, 104, 101, 105, 114, 32, 114, 101, 110, 100, 101, 114, 101, 100, 32, 112, 111, 115, 105, 116, 105, 111, 110, 44, 32, 115, 111, 32, 101, 46, 103, 46, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 116, 104, 97, 116, 32, 103, 111, 32, 98, 101, 108, 111, 119, 32, 116, 104, 101, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 99, 111, 109, 101, 32, 98, 101, 102, 111, 114, 101, 32, 116, 104, 101, 32, 111, 110, 101, 115, 32, 116, 104, 97, 116, 32, 103, 111, 32, 97, 98, 111, 118, 101, 32, 116, 104, 101, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 46, 32, 40, 73, 116, 32, 100, 111, 101, 115, 110, 226, 128, 153, 116, 32, 114, 101, 111, 114, 100, 101, 114, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 105, 110, 32, 116, 104, 101, 32, 115, 97, 109, 101, 32, 114, 101, 110, 100, 101, 114, 101, 100, 32, 112, 111, 115, 105, 116, 105, 111, 110, 44, 32, 115, 105, 110, 99, 101, 32, 116, 104, 101, 105, 114, 32, 111, 114, 100, 101, 114, 32, 109, 97, 116, 116, 101, 114, 115, 32, 118, 105, 115, 117, 97, 108, 108, 121, 44, 32, 97, 115, 32, 112, 114, 101, 118, 105, 111, 117, 115, 108, 121, 32, 109, 101, 110, 116, 105, 111, 110, 101, 100, 46, 41, 32, 32, 84, 104, 101, 32, 226, 128, 156, 78, 70, 67, 226, 128, 157, 32, 102, 111, 114, 109, 44, 32, 99, 111, 110, 118, 101, 114, 115, 101, 108, 121, 44, 32, 112, 117, 116, 115, 32, 116, 104, 105, 110, 103, 115, 32, 98, 97, 99, 107, 32, 116, 111, 103, 101, 116, 104, 101, 114, 32, 105, 110, 116, 111, 32, 112, 114, 101, 99, 111, 109, 112, 111, 115, 101, 100, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 97, 115, 32, 109, 117, 99, 104, 32, 97, 115, 32, 112, 111, 115, 115, 105, 98, 108, 101, 46, 32, 73, 102, 32, 97, 110, 32, 117, 110, 117, 115, 117, 97, 108, 32, 99, 111, 109, 98, 105, 110, 97, 116, 105, 111, 110, 32, 111, 102, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 105, 115, 32, 99, 97, 108, 108, 101, 100, 32, 102, 111, 114, 44, 32, 116, 104, 101, 114, 101, 32, 109, 97, 121, 32, 110, 111, 116, 32, 98, 101, 32, 97, 110, 121, 32, 112, 114, 101, 99, 111, 109, 112, 111, 115, 101, 100, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 102, 111, 114, 32, 105, 116, 44, 32, 105, 110, 32, 119, 104, 105, 99, 104, 32, 99, 97, 115, 101, 32, 78, 70, 67, 32, 115, 116, 105, 108, 108, 32, 112, 114, 101, 99, 111, 109, 112, 111, 115, 101, 115, 32, 119, 104, 97, 116, 32, 105, 116, 32, 99, 97, 110, 32, 97, 110, 100, 32, 108, 101, 97, 118, 101, 115, 32, 97, 110, 121, 32, 114, 101, 109, 97, 105, 110, 105, 110, 103, 32, 99, 111, 109, 98, 105, 110, 105, 110, 103, 32, 109, 97, 114, 107, 115, 32, 105, 110, 32, 112, 108, 97, 99, 101, 32, 40, 97, 103, 97, 105, 110, 32, 111, 114, 100, 101, 114, 101, 100, 32, 98, 121, 32, 114, 101, 110, 100, 101, 114, 101, 100, 32, 112, 111, 115, 105, 116, 105, 111, 110, 44, 32, 97, 115, 32, 105, 110, 32, 78, 70, 68, 41, 46, 32, 32, 84, 104, 101, 114, 101, 32, 97, 114, 101, 32, 97, 108, 115, 111, 32, 102, 111, 114, 109, 115, 32, 99, 97, 108, 108, 101, 100, 32, 78, 70, 75, 68, 32, 97, 110, 100, 32, 78, 70, 75, 67, 46, 32, 84, 104, 101, 32, 226, 128, 156, 75, 226, 128, 157, 32, 104, 101, 114, 101, 32, 114, 101, 102, 101, 114, 115, 32, 116, 111, 32, 99, 111, 109, 112, 97, 116, 105, 98, 105, 108, 105, 116, 121, 32, 100, 101, 99, 111, 109, 112, 111, 115, 105, 116, 105, 111, 110, 115, 44, 32, 119, 104, 105, 99, 104, 32, 99, 111, 118, 101, 114, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 32, 116, 104, 97, 116, 32, 97, 114, 101, 32, 226, 128, 156, 115, 105, 109, 105, 108, 97, 114, 226, 128, 157, 32, 105, 110, 32, 115, 111, 109, 101, 32, 115, 101, 110, 115, 101, 32, 98, 117, 116, 32, 110, 111, 116, 32, 118, 105, 115, 117, 97, 108, 108, 121, 32, 105, 100, 101, 110, 116, 105, 99, 97, 108, 46, 32, 72, 111, 119, 101, 118, 101, 114, 44, 32, 73, 226, 128, 153, 109, 32, 110, 111, 116, 32, 103, 111, 105, 110, 103, 32, 116, 111, 32, 99, 111, 118, 101, 114, 32, 116, 104, 97, 116, 32, 104, 101, 114, 101, 46, 32, 32, 71, 114, 97, 112, 104, 101, 109, 101, 32, 67, 108, 117, 115, 116, 101, 114, 115, 32, 65, 115, 32, 119, 101, 226, 128, 153, 118, 101, 32, 115, 101, 101, 110, 44, 32, 85, 110, 105, 99, 111, 100, 101, 32, 99, 111, 110, 116, 97, 105, 110, 115, 32, 118, 97, 114, 105, 111, 117, 115, 32, 99, 97, 115, 101, 115, 32, 119, 104, 101, 114, 101, 32, 97, 32, 116, 104, 105, 110, 103, 32, 116, 104, 97, 116, 32, 97, 32, 117, 115, 101, 114, 32, 116, 104, 105, 110, 107, 115, 32, 111, 102, 32, 97, 115, 32, 97, 32, 115, 105, 110, 103, 108, 101, 32, 226, 128, 156, 99, 104, 97, 114, 97, 99, 116, 101, 114, 226, 128, 157, 32, 109, 105, 103, 104, 116, 32, 97, 99, 116, 117, 97, 108, 108, 121, 32, 98, 101, 32, 109, 97, 100, 101, 32, 117, 112, 32, 111, 102, 32, 109, 117, 108, 116, 105, 112, 108, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 117, 110, 100, 101, 114, 32, 116, 104, 101, 32, 104, 111, 111, 100, 46, 32, 85, 110, 105, 99, 111, 100, 101, 32, 102, 111, 114, 109, 97, 108, 105, 122, 101, 115, 32, 116, 104, 105, 115, 32, 117, 115, 105, 110, 103, 32, 116, 104, 101, 32, 110, 111, 116, 105, 111, 110, 32, 111, 102, 32, 97, 32, 103, 114, 97, 112, 104, 101, 109, 101, 32, 99, 108, 117, 115, 116, 101, 114, 58, 32, 97, 32, 115, 116, 114, 105, 110, 103, 32, 111, 102, 32, 111, 110, 101, 32, 111, 114, 32, 109, 111, 114, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 116, 104, 97, 116, 32, 99, 111, 110, 115, 116, 105, 116, 117, 116, 101, 32, 97, 32, 115, 105, 110, 103, 108, 101, 32, 226, 128, 156, 117, 115, 101, 114, 45, 112, 101, 114, 99, 101, 105, 118, 101, 100, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 226, 128, 157, 46, 32, 32, 85, 65, 88, 32, 35, 50, 57, 32, 100, 101, 102, 105, 110, 101, 115, 32, 116, 104, 101, 32, 114, 117, 108, 101, 115, 32, 102, 111, 114, 32, 119, 104, 97, 116, 44, 32, 112, 114, 101, 99, 105, 115, 101, 108, 121, 44, 32, 113, 117, 97, 108, 105, 102, 105, 101, 115, 32, 97, 115, 32, 97, 32, 103, 114, 97, 112, 104, 101, 109, 101, 32, 99, 108, 117, 115, 116, 101, 114, 46, 32, 73, 116, 226, 128, 153, 115, 32, 97, 112, 112, 114, 111, 120, 105, 109, 97, 116, 101, 108, 121, 32, 226, 128, 156, 97, 32, 98, 97, 115, 101, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 102, 111, 108, 108, 111, 119, 101, 100, 32, 98, 121, 32, 97, 110, 121, 32, 110, 117, 109, 98, 101, 114, 32, 111, 102, 32, 99, 111, 109, 98, 105, 110, 105, 110, 103, 32, 109, 97, 114, 107, 115, 226, 128, 157, 44, 32, 98, 117, 116, 32, 116, 104, 101, 32, 97, 99, 116, 117, 97, 108, 32, 100, 101, 102, 105, 110, 105, 116, 105, 111, 110, 32, 105, 115, 32, 97, 32, 98, 105, 116, 32, 109, 111, 114, 101, 32, 99, 111, 109, 112, 108, 105, 99, 97, 116, 101, 100, 59, 32, 105, 116, 32, 97, 99, 99, 111, 117, 110, 116, 115, 32, 102, 111, 114, 32, 116, 104, 105, 110, 103, 115, 32, 108, 105, 107, 101, 32, 75, 111, 114, 101, 97, 110, 32, 106, 97, 109, 111, 44, 32, 97, 110, 100, 32, 101, 109, 111, 106, 105, 32, 90, 87, 74, 32, 115, 101, 113, 117, 101, 110, 99, 101, 115, 46, 32, 32, 84, 104, 101, 32, 109, 97, 105, 110, 32, 116, 104, 105, 110, 103, 32, 103, 114, 97, 112, 104, 101, 109, 101, 32, 99, 108, 117, 115, 116, 101, 114, 115, 32, 97, 114, 101, 32, 117, 115, 101, 100, 32, 102, 111, 114, 32, 105, 115, 32, 116, 101, 120, 116, 32, 101, 100, 105, 116, 105, 110, 103, 58, 32, 116, 104, 101, 121, 226, 128, 153, 114, 101, 32, 111, 102, 116, 101, 110, 32, 116, 104, 101, 32, 109, 111, 115, 116, 32, 115, 101, 110, 115, 105, 98, 108, 101, 32, 117, 110, 105, 116, 32, 102, 111, 114, 32, 99, 117, 114, 115, 111, 114, 32, 112, 108, 97, 99, 101, 109, 101, 110, 116, 32, 97, 110, 100, 32, 116, 101, 120, 116, 32, 115, 101, 108, 101, 99, 116, 105, 111, 110, 32, 98, 111, 117, 110, 100, 97, 114, 105, 101, 115, 46, 32, 85, 115, 105, 110, 103, 32, 103, 114, 97, 112, 104, 101, 109, 101, 32, 99, 108, 117, 115, 116, 101, 114, 115, 32, 102, 111, 114, 32, 116, 104, 101, 115, 101, 32, 112, 117, 114, 112, 111, 115, 101, 115, 32, 101, 110, 115, 117, 114, 101, 115, 32, 116, 104, 97, 116, 32, 121, 111, 117, 32, 99, 97, 110, 226, 128, 153, 116, 32, 97, 99, 99, 105, 100, 101, 110, 116, 97, 108, 108, 121, 32, 99, 104, 111, 112, 32, 111, 102, 102, 32, 115, 111, 109, 101, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 115, 32, 119, 104, 101, 110, 32, 121, 111, 117, 32, 99, 111, 112, 121, 45, 97, 110, 100, 45, 112, 97, 115, 116, 101, 32, 116, 101, 120, 116, 44, 32, 116, 104, 97, 116, 32, 108, 101, 102, 116, 47, 114, 105, 103, 104, 116, 32, 97, 114, 114, 111, 119, 32, 107, 101, 121, 115, 32, 97, 108, 119, 97, 121, 115, 32, 109, 111, 118, 101, 32, 116, 104, 101, 32, 99, 117, 114, 115, 111, 114, 32, 98, 121, 32, 111, 110, 101, 32, 118, 105, 115, 105, 98, 108, 101, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 44, 32, 97, 110, 100, 32, 115, 111, 32, 111, 110, 46, 32, 32, 65, 110, 111, 116, 104, 101, 114, 32, 112, 108, 97, 99, 101, 32, 119, 104, 101, 114, 101, 32, 103, 114, 97, 112, 104, 101, 109, 101, 32, 99, 108, 117, 115, 116, 101, 114, 115, 32, 97, 114, 101, 32, 117, 115, 101, 102, 117, 108, 32, 105, 115, 32, 105, 110, 32, 101, 110, 102, 111, 114, 99, 105, 110, 103, 32, 97, 32, 115, 116, 114, 105, 110, 103, 32, 108, 101, 110, 103, 116, 104, 32, 108, 105, 109, 105, 116, 226, 128, 148, 115, 97, 121, 44, 32, 111, 110, 32, 97, 32, 100, 97, 116, 97, 98, 97, 115, 101, 32, 102, 105, 101, 108, 100, 46, 32, 87, 104, 105, 108, 101, 32, 116, 104, 101, 32, 116, 114, 117, 101, 44, 32, 117, 110, 100, 101, 114, 108, 121, 105, 110, 103, 32, 108, 105, 109, 105, 116, 32, 109, 105, 103, 104, 116, 32, 98, 101, 32, 115, 111, 109, 101, 116, 104, 105, 110, 103, 32, 108, 105, 107, 101, 32, 116, 104, 101, 32, 98, 121, 116, 101, 32, 108, 101, 110, 103, 116, 104, 32, 111, 102, 32, 116, 104, 101, 32, 115, 116, 114, 105, 110, 103, 32, 105, 110, 32, 85, 84, 70, 45, 56, 44, 32, 121, 111, 117, 32, 119, 111, 117, 108, 100, 110, 226, 128, 153, 116, 32, 119, 97, 110, 116, 32, 116, 111, 32, 101, 110, 102, 111, 114, 99, 101, 32, 116, 104, 97, 116, 32, 98, 121, 32, 106, 117, 115, 116, 32, 116, 114, 117, 110, 99, 97, 116, 105, 110, 103, 32, 98, 121, 116, 101, 115, 46, 32, 65, 116, 32, 97, 32, 109, 105, 110, 105, 109, 117, 109, 44, 32, 121, 111, 117, 226, 128, 153, 100, 32, 119, 97, 110, 116, 32, 116, 111, 32, 226, 128, 156, 114, 111, 117, 110, 100, 32, 100, 111, 119, 110, 226, 128, 157, 32, 116, 111, 32, 116, 104, 101, 32, 110, 101, 97, 114, 101, 115, 116, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 32, 98, 111, 117, 110, 100, 97, 114, 121, 59, 32, 98, 117, 116, 32, 101, 118, 101, 110, 32, 98, 101, 116, 116, 101, 114, 44, 32, 114, 111, 117, 110, 100, 32, 100, 111, 119, 110, 32, 116, 111, 32, 116, 104, 101, 32, 110, 101, 97, 114, 101, 115, 116, 32, 103, 114, 97, 112, 104, 101, 109, 101, 32, 99, 108, 117, 115, 116, 101, 114, 32, 98, 111, 117, 110, 100, 97, 114, 121, 46, 32, 79, 116, 104, 101, 114, 119, 105, 115, 101, 44, 32, 121, 111, 117, 32, 109, 105, 103, 104, 116, 32, 98, 101, 32, 99, 111, 114, 114, 117, 112, 116, 105, 110, 103, 32, 116, 104, 101, 32, 108, 97, 115, 116, 32, 99, 104, 97, 114, 97, 99, 116, 101, 114, 32, 98, 121, 32, 99, 117, 116, 116, 105, 110, 103, 32, 111, 102, 102, 32, 97, 32, 100, 105, 97, 99, 114, 105, 116, 105, 99, 44, 32, 111, 114, 32, 105, 110, 116, 101, 114, 114, 117, 112, 116, 105, 110, 103, 32, 97, 32, 106, 97, 109, 111, 32, 115, 101, 113, 117, 101, 110, 99, 101, 32, 111, 114, 32, 90, 87, 74, 32, 115, 101, 113, 117, 101, 110, 99, 101, 46, 32, 32, 65, 110, 100, 32, 77, 111, 114, 101, 226, 128, 166, 32, 84, 104, 101, 114, 101, 226, 128, 153, 115, 32, 109, 117, 99, 104, 32, 109, 111, 114, 101, 32, 116, 104, 97, 116, 32, 99, 111, 117, 108, 100, 32, 98, 101, 32, 115, 97, 105, 100, 32, 97, 98, 111, 117, 116, 32, 85, 110, 105, 99, 111, 100, 101, 32, 102, 114, 111, 109, 32, 97, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 226, 128, 153, 115, 32, 112, 101, 114, 115, 112, 101, 99, 116, 105, 118, 101, 33, 32, 73, 32, 104, 97, 118, 101, 110, 226, 128, 153, 116, 32, 103, 111, 116, 116, 101, 110, 32, 105, 110, 116, 111, 32, 115, 117, 99, 104, 32, 102, 117, 110, 32, 116, 111, 112, 105, 99, 115, 32, 97, 115, 32, 99, 97, 115, 101, 32, 109, 97, 112, 112, 105, 110, 103, 44, 32, 99, 111, 108, 108, 97, 116, 105, 111, 110, 44, 32, 99, 111, 109, 112, 97, 116, 105, 98, 105, 108, 105, 116, 121, 32, 100, 101, 99, 111, 109, 112, 111, 115, 105, 116, 105, 111, 110, 115, 32, 97, 110, 100, 32, 99, 111, 110, 102, 117, 115, 97, 98, 108, 101, 115, 44, 32, 85, 110, 105, 99, 111, 100, 101, 45, 97, 119, 97, 114, 101, 32, 114, 101, 103, 101, 120, 101, 115, 44, 32, 111, 114, 32, 98, 105, 100, 105, 114, 101, 99, 116, 105, 111, 110, 97, 108, 32, 116, 101, 120, 116, 46, 32, 78, 111, 114, 32, 104, 97, 118, 101, 32, 73, 32, 115, 97, 105, 100, 32, 97, 110, 121, 116, 104, 105, 110, 103, 32, 121, 101, 116, 32, 97, 98, 111, 117, 116, 32, 105, 109, 112, 108, 101, 109, 101, 110, 116, 97, 116, 105, 111, 110, 32, 105, 115, 115, 117, 101, 115, 226, 128, 148, 104, 111, 119, 32, 116, 111, 32, 101, 102, 102, 105, 99, 105, 101, 110, 116, 108, 121, 32, 115, 116, 111, 114, 101, 32, 97, 110, 100, 32, 108, 111, 111, 107, 45, 117, 112, 32, 100, 97, 116, 97, 32, 97, 98, 111, 117, 116, 32, 116, 104, 101, 32, 115, 112, 97, 114, 115, 101, 108, 121, 45, 97, 115, 115, 105, 103, 110, 101, 100, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 44, 32, 111, 114, 32, 104, 111, 119, 32, 116, 111, 32, 111, 112, 116, 105, 109, 105, 122, 101, 32, 85, 84, 70, 45, 56, 32, 100, 101, 99, 111, 100, 105, 110, 103, 44, 32, 115, 116, 114, 105, 110, 103, 32, 99, 111, 109, 112, 97, 114, 105, 115, 111, 110, 44, 32, 111, 114, 32, 78, 70, 67, 32, 110, 111, 114, 109, 97, 108, 105, 122, 97, 116, 105, 111, 110, 46, 32, 80, 101, 114, 104, 97, 112, 115, 32, 73, 226, 128, 153, 108, 108, 32, 114, 101, 116, 117, 114, 110, 32, 116, 111, 32, 115, 111, 109, 101, 32, 111, 102, 32, 116, 104, 111, 115, 101, 32, 116, 104, 105, 110, 103, 115, 32, 105, 110, 32, 102, 117, 116, 117, 114, 101, 32, 112, 111, 115, 116, 115, 46, 32, 32, 85, 110, 105, 99, 111, 100, 101, 32, 105, 115, 32, 97, 32, 102, 97, 115, 99, 105, 110, 97, 116, 105, 110, 103, 32, 97, 110, 100, 32, 99, 111, 109, 112, 108, 101, 120, 32, 115, 121, 115, 116, 101, 109, 46, 32, 73, 116, 32, 104, 97, 115, 32, 97, 32, 109, 97, 110, 121, 45, 116, 111, 45, 111, 110, 101, 32, 109, 97, 112, 112, 105, 110, 103, 32, 98, 101, 116, 119, 101, 101, 110, 32, 98, 121, 116, 101, 115, 32, 97, 110, 100, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 44, 32, 97, 110, 100, 32, 111, 110, 32, 116, 111, 112, 32, 111, 102, 32, 116, 104, 97, 116, 32, 97, 32, 109, 97, 110, 121, 45, 116, 111, 45, 111, 110, 101, 32, 40, 111, 114, 44, 32, 117, 110, 100, 101, 114, 32, 115, 111, 109, 101, 32, 99, 105, 114, 99, 117, 109, 115, 116, 97, 110, 99, 101, 115, 44, 32, 109, 97, 110, 121, 45, 116, 111, 45, 109, 97, 110, 121, 41, 32, 109, 97, 112, 112, 105, 110, 103, 32, 98, 101, 116, 119, 101, 101, 110, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115, 32, 97, 110, 100, 32, 226, 128, 156, 99, 104, 97, 114, 97, 99, 116, 101, 114, 115, 226, 128, 157, 46, 32, 73, 116, 32, 104, 97, 115, 32, 111, 100, 100, 98, 97, 108, 108, 32, 115, 112, 101, 99, 105, 97, 108, 32, 99, 97, 115, 101, 115, 32, 105, 110, 32, 101, 118, 101, 114, 121, 32, 99, 111, 114, 110, 101, 114, 46, 32, 66, 117, 116, 32, 110, 111, 32, 111, 110, 101, 32, 101, 118, 101, 114, 32, 99, 108, 97, 105, 109, 101, 100, 32, 116, 104, 97, 116, 32, 114, 101, 112, 114, 101, 115, 101, 110, 116, 105, 110, 103, 32, 97, 108, 108, 32, 119, 114, 105, 116, 116, 101, 110, 32, 108, 97, 110, 103, 117, 97, 103, 101, 115, 32, 119, 97, 115, 32, 103, 111, 105, 110, 103, 32, 116, 111, 32, 98, 101, 32, 101, 97, 115, 121, 44, 32, 97, 110, 100, 32, 105, 116, 226, 128, 153, 115, 32, 99, 108, 101, 97, 114, 32, 116, 104, 97, 116, 32, 119, 101, 226, 128, 153, 114, 101, 32, 110, 101, 118, 101, 114, 32, 103, 111, 105, 110, 103, 32, 98, 97, 99, 107, 32, 116, 111, 32, 116, 104, 101, 32, 98, 97, 100, 32, 111, 108, 100, 32, 100, 97, 121, 115, 32, 111, 102, 32, 97, 32, 112, 97, 116, 99, 104, 119, 111, 114, 107, 32, 111, 102, 32, 105, 110, 99, 111, 109, 112, 97, 116, 105, 98, 108, 101, 32, 101, 110, 99, 111, 100, 105, 110, 103, 115, 46, 32, 32, 70, 117, 114, 116, 104, 101, 114, 32, 114, 101, 97, 100, 105, 110, 103, 58, 32, 32, 84, 104, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 83, 116, 97, 110, 100, 97, 114, 100, 32, 85, 84, 70, 45, 56, 32, 69, 118, 101, 114, 121, 119, 104, 101, 114, 101, 32, 77, 97, 110, 105, 102, 101, 115, 116, 111, 32, 68, 97, 114, 107, 32, 99, 111, 114, 110, 101, 114, 115, 32, 111, 102, 32, 85, 110, 105, 99, 111, 100, 101, 32, 98, 121, 32, 69, 101, 118, 101, 101, 32, 73, 67, 85, 32, 40, 73, 110, 116, 101, 114, 110, 97, 116, 105, 111, 110, 97, 108, 32, 67, 111, 109, 112, 111, 110, 101, 110, 116, 115, 32, 102, 111, 114, 32, 85, 110, 105, 99, 111, 100, 101, 41, 226, 128, 148, 67, 47, 67, 43, 43, 47, 74, 97, 118, 97, 32, 108, 105, 98, 114, 97, 114, 105, 101, 115, 32, 105, 109, 112, 108, 101, 109, 101, 110, 116, 105, 110, 103, 32, 109, 97, 110, 121, 32, 85, 110, 105, 99, 111, 100, 101, 32, 97, 108, 103, 111, 114, 105, 116, 104, 109, 115, 32, 97, 110, 100, 32, 114, 101, 108, 97, 116, 101, 100, 32, 116, 104, 105, 110, 103, 115, 32, 80, 121, 116, 104, 111, 110, 32, 51, 32, 85, 110, 105, 99, 111, 100, 101, 32, 72, 111, 119, 116, 111, 32, 71, 111, 111, 103, 108, 101, 32, 78, 111, 116, 111, 32, 70, 111, 110, 116, 115, 226, 128, 148, 115, 101, 116, 32, 111, 102, 32, 102, 111, 110, 116, 115, 32, 105, 110, 116, 101, 110, 100, 101, 100, 32, 116, 111, 32, 99, 111, 118, 101, 114, 32, 97, 108, 108, 32, 97, 115, 115, 105, 103, 110, 101, 100, 32, 99, 111, 100, 101, 32, 112, 111, 105, 110, 116, 115]\n",
            "length: 24597\n",
            "max: 240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "def merge(ids, pair, idx):\n",
        "  newids = []\n",
        "  i = 0\n",
        "  while i < len(ids):\n",
        "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "      newids.append(idx)\n",
        "      i += 2\n",
        "    else:\n",
        "      newids.append(ids[i])\n",
        "      i += 1\n",
        "  return newids\n",
        "\n",
        "# ---\n",
        "vocab_size = 276 # the target final vocabulary size\n",
        "num_merges = vocab_size - 256\n",
        "ids = list(tokens) # copy so we don't destroy the original list // preservation for comparison\n",
        "\n",
        "merges = {} # (int, int) -> int\n",
        "for i in range(num_merges):\n",
        "  stats = get_stats(ids)           # function retrieves dictionary with pairs of consecutive tokens and their frequencies\n",
        "  pair = max(stats, key=stats.get) # stats.get fetches value assosciated with each key in stats // this helps to determine key with highest value\n",
        "  idx = 256 + i\n",
        "  print(f\"merging {pair} into a new token {idx}\")\n",
        "  ids = merge(ids, pair, idx)      # replaces all occurences of \"pair\" in \"ids\" with new tokens \"idx\"\n",
        "  merges[pair] = idx               # records merge operation in \"mergs\" dictiionary, mapping from pair of tokens to the new token index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7upn3FHTjEb",
        "outputId": "54ac197f-bbce-4ae7-9fa3-f35fea17ce29"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "merging (101, 32) into a new token 256\n",
            "merging (105, 110) into a new token 257\n",
            "merging (115, 32) into a new token 258\n",
            "merging (116, 104) into a new token 259\n",
            "merging (101, 114) into a new token 260\n",
            "merging (99, 111) into a new token 261\n",
            "merging (116, 32) into a new token 262\n",
            "merging (226, 128) into a new token 263\n",
            "merging (44, 32) into a new token 264\n",
            "merging (97, 110) into a new token 265\n",
            "merging (111, 114) into a new token 266\n",
            "merging (100, 32) into a new token 267\n",
            "merging (97, 114) into a new token 268\n",
            "merging (101, 110) into a new token 269\n",
            "merging (257, 103) into a new token 270\n",
            "merging (261, 100) into a new token 271\n",
            "merging (121, 32) into a new token 272\n",
            "merging (46, 32) into a new token 273\n",
            "merging (97, 108) into a new token 274\n",
            "merging (259, 256) into a new token 275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tokens length:\", len(tokens))\n",
        "print(\"ids length:\", len(ids))\n",
        "print(f\"compression ratio: {len(tokens) / len(ids):.2f}X\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAtfuU7ETjCs",
        "outputId": "81ba5555-78f3-438a-9ba6-426e176e0934"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens length: 24597\n",
            "ids length: 19438\n",
            "compression ratio: 1.27X\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, the Tokenizer is a completely separate, independent module from the LLM. It has its own training dataset of text (which could be different from that of the LLM), on which you train the vocabulary using the Byte Pair Encoding (BPE) algorithm. It then translates back and forth between raw text and sequences of tokens. The LLM later only ever sees the tokens and never directly deals with any text."
      ],
      "metadata": {
        "id": "bDyBetcxX046"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoding\n",
        "\n",
        "Given a sequence of integers in the range [0, vocab_size], what is the text?\n"
      ],
      "metadata": {
        "id": "xhQX8lZnTjBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {idx: bytes([idx]) for idx in range(256)} # initislises dictionary where key key is an interger randing from 0 to 255 // and corresponding value is a byte array containing that integer.\n",
        "                                                        # this essentially maps each single-byte value to its byte representation. Which is useful for decoding operations becuase it directly translates\n",
        "                                                        # byte values into their respective byte representations.\n",
        "for (p0, p1), idx in merges.items(): # iterates through merges dict which contains mappings of pairs of newly merged token indices\n",
        "    vocab[idx] = vocab[p0] + vocab[p1] # idx is correct. Value was correctly assigned as value during for loop at first!\n",
        "\n",
        "def decode(ids):\n",
        "  # given ids (list of integers), return Python string\n",
        "  tokens = b\"\".join(vocab[idx] for idx in ids) # b\"\" means byte string // this concatenates all the byte array from vocab into a single byte array\n",
        "\n",
        "  text = tokens.decode(\"utf-8\", errors=\"replace\") # Convert Bytes to String: tokens.decode(\"utf-8\", errors=\"replace\") converts the byte array into a string using UTF-8 encoding.\n",
        "                                                          # The errors='replace' parameter ensures that if any bytes cannot be decoded properly, they are replaced with a placeholder character\n",
        "                                                          # (typically ï¿½) instead of raising an error.\n",
        "  return text\n",
        "\n",
        "print(decode([128]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi0NN-yUTi_g",
        "outputId": "9f604de3-7eb0-4012-8a23-a49d80bd04d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ï¿½\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding\n",
        "\n",
        "The other way around: Given a string, what are the tokens?\n"
      ],
      "metadata": {
        "id": "Rq9Ys6uuToIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(merges)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HbbouovTi98",
        "outputId": "2edcf93a-7d95-4800-8bff-ae6824091b71"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(101, 32): 256, (105, 110): 257, (115, 32): 258, (116, 104): 259, (101, 114): 260, (99, 111): 261, (116, 32): 262, (226, 128): 263, (44, 32): 264, (97, 110): 265, (111, 114): 266, (100, 32): 267, (97, 114): 268, (101, 110): 269, (257, 103): 270, (261, 100): 271, (121, 32): 272, (46, 32): 273, (97, 108): 274, (259, 256): 275}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes"
      ],
      "metadata": {
        "id": "bTtqo-s5nkcl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query: help me explain in more detail how does this work\n",
        "\n",
        "\n",
        "\n",
        "pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "\n",
        "---\n",
        "\n",
        "The line of code you're asking about is a key part of the `encode` function, which is involved in selecting the optimal pair of tokens to merge during each iteration of the encoding process. Let's break down this line and explain its components and logic in more detail:\n",
        "\n",
        "### Code Snippet\n",
        "```python\n",
        "pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "```\n",
        "\n",
        "### Components\n",
        "\n",
        "1. **`stats`**:\n",
        "   - This is a dictionary where each key is a pair of consecutive token indices (e.g., `(token1, token2)`) and each value is the frequency of that pair in the current token list. This dictionary is generated by the `get_stats` function.\n",
        "\n",
        "2. **`min()` Function**:\n",
        "   - `min()` is a built-in Python function that returns the smallest item from an iterable. In this case, the iterable is the keys of the `stats` dictionary, each representing a pair of tokens.\n",
        "\n",
        "3. **`key` Argument**:\n",
        "   - The `key` argument of the `min()` function specifies a single-argument ordering function that returns a value used to determine the \"smallness\" for sorting purposes.\n",
        "\n",
        "4. **Lambda Function**:\n",
        "   - The lambda function defined as `lambda p: merges.get(p, float(\"inf\"))` is used here as the key function for `min()`. The `lambda` function takes a pair of tokens `p` as its input.\n",
        "\n",
        "5. **`merges.get(p, float(\"inf\"))`**:\n",
        "   - `merges` is a dictionary where each key is a pair of token indices that have been designated to merge into a new token index during the initialization or a previous run of the encoding process. The value associated with each key in `merges` is the new token index that replaces the pair.\n",
        "   - `merges.get(p, float(\"inf\"))` attempts to retrieve the new token index for the pair `p` from the `merges` dictionary. If `p` is not a key in `merges`, it returns `float(\"inf\")` (infinity) as a default value.\n",
        "\n",
        "### How It Works\n",
        "\n",
        "- **Purpose**: The purpose of this line is to find the pair of tokens (`p`) that is least preferable for merging based on the availability and eligibility defined in the `merges` dictionary.\n",
        "- **Logic**:\n",
        "  - For each pair `p` in `stats`, the lambda function checks if `p` is a key in `merges`. If it is, the lambda returns the index assigned to that pair (indicating it can be merged).\n",
        "  - If `p` is not found in `merges`, the lambda returns infinity (`float(\"inf\")`), effectively prioritizing it as the least desirable for merging because an infinite value will always be greater than any real index.\n",
        "- **Result**: The `min()` function, therefore, picks the pair `p` that has the smallest associated value as returned by the lambda function. By setting non-mergeable pairs to infinity, the function ensures they are never chosen unless all pairs are unmergeable.\n",
        "\n",
        "### Practical Implication\n",
        "\n",
        "This approach allows the `encode` function to dynamically decide which pairs to merge based on a predefined strategy (encoded in the `merges` dictionary). It prioritizes pairs that are designated to be merged and skips those not specified, ensuring the encoding process adheres to the planned token compression or simplification strategy."
      ],
      "metadata": {
        "id": "Ph7zkNR-nkae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "no. just show me the part where the inf is being used. then how and why does it even work by setting the key or value to infinity. this line \"pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\"\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Certainly! To demonstrate the specific functionality of the line:\n",
        "\n",
        "```python\n",
        "pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "```\n",
        "\n",
        "Let's break down how this line works through a focused example. We'll illustrate why we set the default value to infinity (`float(\"inf\")`) and how it impacts the selection of a pair to merge.\n",
        "\n",
        "### Example Setup\n",
        "\n",
        "Suppose you have a sequence of token pairs with their respective frequencies and a set of predefined merge rules that do not cover all possible pairs. Here's the setup:\n",
        "\n",
        "```python\n",
        "# Frequency of each pair of tokens\n",
        "stats = {\n",
        "    (97, 97): 3,  # Pair 'aa' appears 3 times\n",
        "    (97, 98): 2,  # Pair 'ab' appears 2 times\n",
        "    (98, 99): 1   # Pair 'bc' appears 1 time\n",
        "}\n",
        "\n",
        "# Predefined merges (not all pairs are included)\n",
        "merges = {\n",
        "    (97, 97): 256,  # 'aa' can be merged into new token 256\n",
        "    # Notice (97, 98) and (98, 99) are not included in merges\n",
        "}\n",
        "```\n",
        "\n",
        "### Execution of the Key Line\n",
        "\n",
        "The purpose of this line is to find the pair of tokens that should be merged next, based on its frequency and eligibility for merging. Hereâ€™s how itâ€™s executed:\n",
        "\n",
        "```python\n",
        "pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "```\n",
        "\n",
        "- **`min()` Function**: This is looking for the pair (`p`) with the minimum value as determined by the key function.\n",
        "- **`lambda p: merges.get(p, float(\"inf\"))`**: For each pair `p` in `stats`, this lambda function checks if `p` exists in the `merges` dictionary:\n",
        "  - If `p` is in `merges`, `merges.get(p)` returns the new token index (which are valid integers like 256).\n",
        "  - If `p` is not in `merges`, `merges.get(p, float(\"inf\"))` returns infinity (`float(\"inf\")`).\n",
        "\n",
        "### Why Use Infinity?\n",
        "\n",
        "The use of infinity (`float(\"inf\")`) as the default value serves a critical purpose:\n",
        "- **Effectively Excluding Non-mergeable Pairs**: By setting the return value to infinity for pairs not found in `merges`, you ensure these pairs are less favorable for selection. Since infinity is greater than any actual index number or frequency, pairs not eligible for merging will always be considered last, effectively filtering them out as candidates in the `min()` function.\n",
        "\n",
        "### Running the Example\n",
        "\n",
        "When this code runs:\n",
        "\n",
        "```python\n",
        "print(pair)  # Output will be (97, 97)\n",
        "```\n",
        "\n",
        "- **Result Explanation**: Among the pairs, `(97, 97)` is the only pair found in `merges` with a corresponding value (256). The pairs `(97, 98)` and `(98, 99)` return infinity because they are not in `merges`, making `(97, 97)` the minimum by default.\n",
        "\n",
        "This logic ensures that the merging process adheres strictly to predefined rules and avoids attempting to merge pairs for which no merge rule has been set. This is crucial for maintaining consistency and integrity in processes where not all elements are meant to be merged, such as in tokenization or compression systems where specific patterns are targeted for merging."
      ],
      "metadata": {
        "id": "diZ7WIlCq0kL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "wait so because of how its a lambda function. in this case p is all values inside stats?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Yes, exactly! In the context of the line:\n",
        "\n",
        "```python\n",
        "pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "```\n",
        "\n",
        "The variable `p` within the lambda function iterates over each key in the `stats` dictionary. Here's a breakdown of how this works:\n",
        "\n",
        "### How the Lambda Function Interacts with `stats`\n",
        "\n",
        "- **`stats` Dictionary**: Contains pairs of tokens as keys and their frequencies as values. For example, if `stats = {(97, 97): 3, (97, 98): 2}`, it indicates the frequency of each token pair in your data.\n",
        "- **Iteration Process**: When `min()` is called with `stats` as the iterable, it needs to evaluate each item (key) in `stats` to find the one with the minimum value according to some criterion. This criterion is defined by the lambda function.\n",
        "\n",
        "### Role of `lambda p:`\n",
        "\n",
        "- **Lambda Function**: `lambda p: merges.get(p, float(\"inf\"))` serves as the key function for `min()`. The lambda function is called once for each key in `stats`.\n",
        "- **Parameter `p`**: In this lambda function, `p` represents a key from `stats` during each iteration. Since the keys in `stats` are pairs of tokens, `p` takes the value of each pair as `min()` evaluates them.\n",
        "- **Functionality**: For each pair `p`, the lambda function fetches its corresponding value from the `merges` dictionary using `merges.get(p, float(\"inf\"))`. If the pair `p` is found in `merges`, the value (i.e., the new token index) is returned. If `p` is not found, the function returns infinity (`float(\"inf\")`).\n",
        "\n",
        "### Why Using `float(\"inf\")` as Default\n",
        "\n",
        "- **Exclusion of Non-mergeable Pairs**: By returning `float(\"inf\")` for pairs not in the `merges` dictionary, these pairs are effectively made the least desirable choices for the `min()` function. This is because infinity is greater than any real integer index returned for other pairs. Thus, only pairs that are explicitly allowed to be merged (those present in `merges`) will be considered as potential candidates for the minimum value unless all possible pairs are ineligible for merging.\n",
        "\n",
        "This method ensures that `min()` selects the pair with the lowest merge index, favoring pairs that are designated for merging and skipping those that are not planned for such operations. Itâ€™s a way to control and prioritize how elements are merged based on predefined rules in a dynamically updating process."
      ],
      "metadata": {
        "id": "yvurKVjOq0ht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ah i think i get it now never mind. so for values not inside, setting to infinity means it will never be chosen by minimum becuase its too big. what about for values that are inside though, what would their probabilities be like\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Exactly! By setting the default value to infinity for pairs not present in the `merges` dictionary, you ensure they are effectively ignored for merging because they will never be the minimum value. For pairs that are included in `merges`, their selection by the `min()` function is determined by the actual values associated with them in the `merges` dictionary.\n",
        "\n",
        "### Values Inside `merges`\n",
        "\n",
        "For pairs that are present in the `merges` dictionary, the lambda function returns their corresponding merge indices. These indices are usually integers that have been designated during a preprocessing or initialization phase to represent new token IDs formed by merging specific pairs of tokens.\n",
        "\n",
        "### How the Indices Influence Selection\n",
        "\n",
        "1. **Lower Indices Have Higher Priority**: The merge index itself can have implications on how often a pair is selected for merging:\n",
        "   - **Lower Indices**: If the merging strategy involves assigning lower indices to more frequent or preferred pairs, then those pairs would be more likely to be chosen first because `min()` is looking for the lowest value returned by the lambda function.\n",
        "   - **Sequential Indices**: If indices are assigned sequentially without any specific strategy regarding frequency or priority, then the selection purely depends on the order of merging you initially established when populating the `merges` dictionary.\n",
        "\n",
        "### Probabilities and Frequencies\n",
        "\n",
        "The actual selection of pairs for merging doesn't directly involve probabilities in the context you've described since it's based on deterministic rules (the presence of pairs in the `merges` dictionary and their assigned indices). However, if we consider the broader context of how often pairs appear in your data and how they are chosen for merging:\n",
        "\n",
        "- **Frequent Pairs Getting Lower Indices**: If you set up your `merges` such that more frequently occurring pairs in your data get lower indices, these pairs would consistently be merged first in successive runs or batches of data processing. This mimics a \"probabilistic\" favoring of more common pairs, though it is deterministic based on your initial setup.\n",
        "- **Impact of Initial Pair Frequencies**: The frequency of pairs in your initial dataset (used to set up `merges`) can influence how effectively your merging rules generalize. Pairs that were common in the setup phase and thus got lower indices will be merged preferentially in new data, assuming similar distributions.\n",
        "\n",
        "### Strategy for Effective Merging\n",
        "\n",
        "To optimize this process and make it more efficient or relevant to your data, consider analyzing your data's characteristics thoroughly before setting up the `merges` dictionary. This preparation might include:\n",
        "- Statistical analysis to determine the most frequent pairs.\n",
        "- Assigning lower indices to these frequent pairs to ensure they are merged first in the encoding process.\n",
        "\n",
        "This setup helps create a more compressed and efficient representation of your data, reducing variability and complexity by merging common patterns and sequences early in the process."
      ],
      "metadata": {
        "id": "1MJerdM4q0f5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Back to Coding"
      ],
      "metadata": {
        "id": "i7J0cstbnkYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text):\n",
        "  # given a string, return list of integers (the tokens)\n",
        "  tokens = list(text.encode(\"utf-8\"))\n",
        "  while len(tokens) >= 2: # continues process as long as there's at least 2 tokens in the list.\n",
        "    stats = get_stats(tokens) # previously defined // calculate the frequency of each consecutive pair of tokens in the list\n",
        "    pair = min(stats, key=lambda p: merges.get(p, float(\"inf\"))) # purpose of line is to find pair of tokens \"p\" that is least preferable for merging based on whether are they defined in \"merges\" dictionary\n",
        "                                                                 # if p is not found, basically will return infinity as default value, effectively prioritising it as least desirable. Because infinite value will always\n",
        "                                                                 # be greater than any index.\n",
        "\n",
        "                                                                # further notes:\n",
        "                                                                      # refer to above. but i generally get the consensus. Due to how lambda function works here, p is all pair chars in stats being iterated over.\n",
        "                                                                      # when p is not in merges, infinity value is set making it impossible to be ever chosen\n",
        "                                                                      # on the other hand, if not, then the value inside merges or the merge pair vocab will be returned. The lowest value will always be chosen first\n",
        "                                                                      # which due to how most frequent values are always added first, this means that more frequent values are iterated first etc.\n",
        "\n",
        "                                                                      # REFER TO NOTES ABOVE\n",
        "    if pair not in merges:\n",
        "      break # nothing else can be merged // exits loop when\n",
        "    idx = merges[pair]\n",
        "    tokens = merge(tokens, pair, idx)\n",
        "  return tokens\n",
        "\n",
        "print(encode(\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHLdPpSQTi7_",
        "outputId": "4c5ee570-a1f3-43bf-cc27-8f5d03c9712e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(encode(\"hello world\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNGG1E3kTi6o",
        "outputId": "bd2285a9-9e59-440b-b247-f6cbc589ea96"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text2 = decode(encode(text))\n",
        "print(text2 == text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcegyWIqTi4f",
        "outputId": "51c5c3a0-4d5d-4ecc-a847-869dac3dbc46"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGiCTZU-Tc6m",
        "outputId": "b05a59e7-a411-4fbf-8074-b883c5c7a51b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "valtext = \"Many common characters, including numerals, punctuation, and other symbols, are unified within the standard and are not treated as specific to any given writing system. Unicode encodes thousands of emoji, with the continued development thereof conducted by the Consortium as a part of the standard.[4] Moreover, the widespread adoption of Unicode was in large part responsible for the initial popularization of emoji outside of Japan. Unicode is ultimately capable of encoding more than 1.1 million characters.\"\n",
        "valtext2 = decode(encode(valtext))\n",
        "print(valtext2 == valtext)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forced splits using regex patterns (GPT series)\n"
      ],
      "metadata": {
        "id": "ME6u1qYbThFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes"
      ],
      "metadata": {
        "id": "YwJT89vj63YL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code snippet you provided, there is a regex (regular expression) pattern designed to perform specific splits or match sequences in text, and it's being applied to a given string. Let's break down the code and regex pattern to understand what it does:\n",
        "\n",
        "### Code Breakdown\n",
        "\n",
        "```python\n",
        "import regex as re\n",
        "gpt2Pat = re.compile(r'''s|t|re|ve|m|ll|d|\\p{L}+|\\p{N}+| [^\\s\\p{L}\\p{N}]+|s+(?!\\S)|s+''')\n",
        "print(re.findall(gpt2Pat, \"Hello've world123 how's are you!!?\"))\n",
        "```\n",
        "\n",
        "1. **Importing regex module**: The code imports the `regex` module as `re`, which is an enhanced version of Python's built-in `re` module, offering additional functionality and better Unicode support.\n",
        "\n",
        "2. **Compiling a Regex Pattern**:\n",
        "   - `re.compile(r'''...''')` compiles a regex pattern for repeated use. This makes processing more efficient when the same pattern is applied many times.\n",
        "   - The pattern is defined as a raw multi-line string (`r'''...'''`), which avoids processing backslashes as escape characters.\n",
        "\n",
        "3. **Regex Pattern Explanation**:\n",
        "   - `s|t|re|ve|m|ll|d`: Matches any of these literal strings. These are common contractions or suffixes in English.\n",
        "   - `\\p{L}+`: Matches sequences of one or more Unicode letters. `\\p{L}` is a Unicode property that matches any kind of letter from any language.\n",
        "   - `\\p{N}+`: Matches sequences of one or more Unicode digits. `\\p{N}` is a Unicode property that matches any kind of numeric character in any script.\n",
        "   - ` [^\\s\\p{L}\\p{N}]+`: Matches sequences of one or more characters that are neither whitespace (`\\s`), letter (`\\p{L}`), nor numeric (`\\p{N}`). The leading space in the bracket seems to be a typo or formatting error.\n",
        "   - `s+(?!\\S)`: Matches one or more 's' characters that are not followed by a non-whitespace character. This targets trailing 's' at the end of a string or line.\n",
        "   - `s+`: Matches sequences of one or more 's' characters.\n",
        "\n",
        "4. **Finding All Matches**:\n",
        "   - `re.findall(gpt2Pat, \"Hello've world123 how's are you!!?\")`: Searches the string \"Hello've world123 how's are you!!?\" for all non-overlapping matches of the `gpt2Pat` pattern and returns them as a list.\n",
        "\n",
        "### Expected Output\n",
        "\n",
        "Given the input string `\"Hello've world123 how's are you!!?\"`, the regex pattern would typically identify and extract parts of the string as follows, though it would depend on the correct interpretation of the potentially malformed part of the pattern:\n",
        "- Matches words, numbers, contractions, and other sequences based on the defined pattern.\n",
        "\n",
        "### Issues and Recommendations\n",
        "\n",
        "- There appears to be a typo or misplaced character in the part of the pattern `[^\\s\\p{L}\\p{N}]+`. If it's intended to match non-letter, non-digit, and non-whitespace sequences, the space inside the brackets might be incorrect or misplaced.\n",
        "- Depending on the desired behavior, especially with how punctuation and special characters are treated, the pattern might need further refinement.\n",
        "\n",
        "This regex pattern seems tailored for detailed text analysis or preprocessing, potentially for natural language processing tasks where identifying parts of words, digits, and punctuation is useful."
      ],
      "metadata": {
        "id": "IE_SHh4Y63Vh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## back to coding"
      ],
      "metadata": {
        "id": "ou7lUkhK63Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import regex as re\n",
        "gpt2pat = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\") # GPT2's regex\n",
        "\n",
        "print(re.findall(gpt2pat, \"Hello've world123 how's are you!!!?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gng2C4PlThus",
        "outputId": "79eba972-28ea-4fb4-97ce-747f80ae6ae9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', \"'ve\", ' world', '123', ' how', \"'s\", ' are', ' you', '!!!?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"\"\"\n",
        "for i in range(1, 101):\n",
        "    if i % 3 == 0 and i % 5 == 0:\n",
        "        print(\"FizzBuzz\")\n",
        "    elif i % 3 == 0:\n",
        "        print(\"Fizz\")\n",
        "    elif i % 5 == 0:\n",
        "        print(\"Buzz\")\n",
        "    else:\n",
        "        print(i)\n",
        "\"\"\"\n",
        "print(re.findall(gpt2pat, example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPnGc8fE3Tob",
        "outputId": "18b3f6ec-043c-447e-84b6-7c67b6d28ab8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', 'for', ' i', ' in', ' range', '(', '1', ',', ' 101', '):', '\\n   ', ' if', ' i', ' %', ' 3', ' ==', ' 0', ' and', ' i', ' %', ' 5', ' ==', ' 0', ':', '\\n       ', ' print', '(\"', 'FizzBuzz', '\")', '\\n   ', ' elif', ' i', ' %', ' 3', ' ==', ' 0', ':', '\\n       ', ' print', '(\"', 'Fizz', '\")', '\\n   ', ' elif', ' i', ' %', ' 5', ' ==', ' 0', ':', '\\n       ', ' print', '(\"', 'Buzz', '\")', '\\n   ', ' else', ':', '\\n       ', ' print', '(', 'i', ')', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken==0.7.0 # added for colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFWwmG7H3Tlx",
        "outputId": "268cbce2-2e32-4706-c569-74fb1f873e62"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken==0.7.0\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.7.0) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.7.0) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (2024.7.4)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "# GPT-2 (does not merge spaces)\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "print(enc.encode(\"    hello world!!!\")) # demonstrates examples of different types of tokenization\n",
        "\n",
        "# GPT-4 (merges spaces)\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "print(enc.encode(\"    hello world!!!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyJDnM3d3Tjr",
        "outputId": "d4d0baf5-f84d-4b09-e94c-31aafefba9eb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[220, 220, 220, 23748, 995, 10185]\n",
            "[262, 24748, 1917, 12340]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://openaipublic.blob.core.windows.net/gpt-2/models/1558M/vocab.bpe\n",
        "!wget https://openaipublic.blob.core.windows.net/gpt-2/models/1558M/encoder.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hJ7aDc13hXq",
        "outputId": "b98e9e66-610b-4f15-f31a-5fada2301bc2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-29 09:58:43--  https://openaipublic.blob.core.windows.net/gpt-2/models/1558M/vocab.bpe\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.60.179.33\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.60.179.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 456318 (446K) [application/octet-stream]\n",
            "Saving to: â€˜vocab.bpeâ€™\n",
            "\n",
            "vocab.bpe           100%[===================>] 445.62K  2.31MB/s    in 0.2s    \n",
            "\n",
            "2024-07-29 09:58:44 (2.31 MB/s) - â€˜vocab.bpeâ€™ saved [456318/456318]\n",
            "\n",
            "--2024-07-29 09:58:44--  https://openaipublic.blob.core.windows.net/gpt-2/models/1558M/encoder.json\n",
            "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.60.179.33\n",
            "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.60.179.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1042301 (1018K) [application/json]\n",
            "Saving to: â€˜encoder.jsonâ€™\n",
            "\n",
            "encoder.json        100%[===================>]   1018K  4.31MB/s    in 0.2s    \n",
            "\n",
            "2024-07-29 09:58:44 (4.31 MB/s) - â€˜encoder.jsonâ€™ saved [1042301/1042301]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes"
      ],
      "metadata": {
        "id": "w0whBin9BRJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, that's a good way to look at it! The `vocab.bpe` file you're dealing with is conceptually similar to the `merges` dictionary we discussed earlier. Both are involved in determining how text should be processed and transformed into a more manageable form for models to understand, specifically in the context of tokenization using Byte Pair Encoding (BPE).\n",
        "\n",
        "### Similarities:\n",
        "1. **Merging Rules**: Both `vocab.bpe` and your `merges` dictionary contain rules about which tokens (or characters/subwords) should be combined to form new tokens. These rules are based on the frequency and proximity of pairs in the training data.\n",
        "  \n",
        "2. **Purpose**: The purpose of both is to reduce the complexity of the input text by merging frequent pairs, thus simplifying the input space for the model. This helps in managing vocabulary size and dealing with out-of-vocabulary words by breaking them down into recognizable pieces.\n",
        "\n",
        "3. **Use in Tokenization**: Both are used during the tokenization process. In the case of `vocab.bpe`, it provides a step-by-step guideline on how to merge characters and subwords into tokens. Similarly, the `merges` dictionary is used to apply these merging operations programmatically.\n",
        "\n",
        "### Usage in BPE:\n",
        "- **BPE Process with `vocab.bpe`**: As you process text, you would start with the lowest level (individual characters) and use the rules in `vocab.bpe` to iteratively merge them into larger tokens. This is typically done in the order that these pairs appear in the `vocab.bpe`, which reflects their frequency and thus their priority in merging.\n",
        "  \n",
        "- **Dynamic Tokenization**: This process dynamically builds the tokens based on the actual text being processed, unlike fixed vocabulary systems where the tokenization ignores the context and frequency of character combinations in specific texts.\n",
        "\n",
        "### Practical Application:\n",
        "When you're watching discussions or explanations by experts like Andrej Karpathy, they might refer to how these systems efficiently manage language by breaking down complex tasks (like understanding and generating human language) into manageable parts. By using BPE and similar techniques, models like GPT (developed under guidance from researchers like Karpathy) can handle a vast range of vocabulary without needing an explicit entry for every possible word or phrase, making them more robust and versatile in handling various language tasks.\n",
        "\n",
        "In summary, your understanding of `vocab.bpe` as analogous to a `merges` dictionary is quite accurate. Itâ€™s all about creating a system where text is efficiently broken down and reassembled to facilitate deep understanding and generation by AI models."
      ],
      "metadata": {
        "id": "z1dF6q-hBRHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notes above"
      ],
      "metadata": {
        "id": "cLQeWOWZBRFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json\n",
        "\n",
        "with open('encoder.json', 'r') as f:\n",
        "    encoder = json.load(f) # <--- ~equivalent to our \"vocab\"\n",
        "\n",
        "with open('vocab.bpe', 'r', encoding=\"utf-8\") as f: # akin to our merges dictionary\n",
        "    bpe_data = f.read()\n",
        "bpe_merges = [tuple(merge_str.split()) for merge_str in bpe_data.split('\\n')[1:-1]]\n",
        "# ^---- ~equivalent to our \"merges\"\n",
        "print(len(bpe_merges)) # 50,000 merges can be seen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG-yElak3hVk",
        "outputId": "1fef26bf-3e0c-4e21-d29e-12361ac55c05"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# special tokens"
      ],
      "metadata": {
        "id": "1IEWyprG3mbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoder) # 256 raw byte tokens. 50,000 merges. +1 special token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLQOHx2q3hTd",
        "outputId": "6282b22c-8021-45bf-f022-27aaa8871b40"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder['<|endoftext|>'] # the only special token in use for the GPT-2 base model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlq-X9XM3pNZ",
        "outputId": "f964a432-06fb-4176-c37e-3e0f5916b91e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50256"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# minbpe exercise\n",
        "\n",
        "At this point you have everything you need to build your own GPT-4 tokenizer. This is the [exercise progression](https://github.com/karpathy/minbpe/blob/master/exercise.md) you may wish to follow. You'll note that it is part of the [minbpe](https://github.com/karpathy/minbpe) repo, which is the solution to that exercise, and is a cleaned up version of the code above."
      ],
      "metadata": {
        "id": "UnvZkxvQ3qxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\") # GPT-4 tokenizer\n",
        "print(enc.encode(\"ì•ˆë…•í•˜ì„¸ìš” ðŸ‘‹ (hello in Korean!)\"))\n",
        "print(enc.decode(enc.encode(\"ì•ˆë…•í•˜ì„¸ìš” ðŸ‘‹ (hello in Korean!)\")) == \"ì•ˆë…•í•˜ì„¸ìš” ðŸ‘‹ (hello in Korean!)\")\n",
        "# match the above for your own tokenizer, and also implement a train() function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wFTD3aB3tIG",
        "outputId": "6906bd32-f379-4dae-e00d-90fefd63ade3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31495, 230, 75265, 243, 92245, 62904, 233, 320, 15339, 304, 16526, 16715]\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### sentencepiece\n",
        "\n",
        "Commonly used because (unlike tiktoken) it can efficiently both train and inference BPE tokenizers. It is used in both Llama and Mistral series.\n",
        "\n",
        "[sentencepiece on Github link](https://github.com/google/sentencepiece).\n",
        "\n",
        "**The big difference**: sentencepiece runs BPE on the Unicode code points directly! It then has an option `character_coverage` for what to do with very very rare codepoints that appear very few times, and it either maps them onto an UNK token, or if `byte_fallback` is turned on, it encodes them with utf-8 and then encodes the raw bytes instead.\n",
        "\n",
        "TLDR:\n",
        "\n",
        "- tiktoken encodes to utf-8 and then BPEs bytes\n",
        "- sentencepiece BPEs the code points and optionally falls back to utf-8 bytes for rare code points (rarity is determined by character_coverage hyperparameter), which then get translated to byte tokens.\n",
        "\n",
        "(Personally I think the tiktoken way is a lot cleaner...)"
      ],
      "metadata": {
        "id": "DtkrVnI7O4pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "Uw8G60I0CTlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write a toy.txt file with some random text\n",
        "with open(\"toy.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "  f.write(\"SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. SentencePiece implements subword units (e.g., byte-pair-encoding (BPE) [Sennrich et al.]) and unigram language model [Kudo.]) with the extension of direct training from raw sentences. SentencePiece allows us to make a purely end-to-end system that does not depend on language-specific pre/postprocessing.\")"
      ],
      "metadata": {
        "id": "6zGEWaHIO8G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Docs for sentencepiece options:\n",
        "\n",
        "- [markdown](https://github.com/google/sentencepiece/blob/master/doc/options.md)\n",
        "- [protobuf](https://github.com/google/sentencepiece/blob/master/src/sentencepiece_model.proto#L193)"
      ],
      "metadata": {
        "id": "zDlmQp2lO8Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train a sentencepiece model on it\n",
        "# the settings here are (best effort) those used for training Llama 2\n",
        "import os\n",
        "\n",
        "options = dict(\n",
        "  # input spec\n",
        "  input=\"toy.txt\",\n",
        "  input_format=\"text\",\n",
        "  # output spec\n",
        "  model_prefix=\"tok400\", # output filename prefix\n",
        "  # algorithm spec\n",
        "  # BPE alg\n",
        "  model_type=\"bpe\",\n",
        "  vocab_size=400,\n",
        "  # normalization\n",
        "  normalization_rule_name=\"identity\", # ew, turn off normalization\n",
        "  remove_extra_whitespaces=False,\n",
        "  input_sentence_size=200000000, # max number of training sentences\n",
        "  max_sentence_length=4192, # max number of bytes per sentence\n",
        "  seed_sentencepiece_size=1000000,\n",
        "  shuffle_input_sentence=True,\n",
        "  # rare word treatment\n",
        "  character_coverage=0.99995,\n",
        "  byte_fallback=True,\n",
        "  # merge rules\n",
        "  split_digits=True,\n",
        "  split_by_unicode_script=True,\n",
        "  split_by_whitespace=True,\n",
        "  split_by_number=True,\n",
        "  max_sentencepiece_length=16,\n",
        "  add_dummy_prefix=True,\n",
        "  allow_whitespace_only_pieces=True,\n",
        "  # special tokens\n",
        "  unk_id=0, # the UNK token MUST exist\n",
        "  bos_id=1, # the others are optional, set to -1 to turn off\n",
        "  eos_id=2,\n",
        "  pad_id=-1,\n",
        "  # systems\n",
        "  num_threads=os.cpu_count(), # use ~all system resources\n",
        ")\n",
        "\n",
        "spm.SentencePieceTrainer.train(**options)\n"
      ],
      "metadata": {
        "id": "aJu1e_oIO8Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('tok400.model')\n",
        "vocab = [[sp.id_to_piece(idx), idx] for idx in range(sp.get_piece_size())]\n",
        "vocab"
      ],
      "metadata": {
        "id": "TWl0t88IO8Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = sp.encode(\"hello ì•ˆë…•í•˜ì„¸ìš”\")\n",
        "print(ids)"
      ],
      "metadata": {
        "id": "_X_rAOknPBQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([sp.id_to_piece(idx) for idx in ids])"
      ],
      "metadata": {
        "id": "ocBHrGjIPBN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Llama 2 tokenizer proto**\n",
        "If you'd like to export the raw protocol buffer for the `tokenizer.model` released by meta, this is a [helpful issue](https://github.com/google/sentencepiece/issues/121). And this is the result:\n",
        "\n",
        "```\n",
        "normalizer_spec {\n",
        "  name: \"identity\"\n",
        "  precompiled_charsmap: \"\"\n",
        "  add_dummy_prefix: true\n",
        "  remove_extra_whitespaces: false\n",
        "  normalization_rule_tsv: \"\"\n",
        "}\n",
        "\n",
        "trainer_spec {\n",
        "  input: \"/large_experiments/theorem/datasets/MERGED/all.test1.merged\"\n",
        "  model_prefix: \"spm_model_32k_200M_charcov099995_allowWSO__v2\"\n",
        "  model_type: BPE\n",
        "  vocab_size: 32000\n",
        "  self_test_sample_size: 0\n",
        "  input_format: \"text\"\n",
        "  character_coverage: 0.99995\n",
        "  input_sentence_size: 200000000\n",
        "  seed_sentencepiece_size: 1000000\n",
        "  shrinking_factor: 0.75\n",
        "  num_threads: 80\n",
        "  num_sub_iterations: 2\n",
        "  max_sentence_length: 4192\n",
        "  shuffle_input_sentence: true\n",
        "  max_sentencepiece_length: 16\n",
        "  split_by_unicode_script: true\n",
        "  split_by_whitespace: true\n",
        "  split_by_number: true\n",
        "  treat_whitespace_as_suffix: false\n",
        "  split_digits: true\n",
        "  allow_whitespace_only_pieces: true\n",
        "  vocabulary_output_piece_score: true\n",
        "  hard_vocab_limit: true\n",
        "  use_all_vocab: false\n",
        "  byte_fallback: true\n",
        "  required_chars: \"\"\n",
        "  unk_id: 0\n",
        "  bos_id: 1\n",
        "  eos_id: 2\n",
        "  pad_id: -1\n",
        "  unk_surface: \" \\342\\201\\207 \"\n",
        "  unk_piece: \"<unk>\"\n",
        "  bos_piece: \"<s>\"\n",
        "  eos_piece: \"</s>\"\n",
        "  pad_piece: \"<pad>\"\n",
        "  train_extremely_large_corpus: false\n",
        "  enable_differential_privacy: false\n",
        "  differential_privacy_noise_level: 0.0\n",
        "  differential_privacy_clipping_threshold: 0\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "AhGByTpSP-0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### vocab_size\n",
        "\n",
        "- Q: what should be vocab size?\n",
        "- Q: how can I increase vocab size?\n",
        "- A: let's see. Reminder: [gpt.py](https://github.com/karpathy/ng-video-lecture/blob/master/gpt.py) from before."
      ],
      "metadata": {
        "id": "BHlrnU0MP-yM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final recommendations\n",
        "\n",
        "- Don't brush off tokenization. A lot of footguns and sharp edges here. Security issues. Safety issues.\n",
        "- Eternal glory to anyone who can delete tokenization as a required step in LLMs.\n",
        "- In your own application:\n",
        "  - Maybe you can just re-use the GPT-4 tokens and tiktoken?\n",
        "  - If you're training a vocab, ok to use BPE with sentencepiece. Careful with the million settings.\n",
        "  - Switch to minbpe once it is as efficient as sentencepiece :)\n"
      ],
      "metadata": {
        "id": "ToVfNWLKPBLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Personal Notes\n"
      ],
      "metadata": {
        "id": "3uNWzzqZWUfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The different tokenization methodsâ€”**TikTokenizer**, **WordPiece**, **Byte Pair Encoding (BPE)**, and **SentencePiece**â€”are used in natural language processing to break down text into manageable pieces or tokens that machine learning models can understand and process. Each has its specific characteristics and use cases, particularly in the context of training large language models like those in the GPT series or transformers used by Google. Here's a brief overview of each:\n",
        "\n",
        "### 1. Byte Pair Encoding (BPE)\n",
        "- **Used By**: Originally used in data compression, BPE has been widely adopted in NLP for models like GPT-2 and GPT-3. GPT-4 also uses a variant of BPE but it's optimized further.\n",
        "- **Methodology**: BPE starts with the full text broken down into characters and iteratively merges the most frequent pairs of characters or character sequences, until a specified vocabulary size is reached. This allows the model to handle rare words more effectively by breaking them down into known subwords.\n",
        "- **Advantages**: Efficient at reducing the vocabulary size needed to cover most text data, allowing for handling of rare words or out-of-vocabulary (OOV) issues by decomposing them into smaller known units.\n",
        "\n",
        "### 2. WordPiece\n",
        "- **Used By**: Originally developed for speech recognition, it gained prominence in NLP through its use in Google's BERT and other Transformer-based models.\n",
        "- **Methodology**: Similar to BPE, WordPiece starts with characters and iteratively merges the most frequent pairs, but it introduces a likelihood-based criterion for merging that can depend on language model probabilities, not just raw frequency.\n",
        "- **Advantages**: It tends to produce more meaningful subwords compared to BPE, as it considers the context more deeply through the use of language modeling probabilities during the training of the tokenizer.\n",
        "\n",
        "### 3. SentencePiece\n",
        "- **Used By**: Models that require handling multiple languages efficiently, such as multilingual BERT and T5.\n",
        "- **Methodology**: SentencePiece tokenizes text directly into subword units without depending on whitespace for initial token boundaries, which is crucial for languages without clear whitespace delimiters. It includes implementations of both BPE and unigram language model-based tokenization.\n",
        "- **Advantages**: Language-agnostic, robust to changes in script and effective in scenarios involving multiple languages. It avoids the bias introduced by preprocessing steps like whitespace tokenization, making it ideal for direct use on raw text.\n",
        "\n",
        "### 4. TikTokenizer\n",
        "- **Usage Context**: Likely a proprietary or less known tokenizer, possibly designed for specific applications or as part of a specific toolkit.\n",
        "- **Methodology**: Details would depend on the specific implementation, but like other tokenizers, it would aim to decompose text into manageable, processable tokens.\n",
        "- **Advantages**: Without specific details, itâ€™s hard to say, but specialized tokenizers like this might be optimized for particular languages, tasks, or performance characteristics.\n",
        "\n",
        "### Summary and Selection Criteria\n",
        "- **BPE and WordPiece** are excellent for languages with clear subword structures and are widely used due to their balance of performance and comprehensibility.\n",
        "- **SentencePiece** is ideal for applications involving multiple languages, especially when whitespace tokenization is not reliable.\n",
        "- **TikTokenizer** might be suited for specific needs or proprietary applications where customization is crucial.\n",
        "\n",
        "Choosing the right tokenizer depends on the specific requirements of the language model, the languages involved, the computational resources available, and the specific linguistic tasks at hand."
      ],
      "metadata": {
        "id": "jlKSeHUxWUdi"
      }
    }
  ]
}